{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import gymnasium as gym\n",
    "\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 100\n",
    "PERCENTILE = 30\n",
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(DiscreteOneHotWrapper, self).__init__(env)\n",
    "        assert isinstance(env.observation_space,\n",
    "                          gym.spaces.Discrete)\n",
    "        shape = (env.observation_space.n, )\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            0.0, 1.0, shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        res = np.copy(self.observation_space.low)\n",
    "        res[observation] = 1.0\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs, _ = env.reset()\n",
    "    sm = nn.Softmax(dim=1).to(device)\n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs]).to(device)\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.detach().cpu().numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, truncated, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if is_done or truncated:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs, _ = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    filter_fun = lambda s: s.reward * (GAMMA ** len(s.steps))\n",
    "    disc_rewards = list(map(filter_fun, batch))\n",
    "    reward_bound = np.percentile(disc_rewards, percentile)\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    elite_batch = []\n",
    "    for example, discounted_reward in zip(batch, disc_rewards):\n",
    "        if discounted_reward > reward_bound:\n",
    "            train_obs.extend(map(lambda step: step.observation,\n",
    "                                 example.steps))\n",
    "            train_act.extend(map(lambda step: step.action,\n",
    "                                 example.steps))\n",
    "            elite_batch.append(example)\n",
    "\n",
    "    return elite_batch, train_obs, train_act, reward_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v1\", desc=generate_random_map(size=4), is_slippery=True))\n",
    "\n",
    "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = MLP(obs_size, HIDDEN_SIZE, n_actions).to(device)\n",
    "\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('number of parameters', 2692)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'number of parameters', sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q6/m8k2l_j15c12q72fw85lrrqc0000gn/T/ipykernel_33577/3986369348.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  obs_v = torch.FloatTensor([obs]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: loss=1.415, rw_mean=0.010, rw_bound=0.000, batch=1\n",
      "3: loss=1.339, rw_mean=0.010, rw_bound=0.000, batch=2\n",
      "4: loss=1.282, rw_mean=0.000, rw_bound=0.000, batch=2\n",
      "5: loss=1.226, rw_mean=0.000, rw_bound=0.000, batch=2\n",
      "6: loss=1.198, rw_mean=0.010, rw_bound=0.000, batch=3\n",
      "7: loss=1.154, rw_mean=0.000, rw_bound=0.000, batch=3\n",
      "8: loss=1.115, rw_mean=0.000, rw_bound=0.000, batch=3\n",
      "9: loss=1.083, rw_mean=0.000, rw_bound=0.000, batch=3\n",
      "10: loss=1.130, rw_mean=0.020, rw_bound=0.000, batch=5\n",
      "11: loss=1.121, rw_mean=0.010, rw_bound=0.000, batch=6\n",
      "12: loss=1.076, rw_mean=0.010, rw_bound=0.000, batch=7\n",
      "13: loss=1.066, rw_mean=0.010, rw_bound=0.000, batch=8\n",
      "14: loss=1.103, rw_mean=0.020, rw_bound=0.000, batch=10\n",
      "15: loss=1.070, rw_mean=0.020, rw_bound=0.000, batch=12\n",
      "16: loss=1.040, rw_mean=0.010, rw_bound=0.000, batch=13\n",
      "17: loss=1.034, rw_mean=0.000, rw_bound=0.000, batch=13\n",
      "18: loss=1.035, rw_mean=0.020, rw_bound=0.000, batch=15\n",
      "19: loss=1.000, rw_mean=0.010, rw_bound=0.000, batch=16\n",
      "20: loss=0.997, rw_mean=0.010, rw_bound=0.000, batch=17\n",
      "21: loss=0.989, rw_mean=0.000, rw_bound=0.000, batch=17\n",
      "22: loss=0.946, rw_mean=0.020, rw_bound=0.000, batch=19\n",
      "23: loss=0.941, rw_mean=0.000, rw_bound=0.000, batch=19\n",
      "24: loss=0.929, rw_mean=0.010, rw_bound=0.000, batch=20\n",
      "25: loss=0.927, rw_mean=0.000, rw_bound=0.000, batch=20\n",
      "26: loss=0.921, rw_mean=0.020, rw_bound=0.000, batch=22\n",
      "27: loss=0.917, rw_mean=0.000, rw_bound=0.000, batch=22\n",
      "28: loss=0.908, rw_mean=0.010, rw_bound=0.000, batch=23\n",
      "29: loss=0.902, rw_mean=0.040, rw_bound=0.000, batch=27\n",
      "30: loss=0.910, rw_mean=0.010, rw_bound=0.000, batch=28\n",
      "31: loss=0.875, rw_mean=0.040, rw_bound=0.000, batch=32\n",
      "32: loss=0.870, rw_mean=0.000, rw_bound=0.000, batch=32\n",
      "33: loss=0.876, rw_mean=0.020, rw_bound=0.000, batch=34\n",
      "34: loss=0.882, rw_mean=0.030, rw_bound=0.000, batch=37\n",
      "35: loss=0.875, rw_mean=0.020, rw_bound=0.000, batch=39\n",
      "36: loss=0.857, rw_mean=0.020, rw_bound=0.000, batch=41\n",
      "37: loss=0.855, rw_mean=0.000, rw_bound=0.000, batch=41\n",
      "38: loss=0.842, rw_mean=0.040, rw_bound=0.000, batch=45\n",
      "39: loss=0.834, rw_mean=0.010, rw_bound=0.000, batch=46\n",
      "40: loss=0.834, rw_mean=0.020, rw_bound=0.000, batch=48\n",
      "41: loss=0.835, rw_mean=0.010, rw_bound=0.000, batch=49\n",
      "42: loss=0.832, rw_mean=0.030, rw_bound=0.000, batch=52\n",
      "43: loss=0.831, rw_mean=0.040, rw_bound=0.000, batch=56\n",
      "44: loss=0.827, rw_mean=0.040, rw_bound=0.000, batch=60\n",
      "45: loss=0.830, rw_mean=0.040, rw_bound=0.000, batch=64\n",
      "46: loss=0.824, rw_mean=0.010, rw_bound=0.000, batch=65\n",
      "47: loss=0.825, rw_mean=0.020, rw_bound=0.000, batch=67\n",
      "48: loss=0.822, rw_mean=0.010, rw_bound=0.000, batch=68\n",
      "49: loss=0.822, rw_mean=0.000, rw_bound=0.000, batch=68\n",
      "50: loss=0.817, rw_mean=0.060, rw_bound=0.000, batch=74\n",
      "51: loss=0.815, rw_mean=0.050, rw_bound=0.000, batch=79\n",
      "52: loss=0.815, rw_mean=0.000, rw_bound=0.000, batch=79\n",
      "53: loss=0.807, rw_mean=0.030, rw_bound=0.000, batch=82\n",
      "54: loss=0.806, rw_mean=0.000, rw_bound=0.000, batch=82\n",
      "55: loss=0.798, rw_mean=0.030, rw_bound=0.000, batch=85\n",
      "56: loss=0.797, rw_mean=0.030, rw_bound=0.000, batch=88\n",
      "57: loss=0.798, rw_mean=0.020, rw_bound=0.000, batch=90\n",
      "58: loss=0.797, rw_mean=0.050, rw_bound=0.000, batch=95\n",
      "59: loss=0.795, rw_mean=0.040, rw_bound=0.000, batch=99\n",
      "60: loss=0.795, rw_mean=0.010, rw_bound=0.000, batch=100\n",
      "61: loss=0.796, rw_mean=0.050, rw_bound=0.000, batch=105\n",
      "62: loss=0.797, rw_mean=0.020, rw_bound=0.000, batch=107\n",
      "63: loss=0.794, rw_mean=0.040, rw_bound=0.000, batch=111\n",
      "64: loss=0.793, rw_mean=0.050, rw_bound=0.000, batch=116\n",
      "65: loss=0.788, rw_mean=0.040, rw_bound=0.000, batch=120\n",
      "66: loss=0.786, rw_mean=0.020, rw_bound=0.000, batch=122\n",
      "67: loss=0.785, rw_mean=0.010, rw_bound=0.000, batch=123\n",
      "68: loss=0.780, rw_mean=0.050, rw_bound=0.000, batch=128\n",
      "69: loss=0.776, rw_mean=0.040, rw_bound=0.000, batch=132\n",
      "70: loss=0.777, rw_mean=0.010, rw_bound=0.000, batch=133\n",
      "71: loss=0.777, rw_mean=0.020, rw_bound=0.000, batch=135\n",
      "72: loss=0.775, rw_mean=0.020, rw_bound=0.000, batch=137\n",
      "73: loss=0.777, rw_mean=0.070, rw_bound=0.000, batch=144\n",
      "74: loss=0.774, rw_mean=0.030, rw_bound=0.000, batch=147\n",
      "75: loss=0.770, rw_mean=0.040, rw_bound=0.000, batch=151\n",
      "76: loss=0.769, rw_mean=0.020, rw_bound=0.000, batch=153\n",
      "77: loss=0.768, rw_mean=0.030, rw_bound=0.000, batch=156\n",
      "78: loss=0.766, rw_mean=0.020, rw_bound=0.000, batch=158\n",
      "79: loss=0.765, rw_mean=0.010, rw_bound=0.000, batch=159\n",
      "80: loss=0.766, rw_mean=0.030, rw_bound=0.000, batch=162\n",
      "81: loss=0.768, rw_mean=0.020, rw_bound=0.000, batch=164\n",
      "82: loss=0.766, rw_mean=0.030, rw_bound=0.000, batch=167\n",
      "83: loss=0.764, rw_mean=0.020, rw_bound=0.000, batch=169\n",
      "84: loss=0.764, rw_mean=0.000, rw_bound=0.000, batch=169\n",
      "85: loss=0.759, rw_mean=0.050, rw_bound=0.000, batch=174\n",
      "86: loss=0.761, rw_mean=0.020, rw_bound=0.000, batch=176\n",
      "87: loss=0.760, rw_mean=0.010, rw_bound=0.000, batch=177\n",
      "88: loss=0.760, rw_mean=0.010, rw_bound=0.000, batch=178\n",
      "89: loss=0.758, rw_mean=0.060, rw_bound=0.000, batch=184\n",
      "90: loss=0.757, rw_mean=0.010, rw_bound=0.000, batch=185\n",
      "91: loss=0.756, rw_mean=0.020, rw_bound=0.000, batch=187\n",
      "92: loss=0.756, rw_mean=0.020, rw_bound=0.000, batch=189\n",
      "93: loss=0.754, rw_mean=0.020, rw_bound=0.000, batch=191\n",
      "94: loss=0.750, rw_mean=0.030, rw_bound=0.000, batch=194\n",
      "95: loss=0.749, rw_mean=0.010, rw_bound=0.000, batch=195\n",
      "96: loss=0.747, rw_mean=0.020, rw_bound=0.000, batch=197\n",
      "97: loss=0.747, rw_mean=0.010, rw_bound=0.000, batch=198\n",
      "98: loss=0.747, rw_mean=0.000, rw_bound=0.000, batch=198\n",
      "99: loss=0.747, rw_mean=0.040, rw_bound=0.000, batch=202\n",
      "100: loss=0.747, rw_mean=0.030, rw_bound=0.000, batch=205\n",
      "101: loss=0.748, rw_mean=0.010, rw_bound=0.000, batch=206\n",
      "102: loss=0.744, rw_mean=0.030, rw_bound=0.000, batch=209\n",
      "103: loss=0.744, rw_mean=0.030, rw_bound=0.000, batch=212\n",
      "104: loss=0.743, rw_mean=0.040, rw_bound=0.000, batch=216\n",
      "105: loss=0.740, rw_mean=0.020, rw_bound=0.000, batch=218\n",
      "106: loss=0.739, rw_mean=0.030, rw_bound=0.000, batch=221\n",
      "107: loss=0.740, rw_mean=0.040, rw_bound=0.034, batch=224\n",
      "108: loss=0.739, rw_mean=0.030, rw_bound=0.042, batch=227\n",
      "109: loss=0.736, rw_mean=0.040, rw_bound=0.057, batch=229\n",
      "110: loss=0.732, rw_mean=0.030, rw_bound=0.067, batch=230\n",
      "111: loss=0.733, rw_mean=0.010, rw_bound=0.050, batch=231\n",
      "112: loss=0.734, rw_mean=0.030, rw_bound=0.072, batch=230\n",
      "113: loss=0.738, rw_mean=0.040, rw_bound=0.086, batch=231\n",
      "114: loss=0.737, rw_mean=0.060, rw_bound=0.089, batch=231\n",
      "115: loss=0.743, rw_mean=0.010, rw_bound=0.098, batch=229\n",
      "116: loss=0.748, rw_mean=0.070, rw_bound=0.114, batch=230\n",
      "117: loss=0.752, rw_mean=0.030, rw_bound=0.122, batch=227\n",
      "118: loss=0.747, rw_mean=0.040, rw_bound=0.135, batch=223\n",
      "119: loss=0.746, rw_mean=0.010, rw_bound=0.000, batch=224\n",
      "120: loss=0.745, rw_mean=0.050, rw_bound=0.150, batch=221\n",
      "121: loss=0.747, rw_mean=0.040, rw_bound=0.167, batch=216\n",
      "122: loss=0.748, rw_mean=0.050, rw_bound=0.083, batch=221\n",
      "123: loss=0.747, rw_mean=0.040, rw_bound=0.109, batch=224\n",
      "124: loss=0.745, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "125: loss=0.748, rw_mean=0.040, rw_bound=0.167, batch=226\n",
      "126: loss=0.749, rw_mean=0.030, rw_bound=0.147, batch=228\n",
      "127: loss=0.752, rw_mean=0.030, rw_bound=0.185, batch=216\n",
      "128: loss=0.751, rw_mean=0.040, rw_bound=0.000, batch=220\n",
      "129: loss=0.750, rw_mean=0.040, rw_bound=0.105, batch=224\n",
      "130: loss=0.749, rw_mean=0.030, rw_bound=0.135, batch=227\n",
      "131: loss=0.747, rw_mean=0.020, rw_bound=0.120, batch=229\n",
      "132: loss=0.747, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "133: loss=0.748, rw_mean=0.030, rw_bound=0.174, batch=230\n",
      "134: loss=0.749, rw_mean=0.020, rw_bound=0.185, batch=230\n",
      "135: loss=0.746, rw_mean=0.030, rw_bound=0.206, batch=222\n",
      "136: loss=0.746, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "137: loss=0.745, rw_mean=0.020, rw_bound=0.000, batch=226\n",
      "138: loss=0.747, rw_mean=0.010, rw_bound=0.000, batch=227\n",
      "139: loss=0.747, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "140: loss=0.748, rw_mean=0.040, rw_bound=0.208, batch=229\n",
      "141: loss=0.753, rw_mean=0.040, rw_bound=0.229, batch=203\n",
      "142: loss=0.749, rw_mean=0.040, rw_bound=0.000, batch=207\n",
      "143: loss=0.748, rw_mean=0.020, rw_bound=0.000, batch=209\n",
      "144: loss=0.747, rw_mean=0.010, rw_bound=0.000, batch=210\n",
      "145: loss=0.750, rw_mean=0.040, rw_bound=0.000, batch=214\n",
      "146: loss=0.751, rw_mean=0.050, rw_bound=0.000, batch=219\n",
      "147: loss=0.754, rw_mean=0.020, rw_bound=0.000, batch=221\n",
      "148: loss=0.753, rw_mean=0.030, rw_bound=0.000, batch=224\n",
      "149: loss=0.752, rw_mean=0.030, rw_bound=0.072, batch=227\n",
      "150: loss=0.751, rw_mean=0.040, rw_bound=0.128, batch=229\n",
      "151: loss=0.751, rw_mean=0.010, rw_bound=0.054, batch=230\n",
      "152: loss=0.749, rw_mean=0.020, rw_bound=0.127, batch=231\n",
      "153: loss=0.743, rw_mean=0.030, rw_bound=0.135, batch=231\n",
      "154: loss=0.744, rw_mean=0.020, rw_bound=0.150, batch=230\n",
      "155: loss=0.746, rw_mean=0.030, rw_bound=0.185, batch=228\n",
      "156: loss=0.744, rw_mean=0.010, rw_bound=0.023, batch=229\n",
      "157: loss=0.745, rw_mean=0.020, rw_bound=0.229, batch=229\n",
      "158: loss=0.745, rw_mean=0.030, rw_bound=0.254, batch=209\n",
      "159: loss=0.745, rw_mean=0.040, rw_bound=0.000, batch=213\n",
      "160: loss=0.746, rw_mean=0.040, rw_bound=0.000, batch=217\n",
      "161: loss=0.744, rw_mean=0.020, rw_bound=0.000, batch=219\n",
      "162: loss=0.744, rw_mean=0.060, rw_bound=0.113, batch=223\n",
      "163: loss=0.742, rw_mean=0.030, rw_bound=0.081, batch=226\n",
      "164: loss=0.741, rw_mean=0.010, rw_bound=0.000, batch=227\n",
      "165: loss=0.738, rw_mean=0.030, rw_bound=0.135, batch=228\n",
      "166: loss=0.739, rw_mean=0.040, rw_bound=0.206, batch=225\n",
      "167: loss=0.736, rw_mean=0.030, rw_bound=0.043, batch=227\n",
      "168: loss=0.752, rw_mean=0.060, rw_bound=0.282, batch=202\n",
      "169: loss=0.747, rw_mean=0.040, rw_bound=0.000, batch=206\n",
      "170: loss=0.746, rw_mean=0.020, rw_bound=0.000, batch=208\n",
      "171: loss=0.748, rw_mean=0.020, rw_bound=0.000, batch=210\n",
      "172: loss=0.743, rw_mean=0.040, rw_bound=0.000, batch=214\n",
      "173: loss=0.740, rw_mean=0.070, rw_bound=0.120, batch=220\n",
      "174: loss=0.735, rw_mean=0.050, rw_bound=0.181, batch=224\n",
      "175: loss=0.735, rw_mean=0.000, rw_bound=0.000, batch=224\n",
      "176: loss=0.737, rw_mean=0.040, rw_bound=0.199, batch=227\n",
      "177: loss=0.735, rw_mean=0.020, rw_bound=0.079, batch=229\n",
      "178: loss=0.734, rw_mean=0.030, rw_bound=0.108, batch=230\n",
      "179: loss=0.734, rw_mean=0.000, rw_bound=0.000, batch=230\n",
      "180: loss=0.734, rw_mean=0.000, rw_bound=0.000, batch=230\n",
      "181: loss=0.733, rw_mean=0.010, rw_bound=0.085, batch=231\n",
      "182: loss=0.735, rw_mean=0.020, rw_bound=0.122, batch=231\n",
      "183: loss=0.740, rw_mean=0.060, rw_bound=0.254, batch=230\n",
      "184: loss=0.738, rw_mean=0.020, rw_bound=0.282, batch=227\n",
      "185: loss=0.736, rw_mean=0.030, rw_bound=0.308, batch=229\n",
      "186: loss=0.735, rw_mean=0.040, rw_bound=0.295, batch=230\n",
      "187: loss=0.733, rw_mean=0.010, rw_bound=0.220, batch=231\n",
      "188: loss=0.736, rw_mean=0.020, rw_bound=0.314, batch=178\n",
      "189: loss=0.732, rw_mean=0.020, rw_bound=0.000, batch=180\n",
      "190: loss=0.724, rw_mean=0.050, rw_bound=0.000, batch=185\n",
      "191: loss=0.722, rw_mean=0.020, rw_bound=0.000, batch=187\n",
      "192: loss=0.722, rw_mean=0.000, rw_bound=0.000, batch=187\n",
      "193: loss=0.719, rw_mean=0.050, rw_bound=0.000, batch=192\n",
      "194: loss=0.714, rw_mean=0.030, rw_bound=0.000, batch=195\n",
      "195: loss=0.709, rw_mean=0.040, rw_bound=0.000, batch=199\n",
      "196: loss=0.706, rw_mean=0.030, rw_bound=0.000, batch=202\n",
      "197: loss=0.709, rw_mean=0.040, rw_bound=0.000, batch=206\n",
      "198: loss=0.708, rw_mean=0.010, rw_bound=0.000, batch=207\n",
      "199: loss=0.706, rw_mean=0.020, rw_bound=0.000, batch=209\n",
      "200: loss=0.704, rw_mean=0.010, rw_bound=0.000, batch=210\n",
      "201: loss=0.701, rw_mean=0.020, rw_bound=0.000, batch=212\n",
      "202: loss=0.701, rw_mean=0.030, rw_bound=0.000, batch=215\n",
      "203: loss=0.701, rw_mean=0.020, rw_bound=0.000, batch=217\n",
      "204: loss=0.694, rw_mean=0.030, rw_bound=0.000, batch=220\n",
      "205: loss=0.691, rw_mean=0.040, rw_bound=0.013, batch=224\n",
      "206: loss=0.692, rw_mean=0.040, rw_bound=0.049, batch=227\n",
      "207: loss=0.691, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "208: loss=0.690, rw_mean=0.010, rw_bound=0.005, batch=229\n",
      "209: loss=0.697, rw_mean=0.050, rw_bound=0.079, batch=230\n",
      "210: loss=0.696, rw_mean=0.020, rw_bound=0.073, batch=231\n",
      "211: loss=0.697, rw_mean=0.020, rw_bound=0.122, batch=230\n",
      "212: loss=0.698, rw_mean=0.010, rw_bound=0.095, batch=231\n",
      "213: loss=0.702, rw_mean=0.010, rw_bound=0.135, batch=231\n",
      "214: loss=0.697, rw_mean=0.050, rw_bound=0.167, batch=229\n",
      "215: loss=0.703, rw_mean=0.070, rw_bound=0.206, batch=227\n",
      "216: loss=0.702, rw_mean=0.020, rw_bound=0.097, batch=229\n",
      "217: loss=0.704, rw_mean=0.010, rw_bound=0.049, batch=230\n",
      "218: loss=0.704, rw_mean=0.030, rw_bound=0.142, batch=231\n",
      "219: loss=0.701, rw_mean=0.010, rw_bound=0.150, batch=231\n",
      "220: loss=0.708, rw_mean=0.030, rw_bound=0.229, batch=226\n",
      "221: loss=0.704, rw_mean=0.020, rw_bound=0.036, batch=228\n",
      "222: loss=0.710, rw_mean=0.020, rw_bound=0.085, batch=229\n",
      "223: loss=0.708, rw_mean=0.020, rw_bound=0.215, batch=230\n",
      "224: loss=0.708, rw_mean=0.020, rw_bound=0.216, batch=231\n",
      "225: loss=0.708, rw_mean=0.020, rw_bound=0.229, batch=231\n",
      "226: loss=0.712, rw_mean=0.060, rw_bound=0.254, batch=227\n",
      "227: loss=0.711, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "228: loss=0.718, rw_mean=0.060, rw_bound=0.282, batch=219\n",
      "229: loss=0.718, rw_mean=0.040, rw_bound=0.102, batch=223\n",
      "230: loss=0.716, rw_mean=0.010, rw_bound=0.000, batch=224\n",
      "231: loss=0.713, rw_mean=0.030, rw_bound=0.150, batch=227\n",
      "232: loss=0.711, rw_mean=0.040, rw_bound=0.163, batch=229\n",
      "233: loss=0.713, rw_mean=0.030, rw_bound=0.185, batch=229\n",
      "234: loss=0.711, rw_mean=0.020, rw_bound=0.215, batch=230\n",
      "235: loss=0.711, rw_mean=0.040, rw_bound=0.229, batch=229\n",
      "236: loss=0.712, rw_mean=0.040, rw_bound=0.239, batch=230\n",
      "237: loss=0.711, rw_mean=0.020, rw_bound=0.223, batch=231\n",
      "238: loss=0.713, rw_mean=0.040, rw_bound=0.282, batch=230\n",
      "239: loss=0.722, rw_mean=0.020, rw_bound=0.314, batch=218\n",
      "240: loss=0.723, rw_mean=0.020, rw_bound=0.000, batch=220\n",
      "241: loss=0.722, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "242: loss=0.722, rw_mean=0.070, rw_bound=0.185, batch=224\n",
      "243: loss=0.722, rw_mean=0.050, rw_bound=0.206, batch=226\n",
      "244: loss=0.720, rw_mean=0.010, rw_bound=0.000, batch=227\n",
      "245: loss=0.720, rw_mean=0.030, rw_bound=0.119, batch=229\n",
      "246: loss=0.721, rw_mean=0.010, rw_bound=0.049, batch=230\n",
      "247: loss=0.727, rw_mean=0.030, rw_bound=0.247, batch=231\n",
      "248: loss=0.726, rw_mean=0.080, rw_bound=0.282, batch=230\n",
      "249: loss=0.726, rw_mean=0.050, rw_bound=0.314, batch=230\n",
      "250: loss=0.726, rw_mean=0.040, rw_bound=0.313, batch=231\n",
      "251: loss=0.726, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "252: loss=0.726, rw_mean=0.010, rw_bound=0.229, batch=231\n",
      "253: loss=0.741, rw_mean=0.040, rw_bound=0.349, batch=174\n",
      "254: loss=0.735, rw_mean=0.010, rw_bound=0.000, batch=175\n",
      "255: loss=0.726, rw_mean=0.040, rw_bound=0.000, batch=179\n",
      "256: loss=0.726, rw_mean=0.000, rw_bound=0.000, batch=179\n",
      "257: loss=0.726, rw_mean=0.010, rw_bound=0.000, batch=180\n",
      "258: loss=0.716, rw_mean=0.060, rw_bound=0.000, batch=186\n",
      "259: loss=0.712, rw_mean=0.030, rw_bound=0.000, batch=189\n",
      "260: loss=0.712, rw_mean=0.010, rw_bound=0.000, batch=190\n",
      "261: loss=0.708, rw_mean=0.020, rw_bound=0.000, batch=192\n",
      "262: loss=0.710, rw_mean=0.040, rw_bound=0.000, batch=196\n",
      "263: loss=0.706, rw_mean=0.040, rw_bound=0.000, batch=200\n",
      "264: loss=0.708, rw_mean=0.030, rw_bound=0.000, batch=203\n",
      "265: loss=0.707, rw_mean=0.020, rw_bound=0.000, batch=205\n",
      "266: loss=0.706, rw_mean=0.030, rw_bound=0.000, batch=208\n",
      "267: loss=0.703, rw_mean=0.050, rw_bound=0.000, batch=213\n",
      "268: loss=0.700, rw_mean=0.060, rw_bound=0.028, batch=219\n",
      "269: loss=0.702, rw_mean=0.080, rw_bound=0.083, batch=223\n",
      "270: loss=0.700, rw_mean=0.040, rw_bound=0.089, batch=225\n",
      "271: loss=0.699, rw_mean=0.010, rw_bound=0.000, batch=226\n",
      "272: loss=0.696, rw_mean=0.030, rw_bound=0.082, batch=228\n",
      "273: loss=0.688, rw_mean=0.060, rw_bound=0.111, batch=229\n",
      "274: loss=0.687, rw_mean=0.020, rw_bound=0.064, batch=230\n",
      "275: loss=0.688, rw_mean=0.020, rw_bound=0.131, batch=231\n",
      "276: loss=0.693, rw_mean=0.030, rw_bound=0.135, batch=231\n",
      "277: loss=0.696, rw_mean=0.010, rw_bound=0.150, batch=229\n",
      "278: loss=0.699, rw_mean=0.020, rw_bound=0.185, batch=227\n",
      "279: loss=0.701, rw_mean=0.040, rw_bound=0.206, batch=223\n",
      "280: loss=0.701, rw_mean=0.000, rw_bound=0.000, batch=223\n",
      "281: loss=0.698, rw_mean=0.030, rw_bound=0.137, batch=226\n",
      "282: loss=0.694, rw_mean=0.090, rw_bound=0.241, batch=228\n",
      "283: loss=0.695, rw_mean=0.030, rw_bound=0.147, batch=229\n",
      "284: loss=0.706, rw_mean=0.030, rw_bound=0.254, batch=221\n",
      "285: loss=0.704, rw_mean=0.040, rw_bound=0.167, batch=224\n",
      "286: loss=0.704, rw_mean=0.040, rw_bound=0.165, batch=227\n",
      "287: loss=0.703, rw_mean=0.050, rw_bound=0.182, batch=229\n",
      "288: loss=0.704, rw_mean=0.030, rw_bound=0.203, batch=230\n",
      "289: loss=0.703, rw_mean=0.070, rw_bound=0.274, batch=231\n",
      "290: loss=0.707, rw_mean=0.100, rw_bound=0.282, batch=228\n",
      "291: loss=0.713, rw_mean=0.030, rw_bound=0.314, batch=219\n",
      "292: loss=0.710, rw_mean=0.020, rw_bound=0.000, batch=221\n",
      "293: loss=0.706, rw_mean=0.040, rw_bound=0.025, batch=224\n",
      "294: loss=0.701, rw_mean=0.030, rw_bound=0.047, batch=227\n",
      "295: loss=0.703, rw_mean=0.030, rw_bound=0.089, batch=229\n",
      "296: loss=0.701, rw_mean=0.020, rw_bound=0.103, batch=230\n",
      "297: loss=0.703, rw_mean=0.070, rw_bound=0.229, batch=230\n",
      "298: loss=0.703, rw_mean=0.020, rw_bound=0.296, batch=231\n",
      "299: loss=0.709, rw_mean=0.090, rw_bound=0.314, batch=231\n",
      "300: loss=0.709, rw_mean=0.030, rw_bound=0.185, batch=231\n",
      "301: loss=0.705, rw_mean=0.040, rw_bound=0.349, batch=222\n",
      "302: loss=0.706, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "303: loss=0.705, rw_mean=0.020, rw_bound=0.000, batch=226\n",
      "304: loss=0.707, rw_mean=0.030, rw_bound=0.099, batch=228\n",
      "305: loss=0.704, rw_mean=0.040, rw_bound=0.150, batch=228\n",
      "306: loss=0.704, rw_mean=0.030, rw_bound=0.211, batch=229\n",
      "307: loss=0.705, rw_mean=0.030, rw_bound=0.167, batch=230\n",
      "308: loss=0.705, rw_mean=0.030, rw_bound=0.254, batch=230\n",
      "309: loss=0.704, rw_mean=0.010, rw_bound=0.198, batch=231\n",
      "310: loss=0.703, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "311: loss=0.702, rw_mean=0.020, rw_bound=0.098, batch=231\n",
      "312: loss=0.702, rw_mean=0.010, rw_bound=0.135, batch=231\n",
      "313: loss=0.702, rw_mean=0.030, rw_bound=0.349, batch=230\n",
      "314: loss=0.703, rw_mean=0.030, rw_bound=0.376, batch=231\n",
      "315: loss=0.702, rw_mean=0.030, rw_bound=0.387, batch=156\n",
      "316: loss=0.698, rw_mean=0.020, rw_bound=0.000, batch=158\n",
      "317: loss=0.686, rw_mean=0.030, rw_bound=0.000, batch=161\n",
      "318: loss=0.685, rw_mean=0.030, rw_bound=0.000, batch=164\n",
      "319: loss=0.672, rw_mean=0.070, rw_bound=0.000, batch=171\n",
      "320: loss=0.666, rw_mean=0.020, rw_bound=0.000, batch=173\n",
      "321: loss=0.662, rw_mean=0.040, rw_bound=0.000, batch=177\n",
      "322: loss=0.647, rw_mean=0.060, rw_bound=0.000, batch=183\n",
      "323: loss=0.648, rw_mean=0.040, rw_bound=0.000, batch=187\n",
      "324: loss=0.643, rw_mean=0.060, rw_bound=0.000, batch=193\n",
      "325: loss=0.646, rw_mean=0.040, rw_bound=0.000, batch=197\n",
      "326: loss=0.645, rw_mean=0.030, rw_bound=0.000, batch=200\n",
      "327: loss=0.643, rw_mean=0.040, rw_bound=0.000, batch=204\n",
      "328: loss=0.642, rw_mean=0.020, rw_bound=0.000, batch=206\n",
      "329: loss=0.637, rw_mean=0.030, rw_bound=0.000, batch=209\n",
      "330: loss=0.635, rw_mean=0.020, rw_bound=0.000, batch=211\n",
      "331: loss=0.630, rw_mean=0.030, rw_bound=0.000, batch=214\n",
      "332: loss=0.624, rw_mean=0.060, rw_bound=0.020, batch=220\n",
      "333: loss=0.629, rw_mean=0.060, rw_bound=0.034, batch=223\n",
      "334: loss=0.637, rw_mean=0.060, rw_bound=0.072, batch=225\n",
      "335: loss=0.640, rw_mean=0.050, rw_bound=0.101, batch=227\n",
      "336: loss=0.649, rw_mean=0.050, rw_bound=0.109, batch=228\n",
      "337: loss=0.653, rw_mean=0.030, rw_bound=0.135, batch=225\n",
      "338: loss=0.653, rw_mean=0.010, rw_bound=0.000, batch=226\n",
      "339: loss=0.654, rw_mean=0.010, rw_bound=0.000, batch=227\n",
      "340: loss=0.653, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "341: loss=0.655, rw_mean=0.030, rw_bound=0.152, batch=229\n",
      "342: loss=0.653, rw_mean=0.010, rw_bound=0.067, batch=230\n",
      "343: loss=0.654, rw_mean=0.010, rw_bound=0.117, batch=231\n",
      "344: loss=0.651, rw_mean=0.050, rw_bound=0.185, batch=228\n",
      "345: loss=0.654, rw_mean=0.020, rw_bound=0.206, batch=226\n",
      "346: loss=0.655, rw_mean=0.030, rw_bound=0.198, batch=228\n",
      "347: loss=0.654, rw_mean=0.040, rw_bound=0.229, batch=227\n",
      "348: loss=0.658, rw_mean=0.040, rw_bound=0.254, batch=223\n",
      "349: loss=0.656, rw_mean=0.040, rw_bound=0.244, batch=226\n",
      "350: loss=0.657, rw_mean=0.030, rw_bound=0.268, batch=228\n",
      "351: loss=0.661, rw_mean=0.050, rw_bound=0.282, batch=224\n",
      "352: loss=0.659, rw_mean=0.040, rw_bound=0.254, batch=226\n",
      "353: loss=0.657, rw_mean=0.020, rw_bound=0.114, batch=228\n",
      "354: loss=0.656, rw_mean=0.020, rw_bound=0.130, batch=229\n",
      "355: loss=0.655, rw_mean=0.020, rw_bound=0.130, batch=230\n",
      "356: loss=0.653, rw_mean=0.030, rw_bound=0.222, batch=231\n",
      "357: loss=0.656, rw_mean=0.040, rw_bound=0.229, batch=230\n",
      "358: loss=0.657, rw_mean=0.040, rw_bound=0.254, batch=230\n",
      "359: loss=0.657, rw_mean=0.020, rw_bound=0.223, batch=231\n",
      "360: loss=0.656, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "361: loss=0.669, rw_mean=0.020, rw_bound=0.314, batch=214\n",
      "362: loss=0.667, rw_mean=0.060, rw_bound=0.122, batch=220\n",
      "363: loss=0.669, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "364: loss=0.670, rw_mean=0.070, rw_bound=0.184, batch=226\n",
      "365: loss=0.668, rw_mean=0.030, rw_bound=0.185, batch=227\n",
      "366: loss=0.671, rw_mean=0.020, rw_bound=0.165, batch=229\n",
      "367: loss=0.670, rw_mean=0.060, rw_bound=0.239, batch=230\n",
      "368: loss=0.671, rw_mean=0.050, rw_bound=0.254, batch=230\n",
      "369: loss=0.671, rw_mean=0.050, rw_bound=0.282, batch=227\n",
      "370: loss=0.670, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "371: loss=0.672, rw_mean=0.050, rw_bound=0.286, batch=229\n",
      "372: loss=0.672, rw_mean=0.020, rw_bound=0.278, batch=230\n",
      "373: loss=0.673, rw_mean=0.010, rw_bound=0.220, batch=231\n",
      "374: loss=0.670, rw_mean=0.030, rw_bound=0.349, batch=213\n",
      "375: loss=0.671, rw_mean=0.030, rw_bound=0.000, batch=216\n",
      "376: loss=0.672, rw_mean=0.060, rw_bound=0.207, batch=221\n",
      "377: loss=0.668, rw_mean=0.050, rw_bound=0.135, batch=224\n",
      "378: loss=0.664, rw_mean=0.030, rw_bound=0.058, batch=227\n",
      "379: loss=0.663, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "380: loss=0.666, rw_mean=0.020, rw_bound=0.077, batch=229\n",
      "381: loss=0.666, rw_mean=0.010, rw_bound=0.074, batch=230\n",
      "382: loss=0.665, rw_mean=0.020, rw_bound=0.159, batch=231\n",
      "383: loss=0.663, rw_mean=0.060, rw_bound=0.229, batch=228\n",
      "384: loss=0.666, rw_mean=0.040, rw_bound=0.257, batch=229\n",
      "385: loss=0.665, rw_mean=0.030, rw_bound=0.224, batch=230\n",
      "386: loss=0.671, rw_mean=0.050, rw_bound=0.282, batch=228\n",
      "387: loss=0.668, rw_mean=0.020, rw_bound=0.314, batch=226\n",
      "388: loss=0.667, rw_mean=0.040, rw_bound=0.316, batch=228\n",
      "389: loss=0.667, rw_mean=0.020, rw_bound=0.124, batch=229\n",
      "390: loss=0.666, rw_mean=0.050, rw_bound=0.292, batch=230\n",
      "391: loss=0.669, rw_mean=0.040, rw_bound=0.349, batch=225\n",
      "392: loss=0.671, rw_mean=0.080, rw_bound=0.356, batch=227\n",
      "393: loss=0.673, rw_mean=0.040, rw_bound=0.308, batch=229\n",
      "394: loss=0.671, rw_mean=0.020, rw_bound=0.278, batch=230\n",
      "395: loss=0.672, rw_mean=0.030, rw_bound=0.304, batch=231\n",
      "396: loss=0.673, rw_mean=0.010, rw_bound=0.150, batch=231\n",
      "397: loss=0.670, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "398: loss=0.670, rw_mean=0.050, rw_bound=0.349, batch=230\n",
      "399: loss=0.669, rw_mean=0.030, rw_bound=0.316, batch=231\n",
      "400: loss=0.676, rw_mean=0.050, rw_bound=0.387, batch=214\n",
      "401: loss=0.679, rw_mean=0.060, rw_bound=0.150, batch=220\n",
      "402: loss=0.684, rw_mean=0.040, rw_bound=0.105, batch=224\n",
      "403: loss=0.684, rw_mean=0.040, rw_bound=0.165, batch=227\n",
      "404: loss=0.674, rw_mean=0.050, rw_bound=0.206, batch=226\n",
      "405: loss=0.674, rw_mean=0.070, rw_bound=0.268, batch=228\n",
      "406: loss=0.673, rw_mean=0.060, rw_bound=0.282, batch=227\n",
      "407: loss=0.673, rw_mean=0.030, rw_bound=0.163, batch=229\n",
      "408: loss=0.676, rw_mean=0.050, rw_bound=0.328, batch=230\n",
      "409: loss=0.673, rw_mean=0.010, rw_bound=0.244, batch=231\n",
      "410: loss=0.673, rw_mean=0.050, rw_bound=0.349, batch=230\n",
      "411: loss=0.670, rw_mean=0.060, rw_bound=0.387, batch=226\n",
      "412: loss=0.669, rw_mean=0.040, rw_bound=0.330, batch=228\n",
      "413: loss=0.669, rw_mean=0.010, rw_bound=0.039, batch=229\n",
      "414: loss=0.671, rw_mean=0.030, rw_bound=0.387, batch=229\n",
      "415: loss=0.672, rw_mean=0.030, rw_bound=0.309, batch=230\n",
      "416: loss=0.674, rw_mean=0.030, rw_bound=0.418, batch=231\n",
      "417: loss=0.673, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "418: loss=0.673, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "419: loss=0.700, rw_mean=0.020, rw_bound=0.430, batch=129\n",
      "420: loss=0.683, rw_mean=0.050, rw_bound=0.000, batch=134\n",
      "421: loss=0.683, rw_mean=0.010, rw_bound=0.000, batch=135\n",
      "422: loss=0.679, rw_mean=0.030, rw_bound=0.000, batch=138\n",
      "423: loss=0.664, rw_mean=0.030, rw_bound=0.000, batch=141\n",
      "424: loss=0.659, rw_mean=0.030, rw_bound=0.000, batch=144\n",
      "425: loss=0.663, rw_mean=0.010, rw_bound=0.000, batch=145\n",
      "426: loss=0.658, rw_mean=0.020, rw_bound=0.000, batch=147\n",
      "427: loss=0.658, rw_mean=0.010, rw_bound=0.000, batch=148\n",
      "428: loss=0.657, rw_mean=0.020, rw_bound=0.000, batch=150\n",
      "429: loss=0.657, rw_mean=0.030, rw_bound=0.000, batch=153\n",
      "430: loss=0.647, rw_mean=0.050, rw_bound=0.000, batch=158\n",
      "431: loss=0.642, rw_mean=0.040, rw_bound=0.000, batch=162\n",
      "432: loss=0.638, rw_mean=0.020, rw_bound=0.000, batch=164\n",
      "433: loss=0.637, rw_mean=0.020, rw_bound=0.000, batch=166\n",
      "434: loss=0.631, rw_mean=0.050, rw_bound=0.000, batch=171\n",
      "435: loss=0.623, rw_mean=0.040, rw_bound=0.000, batch=175\n",
      "436: loss=0.618, rw_mean=0.050, rw_bound=0.000, batch=180\n",
      "437: loss=0.613, rw_mean=0.030, rw_bound=0.000, batch=183\n",
      "438: loss=0.615, rw_mean=0.040, rw_bound=0.000, batch=187\n",
      "439: loss=0.616, rw_mean=0.040, rw_bound=0.000, batch=191\n",
      "440: loss=0.616, rw_mean=0.050, rw_bound=0.000, batch=196\n",
      "441: loss=0.612, rw_mean=0.030, rw_bound=0.000, batch=199\n",
      "442: loss=0.611, rw_mean=0.020, rw_bound=0.000, batch=201\n",
      "443: loss=0.611, rw_mean=0.020, rw_bound=0.000, batch=203\n",
      "444: loss=0.611, rw_mean=0.070, rw_bound=0.000, batch=210\n",
      "445: loss=0.613, rw_mean=0.060, rw_bound=0.000, batch=216\n",
      "446: loss=0.614, rw_mean=0.020, rw_bound=0.000, batch=218\n",
      "447: loss=0.613, rw_mean=0.060, rw_bound=0.025, batch=222\n",
      "448: loss=0.611, rw_mean=0.030, rw_bound=0.008, batch=225\n",
      "449: loss=0.610, rw_mean=0.020, rw_bound=0.006, batch=227\n",
      "450: loss=0.616, rw_mean=0.060, rw_bound=0.065, batch=227\n",
      "451: loss=0.624, rw_mean=0.040, rw_bound=0.078, batch=229\n",
      "452: loss=0.632, rw_mean=0.030, rw_bound=0.080, batch=229\n",
      "453: loss=0.631, rw_mean=0.030, rw_bound=0.089, batch=229\n",
      "454: loss=0.635, rw_mean=0.030, rw_bound=0.114, batch=230\n",
      "455: loss=0.635, rw_mean=0.060, rw_bound=0.146, batch=231\n",
      "456: loss=0.635, rw_mean=0.020, rw_bound=0.109, batch=231\n",
      "457: loss=0.641, rw_mean=0.040, rw_bound=0.167, batch=229\n",
      "458: loss=0.640, rw_mean=0.020, rw_bound=0.185, batch=226\n",
      "459: loss=0.639, rw_mean=0.070, rw_bound=0.206, batch=227\n",
      "460: loss=0.637, rw_mean=0.080, rw_bound=0.229, batch=224\n",
      "461: loss=0.636, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "462: loss=0.636, rw_mean=0.010, rw_bound=0.000, batch=226\n",
      "463: loss=0.640, rw_mean=0.040, rw_bound=0.230, batch=228\n",
      "464: loss=0.644, rw_mean=0.050, rw_bound=0.254, batch=216\n",
      "465: loss=0.641, rw_mean=0.010, rw_bound=0.000, batch=217\n",
      "466: loss=0.639, rw_mean=0.020, rw_bound=0.000, batch=219\n",
      "467: loss=0.636, rw_mean=0.030, rw_bound=0.000, batch=222\n",
      "468: loss=0.639, rw_mean=0.050, rw_bound=0.127, batch=225\n",
      "469: loss=0.637, rw_mean=0.020, rw_bound=0.016, batch=227\n",
      "470: loss=0.637, rw_mean=0.040, rw_bound=0.151, batch=229\n",
      "471: loss=0.636, rw_mean=0.020, rw_bound=0.167, batch=229\n",
      "472: loss=0.637, rw_mean=0.040, rw_bound=0.206, batch=228\n",
      "473: loss=0.634, rw_mean=0.010, rw_bound=0.023, batch=229\n",
      "474: loss=0.646, rw_mean=0.070, rw_bound=0.282, batch=218\n",
      "475: loss=0.646, rw_mean=0.040, rw_bound=0.011, batch=222\n",
      "476: loss=0.646, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "477: loss=0.645, rw_mean=0.050, rw_bound=0.164, batch=227\n",
      "478: loss=0.644, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "479: loss=0.642, rw_mean=0.040, rw_bound=0.171, batch=229\n",
      "480: loss=0.644, rw_mean=0.020, rw_bound=0.225, batch=230\n",
      "481: loss=0.644, rw_mean=0.040, rw_bound=0.274, batch=231\n",
      "482: loss=0.664, rw_mean=0.040, rw_bound=0.314, batch=208\n",
      "483: loss=0.660, rw_mean=0.050, rw_bound=0.000, batch=213\n",
      "484: loss=0.657, rw_mean=0.030, rw_bound=0.000, batch=216\n",
      "485: loss=0.650, rw_mean=0.050, rw_bound=0.026, batch=221\n",
      "486: loss=0.652, rw_mean=0.050, rw_bound=0.080, batch=224\n",
      "487: loss=0.652, rw_mean=0.030, rw_bound=0.089, batch=227\n",
      "488: loss=0.648, rw_mean=0.040, rw_bound=0.093, batch=229\n",
      "489: loss=0.649, rw_mean=0.040, rw_bound=0.174, batch=230\n",
      "490: loss=0.651, rw_mean=0.040, rw_bound=0.185, batch=229\n",
      "491: loss=0.653, rw_mean=0.030, rw_bound=0.239, batch=230\n",
      "492: loss=0.654, rw_mean=0.040, rw_bound=0.218, batch=231\n",
      "493: loss=0.657, rw_mean=0.040, rw_bound=0.254, batch=231\n",
      "494: loss=0.659, rw_mean=0.040, rw_bound=0.282, batch=225\n",
      "495: loss=0.666, rw_mean=0.040, rw_bound=0.314, batch=224\n",
      "496: loss=0.666, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "497: loss=0.663, rw_mean=0.030, rw_bound=0.125, batch=227\n",
      "498: loss=0.666, rw_mean=0.070, rw_bound=0.308, batch=229\n",
      "499: loss=0.664, rw_mean=0.010, rw_bound=0.126, batch=230\n",
      "500: loss=0.661, rw_mean=0.060, rw_bound=0.338, batch=231\n",
      "501: loss=0.681, rw_mean=0.050, rw_bound=0.349, batch=208\n",
      "502: loss=0.676, rw_mean=0.020, rw_bound=0.000, batch=210\n",
      "503: loss=0.672, rw_mean=0.060, rw_bound=0.000, batch=216\n",
      "504: loss=0.669, rw_mean=0.070, rw_bound=0.099, batch=221\n",
      "505: loss=0.680, rw_mean=0.060, rw_bound=0.167, batch=223\n",
      "506: loss=0.677, rw_mean=0.040, rw_bound=0.154, batch=226\n",
      "507: loss=0.674, rw_mean=0.020, rw_bound=0.061, batch=228\n",
      "508: loss=0.675, rw_mean=0.010, rw_bound=0.012, batch=229\n",
      "509: loss=0.671, rw_mean=0.050, rw_bound=0.194, batch=230\n",
      "510: loss=0.674, rw_mean=0.090, rw_bound=0.229, batch=229\n",
      "511: loss=0.674, rw_mean=0.030, rw_bound=0.203, batch=230\n",
      "512: loss=0.673, rw_mean=0.030, rw_bound=0.282, batch=228\n",
      "513: loss=0.672, rw_mean=0.040, rw_bound=0.314, batch=226\n",
      "514: loss=0.667, rw_mean=0.030, rw_bound=0.059, batch=228\n",
      "515: loss=0.672, rw_mean=0.020, rw_bound=0.077, batch=229\n",
      "516: loss=0.671, rw_mean=0.030, rw_bound=0.108, batch=230\n",
      "517: loss=0.674, rw_mean=0.050, rw_bound=0.296, batch=231\n",
      "518: loss=0.674, rw_mean=0.010, rw_bound=0.135, batch=231\n",
      "519: loss=0.674, rw_mean=0.040, rw_bound=0.282, batch=231\n",
      "520: loss=0.674, rw_mean=0.030, rw_bound=0.229, batch=231\n",
      "521: loss=0.675, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "522: loss=0.674, rw_mean=0.020, rw_bound=0.349, batch=228\n",
      "523: loss=0.674, rw_mean=0.030, rw_bound=0.224, batch=229\n",
      "524: loss=0.680, rw_mean=0.040, rw_bound=0.387, batch=196\n",
      "525: loss=0.679, rw_mean=0.030, rw_bound=0.000, batch=199\n",
      "526: loss=0.678, rw_mean=0.070, rw_bound=0.000, batch=206\n",
      "527: loss=0.673, rw_mean=0.030, rw_bound=0.000, batch=209\n",
      "528: loss=0.669, rw_mean=0.030, rw_bound=0.000, batch=212\n",
      "529: loss=0.670, rw_mean=0.000, rw_bound=0.000, batch=212\n",
      "530: loss=0.665, rw_mean=0.030, rw_bound=0.000, batch=215\n",
      "531: loss=0.664, rw_mean=0.020, rw_bound=0.000, batch=217\n",
      "532: loss=0.663, rw_mean=0.020, rw_bound=0.000, batch=219\n",
      "533: loss=0.656, rw_mean=0.040, rw_bound=0.010, batch=223\n",
      "534: loss=0.659, rw_mean=0.060, rw_bound=0.077, batch=226\n",
      "535: loss=0.658, rw_mean=0.040, rw_bound=0.112, batch=228\n",
      "536: loss=0.669, rw_mean=0.070, rw_bound=0.167, batch=228\n",
      "537: loss=0.672, rw_mean=0.030, rw_bound=0.185, batch=228\n",
      "538: loss=0.675, rw_mean=0.050, rw_bound=0.208, batch=229\n",
      "539: loss=0.676, rw_mean=0.040, rw_bound=0.229, batch=228\n",
      "540: loss=0.677, rw_mean=0.020, rw_bound=0.254, batch=227\n",
      "541: loss=0.681, rw_mean=0.020, rw_bound=0.226, batch=229\n",
      "542: loss=0.684, rw_mean=0.070, rw_bound=0.282, batch=227\n",
      "543: loss=0.684, rw_mean=0.040, rw_bound=0.308, batch=229\n",
      "544: loss=0.683, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "545: loss=0.685, rw_mean=0.010, rw_bound=0.126, batch=230\n",
      "546: loss=0.685, rw_mean=0.040, rw_bound=0.288, batch=231\n",
      "547: loss=0.682, rw_mean=0.030, rw_bound=0.314, batch=229\n",
      "548: loss=0.682, rw_mean=0.040, rw_bound=0.328, batch=230\n",
      "549: loss=0.679, rw_mean=0.010, rw_bound=0.198, batch=231\n",
      "550: loss=0.678, rw_mean=0.040, rw_bound=0.349, batch=222\n",
      "551: loss=0.674, rw_mean=0.030, rw_bound=0.050, batch=225\n",
      "552: loss=0.674, rw_mean=0.030, rw_bound=0.097, batch=227\n",
      "553: loss=0.673, rw_mean=0.030, rw_bound=0.163, batch=229\n",
      "554: loss=0.675, rw_mean=0.020, rw_bound=0.167, batch=229\n",
      "555: loss=0.674, rw_mean=0.030, rw_bound=0.140, batch=230\n",
      "556: loss=0.672, rw_mean=0.070, rw_bound=0.304, batch=231\n",
      "557: loss=0.679, rw_mean=0.050, rw_bound=0.387, batch=224\n",
      "558: loss=0.677, rw_mean=0.030, rw_bound=0.122, batch=227\n",
      "559: loss=0.677, rw_mean=0.020, rw_bound=0.108, batch=229\n",
      "560: loss=0.677, rw_mean=0.050, rw_bound=0.182, batch=230\n",
      "561: loss=0.677, rw_mean=0.010, rw_bound=0.117, batch=231\n",
      "562: loss=0.676, rw_mean=0.040, rw_bound=0.314, batch=230\n",
      "563: loss=0.676, rw_mean=0.020, rw_bound=0.185, batch=230\n",
      "564: loss=0.675, rw_mean=0.020, rw_bound=0.321, batch=231\n",
      "565: loss=0.675, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "566: loss=0.675, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "567: loss=0.675, rw_mean=0.010, rw_bound=0.122, batch=231\n",
      "568: loss=0.675, rw_mean=0.000, rw_bound=0.000, batch=231\n",
      "569: loss=0.675, rw_mean=0.010, rw_bound=0.185, batch=231\n",
      "570: loss=0.690, rw_mean=0.040, rw_bound=0.430, batch=183\n",
      "571: loss=0.687, rw_mean=0.030, rw_bound=0.000, batch=186\n",
      "572: loss=0.683, rw_mean=0.030, rw_bound=0.000, batch=189\n",
      "573: loss=0.678, rw_mean=0.030, rw_bound=0.000, batch=192\n",
      "574: loss=0.677, rw_mean=0.000, rw_bound=0.000, batch=192\n",
      "575: loss=0.672, rw_mean=0.030, rw_bound=0.000, batch=195\n",
      "576: loss=0.677, rw_mean=0.030, rw_bound=0.000, batch=198\n",
      "577: loss=0.673, rw_mean=0.060, rw_bound=0.000, batch=204\n",
      "578: loss=0.672, rw_mean=0.010, rw_bound=0.000, batch=205\n",
      "579: loss=0.670, rw_mean=0.020, rw_bound=0.000, batch=207\n",
      "580: loss=0.671, rw_mean=0.030, rw_bound=0.000, batch=210\n",
      "581: loss=0.669, rw_mean=0.050, rw_bound=0.000, batch=215\n",
      "582: loss=0.669, rw_mean=0.070, rw_bound=0.089, batch=217\n",
      "583: loss=0.669, rw_mean=0.030, rw_bound=0.000, batch=220\n",
      "584: loss=0.661, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "585: loss=0.666, rw_mean=0.050, rw_bound=0.085, batch=226\n",
      "586: loss=0.664, rw_mean=0.030, rw_bound=0.105, batch=228\n",
      "587: loss=0.665, rw_mean=0.030, rw_bound=0.135, batch=227\n",
      "588: loss=0.667, rw_mean=0.030, rw_bound=0.150, batch=227\n",
      "589: loss=0.673, rw_mean=0.090, rw_bound=0.206, batch=227\n",
      "590: loss=0.670, rw_mean=0.020, rw_bound=0.034, batch=229\n",
      "591: loss=0.674, rw_mean=0.020, rw_bound=0.117, batch=230\n",
      "592: loss=0.670, rw_mean=0.010, rw_bound=0.144, batch=231\n",
      "593: loss=0.673, rw_mean=0.030, rw_bound=0.206, batch=231\n",
      "594: loss=0.681, rw_mean=0.070, rw_bound=0.254, batch=228\n",
      "595: loss=0.683, rw_mean=0.040, rw_bound=0.282, batch=218\n",
      "596: loss=0.681, rw_mean=0.040, rw_bound=0.012, batch=222\n",
      "597: loss=0.679, rw_mean=0.050, rw_bound=0.140, batch=225\n",
      "598: loss=0.675, rw_mean=0.050, rw_bound=0.157, batch=227\n",
      "599: loss=0.678, rw_mean=0.060, rw_bound=0.245, batch=229\n",
      "600: loss=0.678, rw_mean=0.030, rw_bound=0.213, batch=230\n",
      "601: loss=0.683, rw_mean=0.040, rw_bound=0.274, batch=231\n",
      "602: loss=0.683, rw_mean=0.020, rw_bound=0.206, batch=231\n",
      "603: loss=0.683, rw_mean=0.030, rw_bound=0.282, batch=230\n",
      "604: loss=0.682, rw_mean=0.010, rw_bound=0.220, batch=231\n",
      "605: loss=0.688, rw_mean=0.010, rw_bound=0.314, batch=223\n",
      "606: loss=0.687, rw_mean=0.010, rw_bound=0.000, batch=224\n",
      "607: loss=0.685, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "608: loss=0.684, rw_mean=0.040, rw_bound=0.131, batch=227\n",
      "609: loss=0.682, rw_mean=0.030, rw_bound=0.155, batch=229\n",
      "610: loss=0.684, rw_mean=0.030, rw_bound=0.206, batch=229\n",
      "611: loss=0.685, rw_mean=0.040, rw_bound=0.282, batch=228\n",
      "612: loss=0.686, rw_mean=0.040, rw_bound=0.217, batch=229\n",
      "613: loss=0.686, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "614: loss=0.682, rw_mean=0.010, rw_bound=0.074, batch=230\n",
      "615: loss=0.681, rw_mean=0.010, rw_bound=0.117, batch=231\n",
      "616: loss=0.685, rw_mean=0.040, rw_bound=0.185, batch=231\n",
      "617: loss=0.687, rw_mean=0.010, rw_bound=0.314, batch=229\n",
      "618: loss=0.691, rw_mean=0.060, rw_bound=0.349, batch=218\n",
      "619: loss=0.688, rw_mean=0.080, rw_bound=0.245, batch=222\n",
      "620: loss=0.686, rw_mean=0.040, rw_bound=0.193, batch=225\n",
      "621: loss=0.683, rw_mean=0.040, rw_bound=0.260, batch=227\n",
      "622: loss=0.680, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "623: loss=0.684, rw_mean=0.040, rw_bound=0.178, batch=229\n",
      "624: loss=0.684, rw_mean=0.040, rw_bound=0.265, batch=230\n",
      "625: loss=0.684, rw_mean=0.050, rw_bound=0.329, batch=231\n",
      "626: loss=0.684, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "627: loss=0.685, rw_mean=0.040, rw_bound=0.387, batch=215\n",
      "628: loss=0.679, rw_mean=0.050, rw_bound=0.027, batch=220\n",
      "629: loss=0.676, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "630: loss=0.677, rw_mean=0.060, rw_bound=0.185, batch=224\n",
      "631: loss=0.678, rw_mean=0.030, rw_bound=0.135, batch=227\n",
      "632: loss=0.676, rw_mean=0.070, rw_bound=0.308, batch=229\n",
      "633: loss=0.686, rw_mean=0.070, rw_bound=0.349, batch=226\n",
      "634: loss=0.682, rw_mean=0.030, rw_bound=0.130, batch=228\n",
      "635: loss=0.683, rw_mean=0.060, rw_bound=0.214, batch=229\n",
      "636: loss=0.684, rw_mean=0.070, rw_bound=0.349, batch=229\n",
      "637: loss=0.683, rw_mean=0.020, rw_bound=0.324, batch=230\n",
      "638: loss=0.681, rw_mean=0.010, rw_bound=0.178, batch=231\n",
      "639: loss=0.681, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "640: loss=0.681, rw_mean=0.020, rw_bound=0.387, batch=225\n",
      "641: loss=0.678, rw_mean=0.010, rw_bound=0.000, batch=226\n",
      "642: loss=0.679, rw_mean=0.070, rw_bound=0.298, batch=228\n",
      "643: loss=0.678, rw_mean=0.030, rw_bound=0.314, batch=228\n",
      "644: loss=0.678, rw_mean=0.060, rw_bound=0.357, batch=229\n",
      "645: loss=0.680, rw_mean=0.080, rw_bound=0.430, batch=211\n",
      "646: loss=0.679, rw_mean=0.040, rw_bound=0.000, batch=215\n",
      "647: loss=0.675, rw_mean=0.040, rw_bound=0.000, batch=219\n",
      "648: loss=0.676, rw_mean=0.010, rw_bound=0.000, batch=220\n",
      "649: loss=0.677, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "650: loss=0.678, rw_mean=0.050, rw_bound=0.122, batch=224\n",
      "651: loss=0.676, rw_mean=0.050, rw_bound=0.185, batch=226\n",
      "652: loss=0.675, rw_mean=0.030, rw_bound=0.217, batch=228\n",
      "653: loss=0.675, rw_mean=0.020, rw_bound=0.103, batch=229\n",
      "654: loss=0.675, rw_mean=0.010, rw_bound=0.092, batch=230\n",
      "655: loss=0.676, rw_mean=0.010, rw_bound=0.160, batch=231\n",
      "656: loss=0.676, rw_mean=0.040, rw_bound=0.229, batch=230\n",
      "657: loss=0.678, rw_mean=0.070, rw_bound=0.282, batch=230\n",
      "658: loss=0.676, rw_mean=0.010, rw_bound=0.220, batch=231\n",
      "659: loss=0.675, rw_mean=0.040, rw_bound=0.314, batch=227\n",
      "660: loss=0.677, rw_mean=0.050, rw_bound=0.342, batch=229\n",
      "661: loss=0.678, rw_mean=0.010, rw_bound=0.060, batch=230\n",
      "662: loss=0.674, rw_mean=0.020, rw_bound=0.243, batch=231\n",
      "663: loss=0.675, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "664: loss=0.677, rw_mean=0.030, rw_bound=0.349, batch=228\n",
      "665: loss=0.678, rw_mean=0.040, rw_bound=0.224, batch=229\n",
      "666: loss=0.676, rw_mean=0.030, rw_bound=0.213, batch=230\n",
      "667: loss=0.679, rw_mean=0.020, rw_bound=0.282, batch=230\n",
      "668: loss=0.678, rw_mean=0.030, rw_bound=0.365, batch=231\n",
      "669: loss=0.678, rw_mean=0.050, rw_bound=0.387, batch=226\n",
      "670: loss=0.679, rw_mean=0.050, rw_bound=0.298, batch=228\n",
      "671: loss=0.678, rw_mean=0.020, rw_bound=0.286, batch=229\n",
      "672: loss=0.677, rw_mean=0.010, rw_bound=0.126, batch=230\n",
      "673: loss=0.678, rw_mean=0.030, rw_bound=0.338, batch=231\n",
      "674: loss=0.680, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "675: loss=0.681, rw_mean=0.060, rw_bound=0.387, batch=230\n",
      "676: loss=0.684, rw_mean=0.010, rw_bound=0.301, batch=231\n",
      "677: loss=0.683, rw_mean=0.040, rw_bound=0.282, batch=231\n",
      "678: loss=0.683, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "679: loss=0.681, rw_mean=0.050, rw_bound=0.430, batch=227\n",
      "680: loss=0.682, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "681: loss=0.684, rw_mean=0.030, rw_bound=0.268, batch=229\n",
      "682: loss=0.681, rw_mean=0.120, rw_bound=0.424, batch=230\n",
      "683: loss=0.680, rw_mean=0.040, rw_bound=0.464, batch=231\n",
      "684: loss=0.680, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "685: loss=0.680, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "686: loss=0.658, rw_mean=0.050, rw_bound=0.478, batch=91\n",
      "687: loss=0.634, rw_mean=0.030, rw_bound=0.000, batch=94\n",
      "688: loss=0.638, rw_mean=0.030, rw_bound=0.000, batch=97\n",
      "689: loss=0.641, rw_mean=0.040, rw_bound=0.000, batch=101\n",
      "690: loss=0.630, rw_mean=0.030, rw_bound=0.000, batch=104\n",
      "691: loss=0.625, rw_mean=0.020, rw_bound=0.000, batch=106\n",
      "692: loss=0.619, rw_mean=0.030, rw_bound=0.000, batch=109\n",
      "693: loss=0.608, rw_mean=0.060, rw_bound=0.000, batch=115\n",
      "694: loss=0.614, rw_mean=0.060, rw_bound=0.000, batch=121\n",
      "695: loss=0.613, rw_mean=0.010, rw_bound=0.000, batch=122\n",
      "696: loss=0.617, rw_mean=0.040, rw_bound=0.000, batch=126\n",
      "697: loss=0.604, rw_mean=0.070, rw_bound=0.000, batch=133\n",
      "698: loss=0.594, rw_mean=0.080, rw_bound=0.000, batch=141\n",
      "699: loss=0.593, rw_mean=0.010, rw_bound=0.000, batch=142\n",
      "700: loss=0.591, rw_mean=0.010, rw_bound=0.000, batch=143\n",
      "701: loss=0.581, rw_mean=0.080, rw_bound=0.000, batch=151\n",
      "702: loss=0.577, rw_mean=0.040, rw_bound=0.000, batch=155\n",
      "703: loss=0.578, rw_mean=0.020, rw_bound=0.000, batch=157\n",
      "704: loss=0.573, rw_mean=0.060, rw_bound=0.000, batch=163\n",
      "705: loss=0.567, rw_mean=0.070, rw_bound=0.000, batch=170\n",
      "706: loss=0.565, rw_mean=0.030, rw_bound=0.000, batch=173\n",
      "707: loss=0.564, rw_mean=0.050, rw_bound=0.000, batch=178\n",
      "708: loss=0.562, rw_mean=0.040, rw_bound=0.000, batch=182\n",
      "709: loss=0.552, rw_mean=0.090, rw_bound=0.000, batch=191\n",
      "710: loss=0.551, rw_mean=0.040, rw_bound=0.000, batch=195\n",
      "711: loss=0.548, rw_mean=0.090, rw_bound=0.000, batch=204\n",
      "712: loss=0.547, rw_mean=0.050, rw_bound=0.000, batch=209\n",
      "713: loss=0.544, rw_mean=0.030, rw_bound=0.000, batch=212\n",
      "714: loss=0.545, rw_mean=0.030, rw_bound=0.000, batch=215\n",
      "715: loss=0.543, rw_mean=0.050, rw_bound=0.004, batch=220\n",
      "716: loss=0.541, rw_mean=0.050, rw_bound=0.020, batch=224\n",
      "717: loss=0.543, rw_mean=0.070, rw_bound=0.046, batch=227\n",
      "718: loss=0.547, rw_mean=0.050, rw_bound=0.057, batch=229\n",
      "719: loss=0.548, rw_mean=0.050, rw_bound=0.067, batch=230\n",
      "720: loss=0.546, rw_mean=0.020, rw_bound=0.084, batch=231\n",
      "721: loss=0.545, rw_mean=0.050, rw_bound=0.098, batch=231\n",
      "722: loss=0.562, rw_mean=0.060, rw_bound=0.135, batch=225\n",
      "723: loss=0.563, rw_mean=0.030, rw_bound=0.094, batch=227\n",
      "724: loss=0.565, rw_mean=0.060, rw_bound=0.167, batch=222\n",
      "725: loss=0.563, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "726: loss=0.562, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "727: loss=0.561, rw_mean=0.020, rw_bound=0.006, batch=227\n",
      "728: loss=0.562, rw_mean=0.040, rw_bound=0.107, batch=229\n",
      "729: loss=0.563, rw_mean=0.020, rw_bound=0.103, batch=230\n",
      "730: loss=0.559, rw_mean=0.030, rw_bound=0.170, batch=231\n",
      "731: loss=0.560, rw_mean=0.010, rw_bound=0.185, batch=224\n",
      "732: loss=0.557, rw_mean=0.050, rw_bound=0.134, batch=227\n",
      "733: loss=0.555, rw_mean=0.030, rw_bound=0.122, batch=229\n",
      "734: loss=0.558, rw_mean=0.040, rw_bound=0.135, batch=229\n",
      "735: loss=0.566, rw_mean=0.070, rw_bound=0.206, batch=224\n",
      "736: loss=0.566, rw_mean=0.060, rw_bound=0.177, batch=227\n",
      "737: loss=0.564, rw_mean=0.050, rw_bound=0.229, batch=218\n",
      "738: loss=0.566, rw_mean=0.030, rw_bound=0.000, batch=221\n",
      "739: loss=0.564, rw_mean=0.030, rw_bound=0.000, batch=224\n",
      "740: loss=0.563, rw_mean=0.040, rw_bound=0.078, batch=227\n",
      "741: loss=0.561, rw_mean=0.040, rw_bound=0.170, batch=229\n",
      "742: loss=0.565, rw_mean=0.030, rw_bound=0.194, batch=230\n",
      "743: loss=0.565, rw_mean=0.040, rw_bound=0.247, batch=231\n",
      "744: loss=0.576, rw_mean=0.050, rw_bound=0.254, batch=205\n",
      "745: loss=0.571, rw_mean=0.060, rw_bound=0.000, batch=211\n",
      "746: loss=0.567, rw_mean=0.050, rw_bound=0.000, batch=216\n",
      "747: loss=0.564, rw_mean=0.040, rw_bound=0.000, batch=220\n",
      "748: loss=0.562, rw_mean=0.020, rw_bound=0.000, batch=222\n",
      "749: loss=0.561, rw_mean=0.030, rw_bound=0.024, batch=225\n",
      "750: loss=0.565, rw_mean=0.050, rw_bound=0.122, batch=226\n",
      "751: loss=0.571, rw_mean=0.030, rw_bound=0.160, batch=228\n",
      "752: loss=0.567, rw_mean=0.020, rw_bound=0.185, batch=228\n",
      "753: loss=0.568, rw_mean=0.020, rw_bound=0.109, batch=229\n",
      "754: loss=0.568, rw_mean=0.040, rw_bound=0.229, batch=229\n",
      "755: loss=0.563, rw_mean=0.060, rw_bound=0.254, batch=228\n",
      "756: loss=0.567, rw_mean=0.030, rw_bound=0.282, batch=210\n",
      "757: loss=0.565, rw_mean=0.010, rw_bound=0.000, batch=211\n",
      "758: loss=0.563, rw_mean=0.020, rw_bound=0.000, batch=213\n",
      "759: loss=0.563, rw_mean=0.100, rw_bound=0.150, batch=218\n",
      "760: loss=0.565, rw_mean=0.110, rw_bound=0.211, batch=222\n",
      "761: loss=0.564, rw_mean=0.030, rw_bound=0.056, batch=225\n",
      "762: loss=0.563, rw_mean=0.000, rw_bound=0.000, batch=225\n",
      "763: loss=0.563, rw_mean=0.050, rw_bound=0.194, batch=227\n",
      "764: loss=0.563, rw_mean=0.060, rw_bound=0.254, batch=227\n",
      "765: loss=0.563, rw_mean=0.040, rw_bound=0.282, batch=224\n",
      "766: loss=0.566, rw_mean=0.060, rw_bound=0.254, batch=226\n",
      "767: loss=0.578, rw_mean=0.040, rw_bound=0.314, batch=206\n",
      "768: loss=0.574, rw_mean=0.050, rw_bound=0.000, batch=211\n",
      "769: loss=0.571, rw_mean=0.010, rw_bound=0.000, batch=212\n",
      "770: loss=0.566, rw_mean=0.050, rw_bound=0.000, batch=217\n",
      "771: loss=0.559, rw_mean=0.070, rw_bound=0.027, batch=222\n",
      "772: loss=0.573, rw_mean=0.070, rw_bound=0.113, batch=225\n",
      "773: loss=0.568, rw_mean=0.030, rw_bound=0.127, batch=227\n",
      "774: loss=0.571, rw_mean=0.060, rw_bound=0.150, batch=227\n",
      "775: loss=0.570, rw_mean=0.020, rw_bound=0.079, batch=229\n",
      "776: loss=0.569, rw_mean=0.030, rw_bound=0.119, batch=230\n",
      "777: loss=0.572, rw_mean=0.060, rw_bound=0.185, batch=229\n",
      "778: loss=0.573, rw_mean=0.040, rw_bound=0.182, batch=230\n",
      "779: loss=0.571, rw_mean=0.050, rw_bound=0.206, batch=230\n",
      "780: loss=0.572, rw_mean=0.050, rw_bound=0.229, batch=230\n",
      "781: loss=0.581, rw_mean=0.040, rw_bound=0.254, batch=227\n",
      "782: loss=0.578, rw_mean=0.030, rw_bound=0.185, batch=229\n",
      "783: loss=0.578, rw_mean=0.030, rw_bound=0.192, batch=230\n",
      "784: loss=0.578, rw_mean=0.030, rw_bound=0.205, batch=231\n",
      "785: loss=0.584, rw_mean=0.040, rw_bound=0.282, batch=228\n",
      "786: loss=0.587, rw_mean=0.040, rw_bound=0.217, batch=229\n",
      "787: loss=0.586, rw_mean=0.030, rw_bound=0.278, batch=230\n",
      "788: loss=0.587, rw_mean=0.030, rw_bound=0.314, batch=227\n",
      "789: loss=0.585, rw_mean=0.030, rw_bound=0.314, batch=228\n",
      "790: loss=0.585, rw_mean=0.080, rw_bound=0.156, batch=229\n",
      "791: loss=0.586, rw_mean=0.040, rw_bound=0.265, batch=230\n",
      "792: loss=0.592, rw_mean=0.140, rw_bound=0.349, batch=198\n",
      "793: loss=0.586, rw_mean=0.020, rw_bound=0.000, batch=200\n",
      "794: loss=0.585, rw_mean=0.020, rw_bound=0.000, batch=202\n",
      "795: loss=0.580, rw_mean=0.050, rw_bound=0.000, batch=207\n",
      "796: loss=0.579, rw_mean=0.040, rw_bound=0.000, batch=211\n",
      "797: loss=0.578, rw_mean=0.020, rw_bound=0.000, batch=213\n",
      "798: loss=0.568, rw_mean=0.060, rw_bound=0.035, batch=219\n",
      "799: loss=0.573, rw_mean=0.060, rw_bound=0.074, batch=223\n",
      "800: loss=0.573, rw_mean=0.000, rw_bound=0.000, batch=223\n",
      "801: loss=0.572, rw_mean=0.030, rw_bound=0.059, batch=226\n",
      "802: loss=0.572, rw_mean=0.040, rw_bound=0.115, batch=228\n",
      "803: loss=0.573, rw_mean=0.030, rw_bound=0.152, batch=229\n",
      "804: loss=0.572, rw_mean=0.030, rw_bound=0.132, batch=230\n",
      "805: loss=0.573, rw_mean=0.010, rw_bound=0.117, batch=231\n",
      "806: loss=0.577, rw_mean=0.070, rw_bound=0.206, batch=231\n",
      "807: loss=0.577, rw_mean=0.050, rw_bound=0.229, batch=229\n",
      "808: loss=0.577, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "809: loss=0.576, rw_mean=0.050, rw_bound=0.254, batch=225\n",
      "810: loss=0.572, rw_mean=0.050, rw_bound=0.282, batch=226\n",
      "811: loss=0.571, rw_mean=0.040, rw_bound=0.122, batch=227\n",
      "812: loss=0.571, rw_mean=0.040, rw_bound=0.277, batch=229\n",
      "813: loss=0.572, rw_mean=0.030, rw_bound=0.282, batch=228\n",
      "814: loss=0.584, rw_mean=0.060, rw_bound=0.314, batch=220\n",
      "815: loss=0.579, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "816: loss=0.581, rw_mean=0.040, rw_bound=0.048, batch=226\n",
      "817: loss=0.582, rw_mean=0.050, rw_bound=0.143, batch=228\n",
      "818: loss=0.580, rw_mean=0.040, rw_bound=0.167, batch=228\n",
      "819: loss=0.580, rw_mean=0.080, rw_bound=0.282, batch=228\n",
      "820: loss=0.580, rw_mean=0.050, rw_bound=0.237, batch=229\n",
      "821: loss=0.581, rw_mean=0.050, rw_bound=0.314, batch=227\n",
      "822: loss=0.580, rw_mean=0.040, rw_bound=0.240, batch=229\n",
      "823: loss=0.580, rw_mean=0.120, rw_bound=0.349, batch=223\n",
      "824: loss=0.577, rw_mean=0.090, rw_bound=0.235, batch=226\n",
      "825: loss=0.577, rw_mean=0.040, rw_bound=0.176, batch=228\n",
      "826: loss=0.575, rw_mean=0.060, rw_bound=0.254, batch=228\n",
      "827: loss=0.574, rw_mean=0.020, rw_bound=0.214, batch=229\n",
      "828: loss=0.574, rw_mean=0.020, rw_bound=0.309, batch=230\n",
      "829: loss=0.573, rw_mean=0.030, rw_bound=0.281, batch=231\n",
      "830: loss=0.577, rw_mean=0.040, rw_bound=0.349, batch=230\n",
      "831: loss=0.575, rw_mean=0.020, rw_bound=0.138, batch=231\n",
      "832: loss=0.609, rw_mean=0.020, rw_bound=0.387, batch=186\n",
      "833: loss=0.600, rw_mean=0.040, rw_bound=0.000, batch=190\n",
      "834: loss=0.595, rw_mean=0.040, rw_bound=0.000, batch=194\n",
      "835: loss=0.589, rw_mean=0.030, rw_bound=0.000, batch=197\n",
      "836: loss=0.593, rw_mean=0.030, rw_bound=0.000, batch=200\n",
      "837: loss=0.587, rw_mean=0.030, rw_bound=0.000, batch=203\n",
      "838: loss=0.589, rw_mean=0.030, rw_bound=0.000, batch=206\n",
      "839: loss=0.580, rw_mean=0.060, rw_bound=0.000, batch=212\n",
      "840: loss=0.577, rw_mean=0.020, rw_bound=0.000, batch=214\n",
      "841: loss=0.571, rw_mean=0.040, rw_bound=0.000, batch=218\n",
      "842: loss=0.569, rw_mean=0.070, rw_bound=0.045, batch=222\n",
      "843: loss=0.578, rw_mean=0.060, rw_bound=0.089, batch=224\n",
      "844: loss=0.577, rw_mean=0.070, rw_bound=0.134, batch=227\n",
      "845: loss=0.582, rw_mean=0.040, rw_bound=0.135, batch=228\n",
      "846: loss=0.583, rw_mean=0.050, rw_bound=0.167, batch=227\n",
      "847: loss=0.579, rw_mean=0.050, rw_bound=0.185, batch=226\n",
      "848: loss=0.577, rw_mean=0.040, rw_bound=0.186, batch=228\n",
      "849: loss=0.577, rw_mean=0.050, rw_bound=0.208, batch=229\n",
      "850: loss=0.588, rw_mean=0.040, rw_bound=0.229, batch=224\n",
      "851: loss=0.585, rw_mean=0.050, rw_bound=0.223, batch=227\n",
      "852: loss=0.581, rw_mean=0.040, rw_bound=0.192, batch=229\n",
      "853: loss=0.583, rw_mean=0.060, rw_bound=0.206, batch=229\n",
      "854: loss=0.581, rw_mean=0.010, rw_bound=0.092, batch=230\n",
      "855: loss=0.580, rw_mean=0.050, rw_bound=0.247, batch=231\n",
      "856: loss=0.579, rw_mean=0.060, rw_bound=0.254, batch=229\n",
      "857: loss=0.585, rw_mean=0.040, rw_bound=0.282, batch=225\n",
      "858: loss=0.593, rw_mean=0.070, rw_bound=0.314, batch=217\n",
      "859: loss=0.596, rw_mean=0.010, rw_bound=0.000, batch=218\n",
      "860: loss=0.588, rw_mean=0.080, rw_bound=0.171, batch=222\n",
      "861: loss=0.589, rw_mean=0.040, rw_bound=0.156, batch=225\n",
      "862: loss=0.586, rw_mean=0.020, rw_bound=0.041, batch=227\n",
      "863: loss=0.586, rw_mean=0.000, rw_bound=0.000, batch=227\n",
      "864: loss=0.591, rw_mean=0.080, rw_bound=0.297, batch=229\n",
      "865: loss=0.589, rw_mean=0.020, rw_bound=0.216, batch=230\n",
      "866: loss=0.596, rw_mean=0.070, rw_bound=0.349, batch=216\n",
      "867: loss=0.594, rw_mean=0.090, rw_bound=0.176, batch=221\n",
      "868: loss=0.592, rw_mean=0.050, rw_bound=0.185, batch=224\n",
      "869: loss=0.591, rw_mean=0.040, rw_bound=0.226, batch=227\n",
      "870: loss=0.592, rw_mean=0.020, rw_bound=0.183, batch=229\n",
      "871: loss=0.592, rw_mean=0.010, rw_bound=0.029, batch=230\n",
      "872: loss=0.590, rw_mean=0.030, rw_bound=0.116, batch=231\n",
      "873: loss=0.595, rw_mean=0.060, rw_bound=0.254, batch=230\n",
      "874: loss=0.595, rw_mean=0.010, rw_bound=0.198, batch=231\n",
      "875: loss=0.593, rw_mean=0.070, rw_bound=0.282, batch=231\n",
      "876: loss=0.593, rw_mean=0.010, rw_bound=0.031, batch=231\n",
      "877: loss=0.594, rw_mean=0.040, rw_bound=0.314, batch=230\n",
      "878: loss=0.594, rw_mean=0.080, rw_bound=0.320, batch=231\n",
      "879: loss=0.595, rw_mean=0.040, rw_bound=0.349, batch=228\n",
      "880: loss=0.593, rw_mean=0.060, rw_bound=0.353, batch=229\n",
      "881: loss=0.593, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "882: loss=0.606, rw_mean=0.050, rw_bound=0.387, batch=216\n",
      "883: loss=0.601, rw_mean=0.030, rw_bound=0.000, batch=219\n",
      "884: loss=0.599, rw_mean=0.070, rw_bound=0.239, batch=223\n",
      "885: loss=0.597, rw_mean=0.040, rw_bound=0.160, batch=226\n",
      "886: loss=0.597, rw_mean=0.040, rw_bound=0.196, batch=228\n",
      "887: loss=0.598, rw_mean=0.050, rw_bound=0.211, batch=229\n",
      "888: loss=0.601, rw_mean=0.030, rw_bound=0.225, batch=230\n",
      "889: loss=0.603, rw_mean=0.030, rw_bound=0.247, batch=231\n",
      "890: loss=0.607, rw_mean=0.060, rw_bound=0.254, batch=231\n",
      "891: loss=0.606, rw_mean=0.040, rw_bound=0.185, batch=231\n",
      "892: loss=0.610, rw_mean=0.040, rw_bound=0.282, batch=228\n",
      "893: loss=0.609, rw_mean=0.060, rw_bound=0.282, batch=228\n",
      "894: loss=0.611, rw_mean=0.050, rw_bound=0.314, batch=227\n",
      "895: loss=0.610, rw_mean=0.030, rw_bound=0.088, batch=229\n",
      "896: loss=0.611, rw_mean=0.060, rw_bound=0.328, batch=230\n",
      "897: loss=0.610, rw_mean=0.070, rw_bound=0.329, batch=231\n",
      "898: loss=0.610, rw_mean=0.060, rw_bound=0.349, batch=227\n",
      "899: loss=0.607, rw_mean=0.020, rw_bound=0.120, batch=229\n",
      "900: loss=0.615, rw_mean=0.040, rw_bound=0.164, batch=230\n",
      "901: loss=0.608, rw_mean=0.050, rw_bound=0.216, batch=231\n",
      "902: loss=0.608, rw_mean=0.040, rw_bound=0.229, batch=231\n",
      "903: loss=0.610, rw_mean=0.050, rw_bound=0.349, batch=230\n",
      "904: loss=0.609, rw_mean=0.020, rw_bound=0.252, batch=231\n",
      "905: loss=0.607, rw_mean=0.040, rw_bound=0.387, batch=222\n",
      "906: loss=0.600, rw_mean=0.070, rw_bound=0.191, batch=225\n",
      "907: loss=0.606, rw_mean=0.060, rw_bound=0.254, batch=226\n",
      "908: loss=0.605, rw_mean=0.040, rw_bound=0.316, batch=228\n",
      "909: loss=0.604, rw_mean=0.030, rw_bound=0.241, batch=229\n",
      "910: loss=0.604, rw_mean=0.030, rw_bound=0.278, batch=230\n",
      "911: loss=0.605, rw_mean=0.040, rw_bound=0.314, batch=230\n",
      "912: loss=0.606, rw_mean=0.020, rw_bound=0.289, batch=231\n",
      "913: loss=0.606, rw_mean=0.030, rw_bound=0.229, batch=231\n",
      "914: loss=0.606, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "915: loss=0.606, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "916: loss=0.605, rw_mean=0.060, rw_bound=0.387, batch=227\n",
      "917: loss=0.602, rw_mean=0.040, rw_bound=0.271, batch=229\n",
      "918: loss=0.602, rw_mean=0.030, rw_bound=0.206, batch=229\n",
      "919: loss=0.603, rw_mean=0.030, rw_bound=0.249, batch=230\n",
      "920: loss=0.603, rw_mean=0.050, rw_bound=0.265, batch=231\n",
      "921: loss=0.605, rw_mean=0.070, rw_bound=0.349, batch=229\n",
      "922: loss=0.606, rw_mean=0.030, rw_bound=0.179, batch=230\n",
      "923: loss=0.605, rw_mean=0.060, rw_bound=0.314, batch=229\n",
      "924: loss=0.606, rw_mean=0.030, rw_bound=0.296, batch=230\n",
      "925: loss=0.607, rw_mean=0.020, rw_bound=0.289, batch=231\n",
      "926: loss=0.606, rw_mean=0.060, rw_bound=0.349, batch=231\n",
      "927: loss=0.614, rw_mean=0.030, rw_bound=0.430, batch=166\n",
      "928: loss=0.605, rw_mean=0.030, rw_bound=0.000, batch=169\n",
      "929: loss=0.589, rw_mean=0.050, rw_bound=0.000, batch=174\n",
      "930: loss=0.575, rw_mean=0.060, rw_bound=0.000, batch=180\n",
      "931: loss=0.567, rw_mean=0.080, rw_bound=0.000, batch=188\n",
      "932: loss=0.558, rw_mean=0.060, rw_bound=0.000, batch=194\n",
      "933: loss=0.560, rw_mean=0.040, rw_bound=0.000, batch=198\n",
      "934: loss=0.555, rw_mean=0.040, rw_bound=0.000, batch=202\n",
      "935: loss=0.555, rw_mean=0.010, rw_bound=0.000, batch=203\n",
      "936: loss=0.556, rw_mean=0.030, rw_bound=0.000, batch=206\n",
      "937: loss=0.549, rw_mean=0.080, rw_bound=0.008, batch=214\n",
      "938: loss=0.543, rw_mean=0.030, rw_bound=0.000, batch=217\n",
      "939: loss=0.542, rw_mean=0.020, rw_bound=0.000, batch=219\n",
      "940: loss=0.540, rw_mean=0.090, rw_bound=0.051, batch=223\n",
      "941: loss=0.543, rw_mean=0.070, rw_bound=0.082, batch=226\n",
      "942: loss=0.542, rw_mean=0.040, rw_bound=0.098, batch=227\n",
      "943: loss=0.545, rw_mean=0.040, rw_bound=0.109, batch=226\n",
      "944: loss=0.552, rw_mean=0.040, rw_bound=0.122, batch=226\n",
      "945: loss=0.547, rw_mean=0.020, rw_bound=0.068, batch=228\n",
      "946: loss=0.556, rw_mean=0.030, rw_bound=0.135, batch=227\n",
      "947: loss=0.555, rw_mean=0.060, rw_bound=0.150, batch=228\n",
      "948: loss=0.554, rw_mean=0.040, rw_bound=0.138, batch=229\n",
      "949: loss=0.551, rw_mean=0.040, rw_bound=0.174, batch=230\n",
      "950: loss=0.553, rw_mean=0.070, rw_bound=0.200, batch=231\n",
      "951: loss=0.561, rw_mean=0.030, rw_bound=0.206, batch=230\n",
      "952: loss=0.563, rw_mean=0.040, rw_bound=0.229, batch=227\n",
      "953: loss=0.561, rw_mean=0.030, rw_bound=0.072, batch=228\n",
      "954: loss=0.561, rw_mean=0.020, rw_bound=0.085, batch=229\n",
      "955: loss=0.570, rw_mean=0.030, rw_bound=0.183, batch=230\n",
      "956: loss=0.579, rw_mean=0.020, rw_bound=0.254, batch=223\n",
      "957: loss=0.578, rw_mean=0.030, rw_bound=0.137, batch=226\n",
      "958: loss=0.577, rw_mean=0.040, rw_bound=0.229, batch=227\n",
      "959: loss=0.577, rw_mean=0.060, rw_bound=0.272, batch=229\n",
      "960: loss=0.578, rw_mean=0.040, rw_bound=0.250, batch=230\n",
      "961: loss=0.578, rw_mean=0.010, rw_bound=0.198, batch=231\n",
      "962: loss=0.582, rw_mean=0.070, rw_bound=0.282, batch=220\n",
      "963: loss=0.582, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "964: loss=0.573, rw_mean=0.070, rw_bound=0.185, batch=225\n",
      "965: loss=0.573, rw_mean=0.060, rw_bound=0.260, batch=227\n",
      "966: loss=0.571, rw_mean=0.040, rw_bound=0.267, batch=229\n",
      "967: loss=0.583, rw_mean=0.070, rw_bound=0.314, batch=220\n",
      "968: loss=0.579, rw_mean=0.080, rw_bound=0.338, batch=224\n",
      "969: loss=0.577, rw_mean=0.020, rw_bound=0.000, batch=226\n",
      "970: loss=0.576, rw_mean=0.040, rw_bound=0.124, batch=228\n",
      "971: loss=0.585, rw_mean=0.060, rw_bound=0.349, batch=217\n",
      "972: loss=0.584, rw_mean=0.030, rw_bound=0.000, batch=220\n",
      "973: loss=0.583, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "974: loss=0.580, rw_mean=0.050, rw_bound=0.206, batch=224\n",
      "975: loss=0.583, rw_mean=0.060, rw_bound=0.182, batch=227\n",
      "976: loss=0.581, rw_mean=0.090, rw_bound=0.282, batch=228\n",
      "977: loss=0.587, rw_mean=0.040, rw_bound=0.317, batch=229\n",
      "978: loss=0.586, rw_mean=0.050, rw_bound=0.249, batch=230\n",
      "979: loss=0.585, rw_mean=0.040, rw_bound=0.288, batch=231\n",
      "980: loss=0.585, rw_mean=0.040, rw_bound=0.349, batch=227\n",
      "981: loss=0.582, rw_mean=0.070, rw_bound=0.277, batch=229\n",
      "982: loss=0.581, rw_mean=0.040, rw_bound=0.225, batch=230\n",
      "983: loss=0.586, rw_mean=0.070, rw_bound=0.304, batch=231\n",
      "984: loss=0.584, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "985: loss=0.585, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "986: loss=0.597, rw_mean=0.030, rw_bound=0.387, batch=206\n",
      "987: loss=0.587, rw_mean=0.050, rw_bound=0.000, batch=211\n",
      "988: loss=0.586, rw_mean=0.040, rw_bound=0.000, batch=215\n",
      "989: loss=0.585, rw_mean=0.080, rw_bound=0.106, batch=220\n",
      "990: loss=0.581, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "991: loss=0.580, rw_mean=0.050, rw_bound=0.125, batch=226\n",
      "992: loss=0.577, rw_mean=0.030, rw_bound=0.099, batch=228\n",
      "993: loss=0.573, rw_mean=0.050, rw_bound=0.135, batch=228\n",
      "994: loss=0.575, rw_mean=0.060, rw_bound=0.206, batch=228\n",
      "995: loss=0.582, rw_mean=0.060, rw_bound=0.282, batch=226\n",
      "996: loss=0.580, rw_mean=0.090, rw_bound=0.298, batch=228\n",
      "997: loss=0.582, rw_mean=0.070, rw_bound=0.198, batch=229\n",
      "998: loss=0.581, rw_mean=0.050, rw_bound=0.278, batch=230\n",
      "999: loss=0.581, rw_mean=0.000, rw_bound=0.000, batch=230\n",
      "1000: loss=0.582, rw_mean=0.030, rw_bound=0.296, batch=231\n",
      "1001: loss=0.582, rw_mean=0.030, rw_bound=0.282, batch=231\n",
      "1002: loss=0.584, rw_mean=0.080, rw_bound=0.314, batch=230\n",
      "1003: loss=0.584, rw_mean=0.060, rw_bound=0.338, batch=231\n",
      "1004: loss=0.584, rw_mean=0.020, rw_bound=0.206, batch=231\n",
      "1005: loss=0.588, rw_mean=0.060, rw_bound=0.349, batch=224\n",
      "1006: loss=0.588, rw_mean=0.060, rw_bound=0.280, batch=227\n",
      "1007: loss=0.589, rw_mean=0.030, rw_bound=0.193, batch=229\n",
      "1008: loss=0.586, rw_mean=0.050, rw_bound=0.265, batch=230\n",
      "1009: loss=0.588, rw_mean=0.050, rw_bound=0.282, batch=230\n",
      "1010: loss=0.586, rw_mean=0.050, rw_bound=0.281, batch=231\n",
      "1011: loss=0.590, rw_mean=0.040, rw_bound=0.349, batch=230\n",
      "1012: loss=0.589, rw_mean=0.010, rw_bound=0.271, batch=231\n",
      "1013: loss=0.589, rw_mean=0.020, rw_bound=0.206, batch=231\n",
      "1014: loss=0.589, rw_mean=0.030, rw_bound=0.282, batch=231\n",
      "1015: loss=0.589, rw_mean=0.010, rw_bound=0.206, batch=231\n",
      "1016: loss=0.589, rw_mean=0.050, rw_bound=0.387, batch=225\n",
      "1017: loss=0.591, rw_mean=0.040, rw_bound=0.321, batch=227\n",
      "1018: loss=0.594, rw_mean=0.050, rw_bound=0.320, batch=229\n",
      "1019: loss=0.593, rw_mean=0.020, rw_bound=0.265, batch=230\n",
      "1020: loss=0.594, rw_mean=0.060, rw_bound=0.338, batch=231\n",
      "1021: loss=0.592, rw_mean=0.010, rw_bound=0.349, batch=230\n",
      "1022: loss=0.593, rw_mean=0.010, rw_bound=0.271, batch=231\n",
      "1023: loss=0.594, rw_mean=0.060, rw_bound=0.282, batch=231\n",
      "1024: loss=0.594, rw_mean=0.040, rw_bound=0.387, batch=230\n",
      "1025: loss=0.592, rw_mean=0.040, rw_bound=0.306, batch=231\n",
      "1026: loss=0.592, rw_mean=0.070, rw_bound=0.314, batch=231\n",
      "1027: loss=0.592, rw_mean=0.010, rw_bound=0.254, batch=231\n",
      "1028: loss=0.592, rw_mean=0.010, rw_bound=0.254, batch=231\n",
      "1029: loss=0.593, rw_mean=0.070, rw_bound=0.349, batch=231\n",
      "1030: loss=0.594, rw_mean=0.070, rw_bound=0.387, batch=231\n",
      "1031: loss=0.607, rw_mean=0.050, rw_bound=0.430, batch=204\n",
      "1032: loss=0.599, rw_mean=0.050, rw_bound=0.000, batch=209\n",
      "1033: loss=0.598, rw_mean=0.020, rw_bound=0.000, batch=211\n",
      "1034: loss=0.593, rw_mean=0.050, rw_bound=0.000, batch=216\n",
      "1035: loss=0.588, rw_mean=0.030, rw_bound=0.000, batch=219\n",
      "1036: loss=0.585, rw_mean=0.060, rw_bound=0.140, batch=223\n",
      "1037: loss=0.580, rw_mean=0.050, rw_bound=0.190, batch=226\n",
      "1038: loss=0.581, rw_mean=0.070, rw_bound=0.217, batch=228\n",
      "1039: loss=0.588, rw_mean=0.060, rw_bound=0.254, batch=227\n",
      "1040: loss=0.588, rw_mean=0.020, rw_bound=0.088, batch=229\n",
      "1041: loss=0.593, rw_mean=0.060, rw_bound=0.282, batch=226\n",
      "1042: loss=0.598, rw_mean=0.040, rw_bound=0.314, batch=221\n",
      "1043: loss=0.594, rw_mean=0.040, rw_bound=0.109, batch=224\n",
      "1044: loss=0.593, rw_mean=0.010, rw_bound=0.000, batch=225\n",
      "1045: loss=0.592, rw_mean=0.060, rw_bound=0.189, batch=227\n",
      "1046: loss=0.588, rw_mean=0.020, rw_bound=0.042, batch=229\n",
      "1047: loss=0.595, rw_mean=0.050, rw_bound=0.136, batch=230\n",
      "1048: loss=0.592, rw_mean=0.080, rw_bound=0.304, batch=231\n",
      "1049: loss=0.597, rw_mean=0.060, rw_bound=0.314, batch=231\n",
      "1050: loss=0.598, rw_mean=0.040, rw_bound=0.349, batch=229\n",
      "1051: loss=0.596, rw_mean=0.020, rw_bound=0.295, batch=230\n",
      "1052: loss=0.598, rw_mean=0.070, rw_bound=0.349, batch=229\n",
      "1053: loss=0.604, rw_mean=0.080, rw_bound=0.387, batch=222\n",
      "1054: loss=0.602, rw_mean=0.050, rw_bound=0.238, batch=225\n",
      "1055: loss=0.601, rw_mean=0.020, rw_bound=0.063, batch=227\n",
      "1056: loss=0.601, rw_mean=0.100, rw_bound=0.349, batch=227\n",
      "1057: loss=0.596, rw_mean=0.030, rw_bound=0.094, batch=229\n",
      "1058: loss=0.599, rw_mean=0.050, rw_bound=0.229, batch=229\n",
      "1059: loss=0.603, rw_mean=0.050, rw_bound=0.282, batch=229\n",
      "1060: loss=0.602, rw_mean=0.040, rw_bound=0.225, batch=230\n",
      "1061: loss=0.602, rw_mean=0.040, rw_bound=0.274, batch=231\n",
      "1062: loss=0.602, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "1063: loss=0.602, rw_mean=0.070, rw_bound=0.314, batch=230\n",
      "1064: loss=0.601, rw_mean=0.020, rw_bound=0.293, batch=231\n",
      "1065: loss=0.601, rw_mean=0.010, rw_bound=0.038, batch=231\n",
      "1066: loss=0.600, rw_mean=0.030, rw_bound=0.387, batch=227\n",
      "1067: loss=0.599, rw_mean=0.040, rw_bound=0.256, batch=229\n",
      "1068: loss=0.602, rw_mean=0.030, rw_bound=0.295, batch=230\n",
      "1069: loss=0.601, rw_mean=0.050, rw_bound=0.296, batch=231\n",
      "1070: loss=0.599, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "1071: loss=0.600, rw_mean=0.040, rw_bound=0.430, batch=220\n",
      "1072: loss=0.592, rw_mean=0.040, rw_bound=0.095, batch=224\n",
      "1073: loss=0.599, rw_mean=0.040, rw_bound=0.135, batch=225\n",
      "1074: loss=0.599, rw_mean=0.040, rw_bound=0.189, batch=227\n",
      "1075: loss=0.600, rw_mean=0.050, rw_bound=0.224, batch=229\n",
      "1076: loss=0.596, rw_mean=0.010, rw_bound=0.023, batch=230\n",
      "1077: loss=0.604, rw_mean=0.090, rw_bound=0.274, batch=231\n",
      "1078: loss=0.600, rw_mean=0.080, rw_bound=0.314, batch=230\n",
      "1079: loss=0.600, rw_mean=0.050, rw_bound=0.349, batch=230\n",
      "1080: loss=0.597, rw_mean=0.010, rw_bound=0.244, batch=231\n",
      "1081: loss=0.601, rw_mean=0.040, rw_bound=0.387, batch=229\n",
      "1082: loss=0.601, rw_mean=0.040, rw_bound=0.405, batch=230\n",
      "1083: loss=0.600, rw_mean=0.040, rw_bound=0.386, batch=231\n",
      "1084: loss=0.599, rw_mean=0.030, rw_bound=0.430, batch=226\n",
      "1085: loss=0.598, rw_mean=0.040, rw_bound=0.289, batch=228\n",
      "1086: loss=0.601, rw_mean=0.050, rw_bound=0.353, batch=229\n",
      "1087: loss=0.600, rw_mean=0.050, rw_bound=0.364, batch=230\n",
      "1088: loss=0.599, rw_mean=0.050, rw_bound=0.387, batch=229\n",
      "1089: loss=0.600, rw_mean=0.050, rw_bound=0.343, batch=230\n",
      "1090: loss=0.600, rw_mean=0.040, rw_bound=0.321, batch=231\n",
      "1091: loss=0.599, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1092: loss=0.599, rw_mean=0.020, rw_bound=0.282, batch=231\n",
      "1093: loss=0.600, rw_mean=0.030, rw_bound=0.430, batch=229\n",
      "1094: loss=0.600, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "1095: loss=0.600, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "1096: loss=0.600, rw_mean=0.050, rw_bound=0.430, batch=229\n",
      "1097: loss=0.599, rw_mean=0.010, rw_bound=0.139, batch=230\n",
      "1098: loss=0.600, rw_mean=0.040, rw_bound=0.349, batch=230\n",
      "1099: loss=0.598, rw_mean=0.020, rw_bound=0.418, batch=231\n",
      "1100: loss=0.600, rw_mean=0.060, rw_bound=0.430, batch=230\n",
      "1101: loss=0.601, rw_mean=0.070, rw_bound=0.418, batch=231\n",
      "1102: loss=0.599, rw_mean=0.050, rw_bound=0.430, batch=231\n",
      "1103: loss=0.599, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1104: loss=0.599, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "1105: loss=0.609, rw_mean=0.060, rw_bound=0.478, batch=147\n",
      "1106: loss=0.611, rw_mean=0.060, rw_bound=0.000, batch=153\n",
      "1107: loss=0.581, rw_mean=0.070, rw_bound=0.000, batch=160\n",
      "1108: loss=0.576, rw_mean=0.040, rw_bound=0.000, batch=164\n",
      "1109: loss=0.565, rw_mean=0.050, rw_bound=0.000, batch=169\n",
      "1110: loss=0.563, rw_mean=0.030, rw_bound=0.000, batch=172\n",
      "1111: loss=0.559, rw_mean=0.030, rw_bound=0.000, batch=175\n",
      "1112: loss=0.559, rw_mean=0.070, rw_bound=0.000, batch=182\n",
      "1113: loss=0.559, rw_mean=0.010, rw_bound=0.000, batch=183\n",
      "1114: loss=0.550, rw_mean=0.060, rw_bound=0.000, batch=189\n",
      "1115: loss=0.551, rw_mean=0.030, rw_bound=0.000, batch=192\n",
      "1116: loss=0.545, rw_mean=0.060, rw_bound=0.000, batch=198\n",
      "1117: loss=0.542, rw_mean=0.020, rw_bound=0.000, batch=200\n",
      "1118: loss=0.539, rw_mean=0.010, rw_bound=0.000, batch=201\n",
      "1119: loss=0.533, rw_mean=0.060, rw_bound=0.000, batch=207\n",
      "1120: loss=0.536, rw_mean=0.030, rw_bound=0.000, batch=210\n",
      "1121: loss=0.534, rw_mean=0.060, rw_bound=0.000, batch=216\n",
      "1122: loss=0.531, rw_mean=0.020, rw_bound=0.000, batch=218\n",
      "1123: loss=0.533, rw_mean=0.040, rw_bound=0.001, batch=222\n",
      "1124: loss=0.533, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "1125: loss=0.529, rw_mean=0.030, rw_bound=0.009, batch=227\n",
      "1126: loss=0.540, rw_mean=0.060, rw_bound=0.031, batch=228\n",
      "1127: loss=0.545, rw_mean=0.050, rw_bound=0.065, batch=229\n",
      "1128: loss=0.539, rw_mean=0.080, rw_bound=0.098, batch=229\n",
      "1129: loss=0.550, rw_mean=0.030, rw_bound=0.109, batch=228\n",
      "1130: loss=0.562, rw_mean=0.060, rw_bound=0.150, batch=228\n",
      "1131: loss=0.574, rw_mean=0.050, rw_bound=0.185, batch=224\n",
      "1132: loss=0.572, rw_mean=0.060, rw_bound=0.204, batch=227\n",
      "1133: loss=0.570, rw_mean=0.070, rw_bound=0.206, batch=228\n",
      "1134: loss=0.568, rw_mean=0.010, rw_bound=0.023, batch=229\n",
      "1135: loss=0.569, rw_mean=0.040, rw_bound=0.229, batch=219\n",
      "1136: loss=0.566, rw_mean=0.040, rw_bound=0.074, batch=223\n",
      "1137: loss=0.566, rw_mean=0.050, rw_bound=0.160, batch=226\n",
      "1138: loss=0.565, rw_mean=0.050, rw_bound=0.185, batch=227\n",
      "1139: loss=0.563, rw_mean=0.040, rw_bound=0.182, batch=229\n",
      "1140: loss=0.562, rw_mean=0.030, rw_bound=0.194, batch=230\n",
      "1141: loss=0.564, rw_mean=0.040, rw_bound=0.200, batch=231\n",
      "1142: loss=0.569, rw_mean=0.050, rw_bound=0.254, batch=225\n",
      "1143: loss=0.566, rw_mean=0.050, rw_bound=0.189, batch=227\n",
      "1144: loss=0.568, rw_mean=0.040, rw_bound=0.267, batch=229\n",
      "1145: loss=0.573, rw_mean=0.100, rw_bound=0.282, batch=214\n",
      "1146: loss=0.571, rw_mean=0.060, rw_bound=0.072, batch=220\n",
      "1147: loss=0.569, rw_mean=0.060, rw_bound=0.124, batch=224\n",
      "1148: loss=0.566, rw_mean=0.040, rw_bound=0.219, batch=227\n",
      "1149: loss=0.565, rw_mean=0.040, rw_bound=0.197, batch=229\n",
      "1150: loss=0.567, rw_mean=0.080, rw_bound=0.254, batch=228\n",
      "1151: loss=0.569, rw_mean=0.050, rw_bound=0.282, batch=228\n",
      "1152: loss=0.580, rw_mean=0.020, rw_bound=0.314, batch=211\n",
      "1153: loss=0.578, rw_mean=0.020, rw_bound=0.000, batch=213\n",
      "1154: loss=0.578, rw_mean=0.010, rw_bound=0.000, batch=214\n",
      "1155: loss=0.572, rw_mean=0.080, rw_bound=0.146, batch=220\n",
      "1156: loss=0.573, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "1157: loss=0.572, rw_mean=0.030, rw_bound=0.048, batch=226\n",
      "1158: loss=0.569, rw_mean=0.030, rw_bound=0.059, batch=228\n",
      "1159: loss=0.567, rw_mean=0.020, rw_bound=0.031, batch=229\n",
      "1160: loss=0.562, rw_mean=0.030, rw_bound=0.102, batch=230\n",
      "1161: loss=0.570, rw_mean=0.080, rw_bound=0.175, batch=231\n",
      "1162: loss=0.580, rw_mean=0.040, rw_bound=0.206, batch=230\n",
      "1163: loss=0.578, rw_mean=0.030, rw_bound=0.197, batch=231\n",
      "1164: loss=0.572, rw_mean=0.050, rw_bound=0.254, batch=229\n",
      "1165: loss=0.581, rw_mean=0.050, rw_bound=0.282, batch=227\n",
      "1166: loss=0.582, rw_mean=0.050, rw_bound=0.281, batch=229\n",
      "1167: loss=0.581, rw_mean=0.040, rw_bound=0.295, batch=230\n",
      "1168: loss=0.580, rw_mean=0.040, rw_bound=0.314, batch=229\n",
      "1169: loss=0.594, rw_mean=0.070, rw_bound=0.349, batch=213\n",
      "1170: loss=0.584, rw_mean=0.060, rw_bound=0.043, batch=219\n",
      "1171: loss=0.591, rw_mean=0.060, rw_bound=0.127, batch=223\n",
      "1172: loss=0.585, rw_mean=0.020, rw_bound=0.000, batch=225\n",
      "1173: loss=0.587, rw_mean=0.040, rw_bound=0.106, batch=227\n",
      "1174: loss=0.588, rw_mean=0.040, rw_bound=0.163, batch=229\n",
      "1175: loss=0.583, rw_mean=0.050, rw_bound=0.182, batch=230\n",
      "1176: loss=0.581, rw_mean=0.030, rw_bound=0.222, batch=231\n",
      "1177: loss=0.585, rw_mean=0.030, rw_bound=0.229, batch=230\n",
      "1178: loss=0.585, rw_mean=0.070, rw_bound=0.304, batch=231\n",
      "1179: loss=0.585, rw_mean=0.000, rw_bound=0.000, batch=231\n",
      "1180: loss=0.587, rw_mean=0.070, rw_bound=0.314, batch=230\n",
      "1181: loss=0.588, rw_mean=0.030, rw_bound=0.349, batch=230\n",
      "1182: loss=0.588, rw_mean=0.050, rw_bound=0.282, batch=230\n",
      "1183: loss=0.586, rw_mean=0.040, rw_bound=0.338, batch=231\n",
      "1184: loss=0.586, rw_mean=0.040, rw_bound=0.229, batch=231\n",
      "1185: loss=0.588, rw_mean=0.120, rw_bound=0.387, batch=212\n",
      "1186: loss=0.585, rw_mean=0.040, rw_bound=0.000, batch=216\n",
      "1187: loss=0.583, rw_mean=0.030, rw_bound=0.000, batch=219\n",
      "1188: loss=0.583, rw_mean=0.050, rw_bound=0.077, batch=223\n",
      "1189: loss=0.579, rw_mean=0.020, rw_bound=0.000, batch=225\n",
      "1190: loss=0.577, rw_mean=0.030, rw_bound=0.042, batch=227\n",
      "1191: loss=0.578, rw_mean=0.070, rw_bound=0.202, batch=229\n",
      "1192: loss=0.584, rw_mean=0.060, rw_bound=0.265, batch=230\n",
      "1193: loss=0.584, rw_mean=0.060, rw_bound=0.282, batch=229\n",
      "1194: loss=0.584, rw_mean=0.020, rw_bound=0.067, batch=230\n",
      "1195: loss=0.584, rw_mean=0.030, rw_bound=0.288, batch=231\n",
      "1196: loss=0.588, rw_mean=0.030, rw_bound=0.314, batch=225\n",
      "1197: loss=0.588, rw_mean=0.020, rw_bound=0.022, batch=227\n",
      "1198: loss=0.581, rw_mean=0.060, rw_bound=0.272, batch=229\n",
      "1199: loss=0.586, rw_mean=0.070, rw_bound=0.282, batch=228\n",
      "1200: loss=0.589, rw_mean=0.050, rw_bound=0.286, batch=229\n",
      "1201: loss=0.590, rw_mean=0.060, rw_bound=0.349, batch=226\n",
      "1202: loss=0.592, rw_mean=0.040, rw_bound=0.229, batch=227\n",
      "1203: loss=0.589, rw_mean=0.040, rw_bound=0.249, batch=229\n",
      "1204: loss=0.592, rw_mean=0.020, rw_bound=0.175, batch=230\n",
      "1205: loss=0.592, rw_mean=0.040, rw_bound=0.274, batch=231\n",
      "1206: loss=0.587, rw_mean=0.050, rw_bound=0.282, batch=231\n",
      "1207: loss=0.591, rw_mean=0.020, rw_bound=0.314, batch=230\n",
      "1208: loss=0.591, rw_mean=0.040, rw_bound=0.282, batch=230\n",
      "1209: loss=0.591, rw_mean=0.040, rw_bound=0.338, batch=231\n",
      "1210: loss=0.589, rw_mean=0.070, rw_bound=0.349, batch=231\n",
      "1211: loss=0.589, rw_mean=0.020, rw_bound=0.282, batch=231\n",
      "1212: loss=0.592, rw_mean=0.050, rw_bound=0.387, batch=229\n",
      "1213: loss=0.600, rw_mean=0.070, rw_bound=0.430, batch=200\n",
      "1214: loss=0.594, rw_mean=0.020, rw_bound=0.000, batch=202\n",
      "1215: loss=0.593, rw_mean=0.040, rw_bound=0.000, batch=206\n",
      "1216: loss=0.582, rw_mean=0.040, rw_bound=0.000, batch=210\n",
      "1217: loss=0.579, rw_mean=0.070, rw_bound=0.056, batch=217\n",
      "1218: loss=0.580, rw_mean=0.070, rw_bound=0.144, batch=222\n",
      "1219: loss=0.577, rw_mean=0.040, rw_bound=0.041, batch=225\n",
      "1220: loss=0.580, rw_mean=0.030, rw_bound=0.075, batch=227\n",
      "1221: loss=0.577, rw_mean=0.050, rw_bound=0.163, batch=229\n",
      "1222: loss=0.576, rw_mean=0.050, rw_bound=0.174, batch=230\n",
      "1223: loss=0.575, rw_mean=0.020, rw_bound=0.166, batch=231\n",
      "1224: loss=0.583, rw_mean=0.040, rw_bound=0.185, batch=230\n",
      "1225: loss=0.583, rw_mean=0.060, rw_bound=0.222, batch=231\n",
      "1226: loss=0.594, rw_mean=0.090, rw_bound=0.254, batch=228\n",
      "1227: loss=0.592, rw_mean=0.060, rw_bound=0.286, batch=229\n",
      "1228: loss=0.590, rw_mean=0.020, rw_bound=0.119, batch=230\n",
      "1229: loss=0.591, rw_mean=0.040, rw_bound=0.274, batch=231\n",
      "1230: loss=0.591, rw_mean=0.060, rw_bound=0.314, batch=228\n",
      "1231: loss=0.591, rw_mean=0.090, rw_bound=0.349, batch=223\n",
      "1232: loss=0.588, rw_mean=0.050, rw_bound=0.282, batch=225\n",
      "1233: loss=0.588, rw_mean=0.020, rw_bound=0.056, batch=227\n",
      "1234: loss=0.591, rw_mean=0.050, rw_bound=0.282, batch=228\n",
      "1235: loss=0.592, rw_mean=0.060, rw_bound=0.317, batch=229\n",
      "1236: loss=0.590, rw_mean=0.030, rw_bound=0.068, batch=230\n",
      "1237: loss=0.591, rw_mean=0.060, rw_bound=0.259, batch=231\n",
      "1238: loss=0.591, rw_mean=0.020, rw_bound=0.254, batch=231\n",
      "1239: loss=0.594, rw_mean=0.040, rw_bound=0.282, batch=230\n",
      "1240: loss=0.594, rw_mean=0.030, rw_bound=0.274, batch=231\n",
      "1241: loss=0.593, rw_mean=0.050, rw_bound=0.349, batch=229\n",
      "1242: loss=0.597, rw_mean=0.040, rw_bound=0.387, batch=220\n",
      "1243: loss=0.601, rw_mean=0.070, rw_bound=0.338, batch=224\n",
      "1244: loss=0.598, rw_mean=0.040, rw_bound=0.158, batch=227\n",
      "1245: loss=0.593, rw_mean=0.050, rw_bound=0.198, batch=229\n",
      "1246: loss=0.597, rw_mean=0.050, rw_bound=0.225, batch=230\n",
      "1247: loss=0.597, rw_mean=0.030, rw_bound=0.254, batch=230\n",
      "1248: loss=0.597, rw_mean=0.040, rw_bound=0.338, batch=231\n",
      "1249: loss=0.597, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "1250: loss=0.596, rw_mean=0.050, rw_bound=0.349, batch=229\n",
      "1251: loss=0.595, rw_mean=0.020, rw_bound=0.179, batch=230\n",
      "1252: loss=0.597, rw_mean=0.060, rw_bound=0.356, batch=231\n",
      "1253: loss=0.597, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "1254: loss=0.597, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1255: loss=0.600, rw_mean=0.040, rw_bound=0.387, batch=227\n",
      "1256: loss=0.599, rw_mean=0.050, rw_bound=0.245, batch=229\n",
      "1257: loss=0.599, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "1258: loss=0.602, rw_mean=0.090, rw_bound=0.405, batch=230\n",
      "1259: loss=0.600, rw_mean=0.030, rw_bound=0.376, batch=231\n",
      "1260: loss=0.603, rw_mean=0.030, rw_bound=0.387, batch=231\n",
      "1261: loss=0.604, rw_mean=0.030, rw_bound=0.430, batch=222\n",
      "1262: loss=0.602, rw_mean=0.050, rw_bound=0.179, batch=225\n",
      "1263: loss=0.603, rw_mean=0.020, rw_bound=0.041, batch=227\n",
      "1264: loss=0.601, rw_mean=0.080, rw_bound=0.229, batch=228\n",
      "1265: loss=0.601, rw_mean=0.070, rw_bound=0.317, batch=229\n",
      "1266: loss=0.599, rw_mean=0.060, rw_bound=0.349, batch=229\n",
      "1267: loss=0.601, rw_mean=0.020, rw_bound=0.225, batch=230\n",
      "1268: loss=0.596, rw_mean=0.050, rw_bound=0.274, batch=231\n",
      "1269: loss=0.601, rw_mean=0.050, rw_bound=0.387, batch=229\n",
      "1270: loss=0.600, rw_mean=0.010, rw_bound=0.155, batch=230\n",
      "1271: loss=0.601, rw_mean=0.070, rw_bound=0.387, batch=229\n",
      "1272: loss=0.599, rw_mean=0.020, rw_bound=0.175, batch=230\n",
      "1273: loss=0.597, rw_mean=0.040, rw_bound=0.329, batch=231\n",
      "1274: loss=0.597, rw_mean=0.010, rw_bound=0.109, batch=231\n",
      "1275: loss=0.597, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1276: loss=0.601, rw_mean=0.050, rw_bound=0.387, batch=230\n",
      "1277: loss=0.599, rw_mean=0.040, rw_bound=0.259, batch=231\n",
      "1278: loss=0.599, rw_mean=0.040, rw_bound=0.282, batch=231\n",
      "1279: loss=0.601, rw_mean=0.040, rw_bound=0.349, batch=230\n",
      "1280: loss=0.602, rw_mean=0.070, rw_bound=0.430, batch=227\n",
      "1281: loss=0.605, rw_mean=0.080, rw_bound=0.380, batch=229\n",
      "1282: loss=0.601, rw_mean=0.020, rw_bound=0.074, batch=230\n",
      "1283: loss=0.601, rw_mean=0.080, rw_bound=0.387, batch=230\n",
      "1284: loss=0.599, rw_mean=0.060, rw_bound=0.296, batch=231\n",
      "1285: loss=0.599, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "1286: loss=0.600, rw_mean=0.050, rw_bound=0.430, batch=230\n",
      "1287: loss=0.597, rw_mean=0.030, rw_bound=0.238, batch=231\n",
      "1288: loss=0.597, rw_mean=0.020, rw_bound=0.206, batch=231\n",
      "1289: loss=0.609, rw_mean=0.050, rw_bound=0.478, batch=177\n",
      "1290: loss=0.608, rw_mean=0.040, rw_bound=0.000, batch=181\n",
      "1291: loss=0.595, rw_mean=0.040, rw_bound=0.000, batch=185\n",
      "1292: loss=0.589, rw_mean=0.050, rw_bound=0.000, batch=190\n",
      "1293: loss=0.587, rw_mean=0.030, rw_bound=0.000, batch=193\n",
      "1294: loss=0.578, rw_mean=0.050, rw_bound=0.000, batch=198\n",
      "1295: loss=0.580, rw_mean=0.030, rw_bound=0.000, batch=201\n",
      "1296: loss=0.574, rw_mean=0.050, rw_bound=0.000, batch=206\n",
      "1297: loss=0.570, rw_mean=0.040, rw_bound=0.000, batch=210\n",
      "1298: loss=0.573, rw_mean=0.030, rw_bound=0.000, batch=213\n",
      "1299: loss=0.561, rw_mean=0.050, rw_bound=0.000, batch=218\n",
      "1300: loss=0.559, rw_mean=0.020, rw_bound=0.000, batch=220\n",
      "1301: loss=0.549, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "1302: loss=0.552, rw_mean=0.060, rw_bound=0.050, batch=226\n",
      "1303: loss=0.559, rw_mean=0.060, rw_bound=0.115, batch=228\n",
      "1304: loss=0.563, rw_mean=0.030, rw_bound=0.122, batch=228\n",
      "1305: loss=0.564, rw_mean=0.030, rw_bound=0.137, batch=229\n",
      "1306: loss=0.568, rw_mean=0.040, rw_bound=0.150, batch=227\n",
      "1307: loss=0.569, rw_mean=0.040, rw_bound=0.167, batch=227\n",
      "1308: loss=0.565, rw_mean=0.040, rw_bound=0.224, batch=229\n",
      "1309: loss=0.572, rw_mean=0.060, rw_bound=0.229, batch=226\n",
      "1310: loss=0.569, rw_mean=0.030, rw_bound=0.066, batch=228\n",
      "1311: loss=0.566, rw_mean=0.020, rw_bound=0.025, batch=229\n",
      "1312: loss=0.571, rw_mean=0.040, rw_bound=0.163, batch=230\n",
      "1313: loss=0.573, rw_mean=0.060, rw_bound=0.247, batch=231\n",
      "1314: loss=0.572, rw_mean=0.070, rw_bound=0.254, batch=230\n",
      "1315: loss=0.577, rw_mean=0.020, rw_bound=0.282, batch=225\n",
      "1316: loss=0.575, rw_mean=0.030, rw_bound=0.124, batch=227\n",
      "1317: loss=0.576, rw_mean=0.040, rw_bound=0.230, batch=229\n",
      "1318: loss=0.577, rw_mean=0.050, rw_bound=0.295, batch=230\n",
      "1319: loss=0.585, rw_mean=0.050, rw_bound=0.314, batch=220\n",
      "1320: loss=0.584, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "1321: loss=0.584, rw_mean=0.060, rw_bound=0.254, batch=224\n",
      "1322: loss=0.580, rw_mean=0.060, rw_bound=0.273, batch=227\n",
      "1323: loss=0.574, rw_mean=0.020, rw_bound=0.133, batch=229\n",
      "1324: loss=0.581, rw_mean=0.040, rw_bound=0.282, batch=229\n",
      "1325: loss=0.581, rw_mean=0.030, rw_bound=0.328, batch=230\n",
      "1326: loss=0.583, rw_mean=0.030, rw_bound=0.170, batch=231\n",
      "1327: loss=0.579, rw_mean=0.020, rw_bound=0.185, batch=231\n",
      "1328: loss=0.586, rw_mean=0.060, rw_bound=0.349, batch=217\n",
      "1329: loss=0.579, rw_mean=0.030, rw_bound=0.000, batch=220\n",
      "1330: loss=0.572, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "1331: loss=0.571, rw_mean=0.080, rw_bound=0.160, batch=226\n",
      "1332: loss=0.571, rw_mean=0.000, rw_bound=0.000, batch=226\n",
      "1333: loss=0.573, rw_mean=0.060, rw_bound=0.176, batch=228\n",
      "1334: loss=0.572, rw_mean=0.040, rw_bound=0.169, batch=229\n",
      "1335: loss=0.567, rw_mean=0.010, rw_bound=0.009, batch=230\n",
      "1336: loss=0.572, rw_mean=0.020, rw_bound=0.136, batch=231\n",
      "1337: loss=0.580, rw_mean=0.040, rw_bound=0.185, batch=230\n",
      "1338: loss=0.583, rw_mean=0.070, rw_bound=0.229, batch=229\n",
      "1339: loss=0.578, rw_mean=0.070, rw_bound=0.282, batch=226\n",
      "1340: loss=0.575, rw_mean=0.040, rw_bound=0.284, batch=228\n",
      "1341: loss=0.580, rw_mean=0.050, rw_bound=0.314, batch=228\n",
      "1342: loss=0.583, rw_mean=0.040, rw_bound=0.349, batch=228\n",
      "1343: loss=0.582, rw_mean=0.060, rw_bound=0.282, batch=228\n",
      "1344: loss=0.580, rw_mean=0.020, rw_bound=0.231, batch=229\n",
      "1345: loss=0.577, rw_mean=0.020, rw_bound=0.108, batch=230\n",
      "1346: loss=0.579, rw_mean=0.080, rw_bound=0.247, batch=231\n",
      "1347: loss=0.582, rw_mean=0.060, rw_bound=0.282, batch=231\n",
      "1348: loss=0.598, rw_mean=0.020, rw_bound=0.387, batch=210\n",
      "1349: loss=0.596, rw_mean=0.060, rw_bound=0.000, batch=216\n",
      "1350: loss=0.595, rw_mean=0.000, rw_bound=0.000, batch=216\n",
      "1351: loss=0.596, rw_mean=0.060, rw_bound=0.039, batch=221\n",
      "1352: loss=0.594, rw_mean=0.020, rw_bound=0.000, batch=223\n",
      "1353: loss=0.595, rw_mean=0.010, rw_bound=0.000, batch=224\n",
      "1354: loss=0.593, rw_mean=0.040, rw_bound=0.104, batch=227\n",
      "1355: loss=0.590, rw_mean=0.050, rw_bound=0.206, batch=227\n",
      "1356: loss=0.592, rw_mean=0.050, rw_bound=0.229, batch=227\n",
      "1357: loss=0.593, rw_mean=0.040, rw_bound=0.254, batch=223\n",
      "1358: loss=0.592, rw_mean=0.050, rw_bound=0.204, batch=226\n",
      "1359: loss=0.591, rw_mean=0.050, rw_bound=0.268, batch=228\n",
      "1360: loss=0.594, rw_mean=0.030, rw_bound=0.282, batch=228\n",
      "1361: loss=0.599, rw_mean=0.030, rw_bound=0.314, batch=226\n",
      "1362: loss=0.592, rw_mean=0.070, rw_bound=0.349, batch=226\n",
      "1363: loss=0.591, rw_mean=0.050, rw_bound=0.321, batch=228\n",
      "1364: loss=0.590, rw_mean=0.070, rw_bound=0.387, batch=223\n",
      "1365: loss=0.586, rw_mean=0.060, rw_bound=0.229, batch=225\n",
      "1366: loss=0.584, rw_mean=0.050, rw_bound=0.329, batch=227\n",
      "1367: loss=0.588, rw_mean=0.020, rw_bound=0.120, batch=229\n",
      "1368: loss=0.589, rw_mean=0.020, rw_bound=0.192, batch=230\n",
      "1369: loss=0.583, rw_mean=0.050, rw_bound=0.254, batch=229\n",
      "1370: loss=0.581, rw_mean=0.020, rw_bound=0.164, batch=230\n",
      "1371: loss=0.580, rw_mean=0.020, rw_bound=0.340, batch=231\n",
      "1372: loss=0.583, rw_mean=0.030, rw_bound=0.387, batch=228\n",
      "1373: loss=0.583, rw_mean=0.040, rw_bound=0.392, batch=229\n",
      "1374: loss=0.581, rw_mean=0.040, rw_bound=0.364, batch=230\n",
      "1375: loss=0.580, rw_mean=0.030, rw_bound=0.356, batch=231\n",
      "1376: loss=0.580, rw_mean=0.020, rw_bound=0.349, batch=231\n",
      "1377: loss=0.580, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1378: loss=0.579, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "1379: loss=0.604, rw_mean=0.060, rw_bound=0.430, batch=205\n",
      "1380: loss=0.598, rw_mean=0.030, rw_bound=0.000, batch=208\n",
      "1381: loss=0.604, rw_mean=0.060, rw_bound=0.000, batch=214\n",
      "1382: loss=0.605, rw_mean=0.030, rw_bound=0.000, batch=217\n",
      "1383: loss=0.606, rw_mean=0.030, rw_bound=0.000, batch=220\n",
      "1384: loss=0.602, rw_mean=0.030, rw_bound=0.000, batch=223\n",
      "1385: loss=0.600, rw_mean=0.050, rw_bound=0.080, batch=226\n",
      "1386: loss=0.596, rw_mean=0.020, rw_bound=0.049, batch=228\n",
      "1387: loss=0.596, rw_mean=0.070, rw_bound=0.231, batch=229\n",
      "1388: loss=0.595, rw_mean=0.110, rw_bound=0.314, batch=225\n",
      "1389: loss=0.599, rw_mean=0.060, rw_bound=0.349, batch=223\n",
      "1390: loss=0.592, rw_mean=0.040, rw_bound=0.076, batch=226\n",
      "1391: loss=0.595, rw_mean=0.070, rw_bound=0.316, batch=228\n",
      "1392: loss=0.596, rw_mean=0.040, rw_bound=0.349, batch=228\n",
      "1393: loss=0.594, rw_mean=0.020, rw_bound=0.185, batch=229\n",
      "1394: loss=0.592, rw_mean=0.010, rw_bound=0.082, batch=230\n",
      "1395: loss=0.592, rw_mean=0.070, rw_bound=0.296, batch=231\n",
      "1396: loss=0.594, rw_mean=0.060, rw_bound=0.349, batch=231\n",
      "1397: loss=0.597, rw_mean=0.100, rw_bound=0.387, batch=229\n",
      "1398: loss=0.596, rw_mean=0.060, rw_bound=0.405, batch=230\n",
      "1399: loss=0.594, rw_mean=0.030, rw_bound=0.200, batch=231\n",
      "1400: loss=0.595, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1401: loss=0.595, rw_mean=0.040, rw_bound=0.387, batch=231\n",
      "1402: loss=0.602, rw_mean=0.050, rw_bound=0.430, batch=222\n",
      "1403: loss=0.598, rw_mean=0.050, rw_bound=0.190, batch=225\n",
      "1404: loss=0.592, rw_mean=0.020, rw_bound=0.020, batch=227\n",
      "1405: loss=0.596, rw_mean=0.020, rw_bound=0.079, batch=229\n",
      "1406: loss=0.596, rw_mean=0.050, rw_bound=0.309, batch=230\n",
      "1407: loss=0.595, rw_mean=0.030, rw_bound=0.288, batch=231\n",
      "1408: loss=0.596, rw_mean=0.030, rw_bound=0.314, batch=230\n",
      "1409: loss=0.598, rw_mean=0.010, rw_bound=0.244, batch=231\n",
      "1410: loss=0.598, rw_mean=0.000, rw_bound=0.000, batch=231\n",
      "1411: loss=0.600, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "1412: loss=0.602, rw_mean=0.020, rw_bound=0.387, batch=227\n",
      "1413: loss=0.599, rw_mean=0.060, rw_bound=0.407, batch=229\n",
      "1414: loss=0.601, rw_mean=0.020, rw_bound=0.198, batch=230\n",
      "1415: loss=0.601, rw_mean=0.040, rw_bound=0.304, batch=231\n",
      "1416: loss=0.601, rw_mean=0.050, rw_bound=0.282, batch=231\n",
      "1417: loss=0.600, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "1418: loss=0.601, rw_mean=0.060, rw_bound=0.430, batch=230\n",
      "1419: loss=0.601, rw_mean=0.030, rw_bound=0.340, batch=231\n",
      "1420: loss=0.601, rw_mean=0.020, rw_bound=0.229, batch=231\n",
      "1421: loss=0.601, rw_mean=0.030, rw_bound=0.254, batch=231\n",
      "1422: loss=0.601, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "1423: loss=0.601, rw_mean=0.070, rw_bound=0.229, batch=231\n",
      "1424: loss=0.601, rw_mean=0.040, rw_bound=0.387, batch=231\n",
      "1425: loss=0.601, rw_mean=0.030, rw_bound=0.387, batch=231\n",
      "1426: loss=0.601, rw_mean=0.070, rw_bound=0.430, batch=230\n",
      "1427: loss=0.601, rw_mean=0.020, rw_bound=0.314, batch=230\n",
      "1428: loss=0.600, rw_mean=0.020, rw_bound=0.451, batch=231\n",
      "1429: loss=0.610, rw_mean=0.050, rw_bound=0.478, batch=198\n",
      "1430: loss=0.596, rw_mean=0.050, rw_bound=0.000, batch=203\n",
      "1431: loss=0.594, rw_mean=0.020, rw_bound=0.000, batch=205\n",
      "1432: loss=0.590, rw_mean=0.060, rw_bound=0.000, batch=211\n",
      "1433: loss=0.586, rw_mean=0.060, rw_bound=0.000, batch=217\n",
      "1434: loss=0.593, rw_mean=0.060, rw_bound=0.057, batch=222\n",
      "1435: loss=0.593, rw_mean=0.060, rw_bound=0.117, batch=225\n",
      "1436: loss=0.596, rw_mean=0.060, rw_bound=0.170, batch=227\n",
      "1437: loss=0.595, rw_mean=0.070, rw_bound=0.206, batch=226\n",
      "1438: loss=0.594, rw_mean=0.050, rw_bound=0.217, batch=228\n",
      "1439: loss=0.587, rw_mean=0.060, rw_bound=0.229, batch=226\n",
      "1440: loss=0.590, rw_mean=0.020, rw_bound=0.061, batch=228\n",
      "1441: loss=0.600, rw_mean=0.030, rw_bound=0.254, batch=219\n",
      "1442: loss=0.597, rw_mean=0.040, rw_bound=0.060, batch=223\n",
      "1443: loss=0.589, rw_mean=0.050, rw_bound=0.125, batch=226\n",
      "1444: loss=0.593, rw_mean=0.030, rw_bound=0.143, batch=228\n",
      "1445: loss=0.593, rw_mean=0.020, rw_bound=0.137, batch=229\n",
      "1446: loss=0.592, rw_mean=0.020, rw_bound=0.141, batch=230\n",
      "1447: loss=0.592, rw_mean=0.030, rw_bound=0.189, batch=231\n",
      "1448: loss=0.592, rw_mean=0.010, rw_bound=0.135, batch=231\n",
      "1449: loss=0.595, rw_mean=0.020, rw_bound=0.254, batch=230\n",
      "1450: loss=0.593, rw_mean=0.010, rw_bound=0.198, batch=231\n",
      "1451: loss=0.597, rw_mean=0.050, rw_bound=0.282, batch=228\n",
      "1452: loss=0.597, rw_mean=0.010, rw_bound=0.015, batch=229\n",
      "1453: loss=0.597, rw_mean=0.020, rw_bound=0.157, batch=230\n",
      "1454: loss=0.600, rw_mean=0.060, rw_bound=0.314, batch=223\n",
      "1455: loss=0.598, rw_mean=0.030, rw_bound=0.188, batch=226\n",
      "1456: loss=0.596, rw_mean=0.030, rw_bound=0.250, batch=228\n",
      "1457: loss=0.598, rw_mean=0.030, rw_bound=0.237, batch=229\n",
      "1458: loss=0.596, rw_mean=0.030, rw_bound=0.194, batch=230\n",
      "1459: loss=0.597, rw_mean=0.030, rw_bound=0.281, batch=231\n",
      "1460: loss=0.595, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "1461: loss=0.597, rw_mean=0.040, rw_bound=0.349, batch=223\n",
      "1462: loss=0.593, rw_mean=0.030, rw_bound=0.111, batch=226\n",
      "1463: loss=0.594, rw_mean=0.060, rw_bound=0.230, batch=228\n",
      "1464: loss=0.596, rw_mean=0.060, rw_bound=0.282, batch=228\n",
      "1465: loss=0.593, rw_mean=0.030, rw_bound=0.192, batch=229\n",
      "1466: loss=0.594, rw_mean=0.050, rw_bound=0.278, batch=230\n",
      "1467: loss=0.595, rw_mean=0.060, rw_bound=0.338, batch=231\n",
      "1468: loss=0.598, rw_mean=0.040, rw_bound=0.349, batch=228\n",
      "1469: loss=0.598, rw_mean=0.040, rw_bound=0.195, batch=229\n",
      "1470: loss=0.596, rw_mean=0.030, rw_bound=0.387, batch=222\n",
      "1471: loss=0.597, rw_mean=0.050, rw_bound=0.156, batch=225\n",
      "1472: loss=0.595, rw_mean=0.040, rw_bound=0.106, batch=227\n",
      "1473: loss=0.598, rw_mean=0.070, rw_bound=0.245, batch=229\n",
      "1474: loss=0.598, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "1475: loss=0.595, rw_mean=0.030, rw_bound=0.213, batch=230\n",
      "1476: loss=0.594, rw_mean=0.050, rw_bound=0.282, batch=230\n",
      "1477: loss=0.593, rw_mean=0.050, rw_bound=0.314, batch=228\n",
      "1478: loss=0.594, rw_mean=0.060, rw_bound=0.353, batch=229\n",
      "1479: loss=0.596, rw_mean=0.100, rw_bound=0.387, batch=229\n",
      "1480: loss=0.595, rw_mean=0.060, rw_bound=0.295, batch=230\n",
      "1481: loss=0.596, rw_mean=0.050, rw_bound=0.314, batch=229\n",
      "1482: loss=0.596, rw_mean=0.030, rw_bound=0.229, batch=229\n",
      "1483: loss=0.593, rw_mean=0.010, rw_bound=0.049, batch=230\n",
      "1484: loss=0.596, rw_mean=0.040, rw_bound=0.406, batch=231\n",
      "1485: loss=0.611, rw_mean=0.040, rw_bound=0.430, batch=214\n",
      "1486: loss=0.606, rw_mean=0.030, rw_bound=0.000, batch=217\n",
      "1487: loss=0.602, rw_mean=0.040, rw_bound=0.000, batch=221\n",
      "1488: loss=0.598, rw_mean=0.020, rw_bound=0.000, batch=223\n",
      "1489: loss=0.597, rw_mean=0.070, rw_bound=0.139, batch=226\n",
      "1490: loss=0.595, rw_mean=0.040, rw_bound=0.176, batch=228\n",
      "1491: loss=0.594, rw_mean=0.040, rw_bound=0.211, batch=229\n",
      "1492: loss=0.591, rw_mean=0.040, rw_bound=0.265, batch=230\n",
      "1493: loss=0.594, rw_mean=0.030, rw_bound=0.282, batch=228\n",
      "1494: loss=0.594, rw_mean=0.040, rw_bound=0.229, batch=228\n",
      "1495: loss=0.598, rw_mean=0.040, rw_bound=0.314, batch=227\n",
      "1496: loss=0.597, rw_mean=0.030, rw_bound=0.110, batch=229\n",
      "1497: loss=0.597, rw_mean=0.070, rw_bound=0.314, batch=229\n",
      "1498: loss=0.606, rw_mean=0.060, rw_bound=0.349, batch=223\n",
      "1499: loss=0.606, rw_mean=0.030, rw_bound=0.169, batch=226\n",
      "1500: loss=0.608, rw_mean=0.020, rw_bound=0.141, batch=228\n",
      "1501: loss=0.607, rw_mean=0.020, rw_bound=0.208, batch=229\n",
      "1502: loss=0.607, rw_mean=0.030, rw_bound=0.229, batch=229\n",
      "1503: loss=0.606, rw_mean=0.020, rw_bound=0.120, batch=230\n",
      "1504: loss=0.605, rw_mean=0.010, rw_bound=0.095, batch=231\n",
      "1505: loss=0.606, rw_mean=0.030, rw_bound=0.254, batch=231\n",
      "1506: loss=0.606, rw_mean=0.030, rw_bound=0.282, batch=230\n",
      "1507: loss=0.606, rw_mean=0.010, rw_bound=0.220, batch=231\n",
      "1508: loss=0.606, rw_mean=0.030, rw_bound=0.254, batch=231\n",
      "1509: loss=0.607, rw_mean=0.070, rw_bound=0.387, batch=226\n",
      "1510: loss=0.608, rw_mean=0.060, rw_bound=0.390, batch=228\n",
      "1511: loss=0.608, rw_mean=0.070, rw_bound=0.392, batch=229\n",
      "1512: loss=0.608, rw_mean=0.030, rw_bound=0.381, batch=230\n",
      "1513: loss=0.607, rw_mean=0.040, rw_bound=0.376, batch=231\n",
      "1514: loss=0.607, rw_mean=0.030, rw_bound=0.282, batch=231\n",
      "1515: loss=0.608, rw_mean=0.030, rw_bound=0.387, batch=230\n",
      "1516: loss=0.608, rw_mean=0.070, rw_bound=0.387, batch=230\n",
      "1517: loss=0.610, rw_mean=0.010, rw_bound=0.271, batch=231\n",
      "1518: loss=0.614, rw_mean=0.050, rw_bound=0.430, batch=225\n",
      "1519: loss=0.615, rw_mean=0.010, rw_bound=0.000, batch=226\n",
      "1520: loss=0.614, rw_mean=0.040, rw_bound=0.390, batch=228\n",
      "1521: loss=0.614, rw_mean=0.070, rw_bound=0.430, batch=226\n",
      "1522: loss=0.612, rw_mean=0.020, rw_bound=0.174, batch=228\n",
      "1523: loss=0.611, rw_mean=0.030, rw_bound=0.241, batch=229\n",
      "1524: loss=0.611, rw_mean=0.060, rw_bound=0.349, batch=229\n",
      "1525: loss=0.609, rw_mean=0.040, rw_bound=0.364, batch=230\n",
      "1526: loss=0.611, rw_mean=0.080, rw_bound=0.418, batch=231\n",
      "1527: loss=0.611, rw_mean=0.020, rw_bound=0.387, batch=231\n",
      "1528: loss=0.612, rw_mean=0.080, rw_bound=0.430, batch=231\n",
      "1529: loss=0.612, rw_mean=0.040, rw_bound=0.430, batch=231\n",
      "1530: loss=0.607, rw_mean=0.050, rw_bound=0.478, batch=214\n",
      "1531: loss=0.606, rw_mean=0.030, rw_bound=0.000, batch=217\n",
      "1532: loss=0.606, rw_mean=0.020, rw_bound=0.000, batch=219\n",
      "1533: loss=0.604, rw_mean=0.010, rw_bound=0.000, batch=220\n",
      "1534: loss=0.604, rw_mean=0.010, rw_bound=0.000, batch=221\n",
      "1535: loss=0.601, rw_mean=0.060, rw_bound=0.080, batch=224\n",
      "1536: loss=0.601, rw_mean=0.060, rw_bound=0.185, batch=226\n",
      "1537: loss=0.598, rw_mean=0.020, rw_bound=0.114, batch=228\n",
      "1538: loss=0.591, rw_mean=0.050, rw_bound=0.231, batch=229\n",
      "1539: loss=0.588, rw_mean=0.040, rw_bound=0.239, batch=230\n",
      "1540: loss=0.592, rw_mean=0.030, rw_bound=0.254, batch=229\n",
      "1541: loss=0.599, rw_mean=0.050, rw_bound=0.282, batch=228\n",
      "1542: loss=0.600, rw_mean=0.030, rw_bound=0.314, batch=226\n",
      "1543: loss=0.598, rw_mean=0.050, rw_bound=0.349, batch=226\n",
      "1544: loss=0.598, rw_mean=0.060, rw_bound=0.316, batch=228\n",
      "1545: loss=0.600, rw_mean=0.010, rw_bound=0.035, batch=229\n",
      "1546: loss=0.600, rw_mean=0.060, rw_bound=0.295, batch=230\n",
      "1547: loss=0.603, rw_mean=0.070, rw_bound=0.376, batch=231\n",
      "1548: loss=0.604, rw_mean=0.030, rw_bound=0.206, batch=231\n",
      "1549: loss=0.609, rw_mean=0.020, rw_bound=0.387, batch=223\n",
      "1550: loss=0.603, rw_mean=0.050, rw_bound=0.160, batch=226\n",
      "1551: loss=0.599, rw_mean=0.020, rw_bound=0.021, batch=228\n",
      "1552: loss=0.598, rw_mean=0.040, rw_bound=0.152, batch=229\n",
      "1553: loss=0.602, rw_mean=0.030, rw_bound=0.182, batch=230\n",
      "1554: loss=0.602, rw_mean=0.030, rw_bound=0.281, batch=231\n",
      "1555: loss=0.603, rw_mean=0.050, rw_bound=0.314, batch=230\n",
      "1556: loss=0.609, rw_mean=0.040, rw_bound=0.349, batch=227\n",
      "1557: loss=0.609, rw_mean=0.040, rw_bound=0.380, batch=229\n",
      "1558: loss=0.608, rw_mean=0.000, rw_bound=0.000, batch=229\n",
      "1559: loss=0.610, rw_mean=0.070, rw_bound=0.387, batch=226\n",
      "1560: loss=0.608, rw_mean=0.050, rw_bound=0.284, batch=228\n",
      "1561: loss=0.610, rw_mean=0.030, rw_bound=0.321, batch=229\n",
      "1562: loss=0.611, rw_mean=0.010, rw_bound=0.155, batch=230\n",
      "1563: loss=0.611, rw_mean=0.060, rw_bound=0.430, batch=225\n",
      "1564: loss=0.609, rw_mean=0.030, rw_bound=0.105, batch=227\n",
      "1565: loss=0.610, rw_mean=0.040, rw_bound=0.198, batch=229\n",
      "1566: loss=0.611, rw_mean=0.030, rw_bound=0.136, batch=230\n",
      "1567: loss=0.612, rw_mean=0.050, rw_bound=0.306, batch=231\n",
      "1568: loss=0.612, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1569: loss=0.612, rw_mean=0.030, rw_bound=0.206, batch=231\n",
      "1570: loss=0.612, rw_mean=0.050, rw_bound=0.430, batch=230\n",
      "1571: loss=0.611, rw_mean=0.060, rw_bound=0.386, batch=231\n",
      "1572: loss=0.611, rw_mean=0.010, rw_bound=0.229, batch=231\n",
      "1573: loss=0.612, rw_mean=0.040, rw_bound=0.430, batch=230\n",
      "1574: loss=0.612, rw_mean=0.010, rw_bound=0.160, batch=231\n",
      "1575: loss=0.611, rw_mean=0.080, rw_bound=0.387, batch=231\n",
      "1576: loss=0.610, rw_mean=0.040, rw_bound=0.430, batch=231\n",
      "1577: loss=0.610, rw_mean=0.010, rw_bound=0.314, batch=231\n",
      "1578: loss=0.610, rw_mean=0.050, rw_bound=0.430, batch=231\n",
      "1579: loss=0.612, rw_mean=0.020, rw_bound=0.478, batch=219\n",
      "1580: loss=0.607, rw_mean=0.030, rw_bound=0.000, batch=222\n",
      "1581: loss=0.608, rw_mean=0.020, rw_bound=0.000, batch=224\n",
      "1582: loss=0.605, rw_mean=0.030, rw_bound=0.150, batch=227\n",
      "1583: loss=0.607, rw_mean=0.040, rw_bound=0.237, batch=229\n",
      "1584: loss=0.605, rw_mean=0.010, rw_bound=0.074, batch=230\n",
      "1585: loss=0.610, rw_mean=0.040, rw_bound=0.254, batch=230\n",
      "1586: loss=0.614, rw_mean=0.050, rw_bound=0.304, batch=231\n",
      "1587: loss=0.612, rw_mean=0.020, rw_bound=0.314, batch=230\n",
      "1588: loss=0.612, rw_mean=0.030, rw_bound=0.338, batch=231\n",
      "1589: loss=0.606, rw_mean=0.020, rw_bound=0.349, batch=230\n",
      "1590: loss=0.608, rw_mean=0.030, rw_bound=0.327, batch=231\n",
      "1591: loss=0.608, rw_mean=0.070, rw_bound=0.387, batch=227\n",
      "1592: loss=0.605, rw_mean=0.020, rw_bound=0.148, batch=229\n",
      "1593: loss=0.605, rw_mean=0.050, rw_bound=0.254, batch=229\n",
      "1594: loss=0.603, rw_mean=0.020, rw_bound=0.230, batch=230\n",
      "1595: loss=0.601, rw_mean=0.040, rw_bound=0.180, batch=231\n",
      "1596: loss=0.601, rw_mean=0.010, rw_bound=0.185, batch=231\n",
      "1597: loss=0.603, rw_mean=0.040, rw_bound=0.229, batch=231\n",
      "1598: loss=0.603, rw_mean=0.030, rw_bound=0.314, batch=230\n",
      "1599: loss=0.604, rw_mean=0.040, rw_bound=0.338, batch=231\n",
      "1600: loss=0.605, rw_mean=0.050, rw_bound=0.349, batch=231\n",
      "1601: loss=0.606, rw_mean=0.040, rw_bound=0.387, batch=231\n",
      "1602: loss=0.610, rw_mean=0.030, rw_bound=0.430, batch=226\n",
      "1603: loss=0.609, rw_mean=0.020, rw_bound=0.024, batch=228\n",
      "1604: loss=0.606, rw_mean=0.040, rw_bound=0.260, batch=229\n",
      "1605: loss=0.604, rw_mean=0.060, rw_bound=0.237, batch=230\n",
      "1606: loss=0.608, rw_mean=0.070, rw_bound=0.387, batch=229\n",
      "1607: loss=0.608, rw_mean=0.040, rw_bound=0.225, batch=230\n",
      "1608: loss=0.607, rw_mean=0.070, rw_bound=0.451, batch=231\n",
      "1609: loss=0.607, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1610: loss=0.607, rw_mean=0.050, rw_bound=0.430, batch=231\n",
      "1611: loss=0.607, rw_mean=0.040, rw_bound=0.430, batch=231\n",
      "1612: loss=0.611, rw_mean=0.040, rw_bound=0.478, batch=224\n",
      "1613: loss=0.608, rw_mean=0.030, rw_bound=0.206, batch=227\n",
      "1614: loss=0.606, rw_mean=0.010, rw_bound=0.000, batch=228\n",
      "1615: loss=0.605, rw_mean=0.010, rw_bound=0.017, batch=229\n",
      "1616: loss=0.601, rw_mean=0.030, rw_bound=0.182, batch=230\n",
      "1617: loss=0.593, rw_mean=0.010, rw_bound=0.009, batch=231\n",
      "1618: loss=0.605, rw_mean=0.030, rw_bound=0.206, batch=231\n",
      "1619: loss=0.601, rw_mean=0.040, rw_bound=0.229, batch=231\n",
      "1620: loss=0.604, rw_mean=0.050, rw_bound=0.314, batch=231\n",
      "1621: loss=0.605, rw_mean=0.030, rw_bound=0.349, batch=230\n",
      "1622: loss=0.605, rw_mean=0.040, rw_bound=0.296, batch=231\n",
      "1623: loss=0.605, rw_mean=0.070, rw_bound=0.314, batch=231\n",
      "1624: loss=0.609, rw_mean=0.050, rw_bound=0.387, batch=229\n",
      "1625: loss=0.607, rw_mean=0.040, rw_bound=0.230, batch=230\n",
      "1626: loss=0.608, rw_mean=0.030, rw_bound=0.338, batch=231\n",
      "1627: loss=0.608, rw_mean=0.010, rw_bound=0.254, batch=231\n",
      "1628: loss=0.611, rw_mean=0.050, rw_bound=0.430, batch=226\n",
      "1629: loss=0.610, rw_mean=0.060, rw_bound=0.250, batch=228\n",
      "1630: loss=0.614, rw_mean=0.050, rw_bound=0.317, batch=229\n",
      "1631: loss=0.613, rw_mean=0.020, rw_bound=0.277, batch=230\n",
      "1632: loss=0.611, rw_mean=0.070, rw_bound=0.376, batch=231\n",
      "1633: loss=0.610, rw_mean=0.040, rw_bound=0.430, batch=230\n",
      "1634: loss=0.610, rw_mean=0.060, rw_bound=0.418, batch=231\n",
      "1635: loss=0.610, rw_mean=0.030, rw_bound=0.314, batch=231\n",
      "1636: loss=0.610, rw_mean=0.020, rw_bound=0.430, batch=230\n",
      "1637: loss=0.608, rw_mean=0.050, rw_bound=0.439, batch=231\n",
      "1638: loss=0.608, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "1639: loss=0.608, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "1640: loss=0.608, rw_mean=0.060, rw_bound=0.387, batch=231\n",
      "1641: loss=0.612, rw_mean=0.030, rw_bound=0.478, batch=227\n",
      "1642: loss=0.612, rw_mean=0.000, rw_bound=0.000, batch=227\n",
      "1643: loss=0.611, rw_mean=0.020, rw_bound=0.251, batch=229\n",
      "1644: loss=0.610, rw_mean=0.040, rw_bound=0.263, batch=230\n",
      "1645: loss=0.612, rw_mean=0.070, rw_bound=0.314, batch=230\n",
      "1646: loss=0.611, rw_mean=0.030, rw_bound=0.296, batch=231\n",
      "1647: loss=0.612, rw_mean=0.080, rw_bound=0.314, batch=230\n",
      "1648: loss=0.608, rw_mean=0.010, rw_bound=0.144, batch=231\n",
      "1649: loss=0.611, rw_mean=0.040, rw_bound=0.349, batch=231\n",
      "1650: loss=0.611, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1651: loss=0.611, rw_mean=0.050, rw_bound=0.314, batch=231\n",
      "1652: loss=0.613, rw_mean=0.010, rw_bound=0.430, batch=230\n",
      "1653: loss=0.613, rw_mean=0.050, rw_bound=0.430, batch=230\n",
      "1654: loss=0.612, rw_mean=0.020, rw_bound=0.331, batch=231\n",
      "1655: loss=0.613, rw_mean=0.030, rw_bound=0.430, batch=230\n",
      "1656: loss=0.611, rw_mean=0.030, rw_bound=0.342, batch=231\n",
      "1657: loss=0.613, rw_mean=0.040, rw_bound=0.430, batch=230\n",
      "1658: loss=0.613, rw_mean=0.030, rw_bound=0.349, batch=230\n",
      "1659: loss=0.613, rw_mean=0.020, rw_bound=0.253, batch=231\n",
      "1660: loss=0.613, rw_mean=0.060, rw_bound=0.430, batch=231\n",
      "1661: loss=0.613, rw_mean=0.020, rw_bound=0.314, batch=231\n",
      "1662: loss=0.611, rw_mean=0.060, rw_bound=0.478, batch=227\n",
      "1663: loss=0.609, rw_mean=0.020, rw_bound=0.183, batch=229\n",
      "1664: loss=0.606, rw_mean=0.030, rw_bound=0.215, batch=230\n",
      "1665: loss=0.605, rw_mean=0.060, rw_bound=0.266, batch=231\n",
      "1666: loss=0.612, rw_mean=0.030, rw_bound=0.387, batch=230\n",
      "1667: loss=0.614, rw_mean=0.030, rw_bound=0.370, batch=231\n",
      "1668: loss=0.614, rw_mean=0.030, rw_bound=0.229, batch=231\n",
      "1669: loss=0.614, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1670: loss=0.615, rw_mean=0.030, rw_bound=0.430, batch=229\n",
      "1671: loss=0.614, rw_mean=0.040, rw_bound=0.264, batch=230\n",
      "1672: loss=0.619, rw_mean=0.020, rw_bound=0.338, batch=231\n",
      "1673: loss=0.614, rw_mean=0.060, rw_bound=0.349, batch=231\n",
      "1674: loss=0.614, rw_mean=0.030, rw_bound=0.282, batch=231\n",
      "1675: loss=0.614, rw_mean=0.070, rw_bound=0.430, batch=231\n",
      "1676: loss=0.614, rw_mean=0.030, rw_bound=0.349, batch=231\n",
      "1677: loss=0.614, rw_mean=0.030, rw_bound=0.387, batch=231\n",
      "1678: loss=0.614, rw_mean=0.020, rw_bound=0.229, batch=231\n",
      "1679: loss=0.614, rw_mean=0.040, rw_bound=0.387, batch=231\n",
      "1680: loss=0.611, rw_mean=0.030, rw_bound=0.478, batch=229\n",
      "1681: loss=0.613, rw_mean=0.020, rw_bound=0.173, batch=230\n",
      "1682: loss=0.613, rw_mean=0.080, rw_bound=0.418, batch=231\n",
      "1683: loss=0.612, rw_mean=0.060, rw_bound=0.387, batch=231\n",
      "1684: loss=0.612, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1685: loss=0.612, rw_mean=0.060, rw_bound=0.387, batch=231\n",
      "1686: loss=0.612, rw_mean=0.050, rw_bound=0.387, batch=231\n",
      "1687: loss=0.609, rw_mean=0.020, rw_bound=0.430, batch=230\n",
      "1688: loss=0.611, rw_mean=0.030, rw_bound=0.406, batch=231\n",
      "1689: loss=0.611, rw_mean=0.040, rw_bound=0.314, batch=231\n",
      "1690: loss=0.610, rw_mean=0.050, rw_bound=0.430, batch=231\n",
      "1691: loss=0.610, rw_mean=0.030, rw_bound=0.254, batch=231\n",
      "1692: loss=0.611, rw_mean=0.070, rw_bound=0.478, batch=231\n",
      "1694: loss=0.393, rw_mean=0.010, rw_bound=0.000, batch=1\n",
      "1695: loss=0.429, rw_mean=0.040, rw_bound=0.000, batch=5\n",
      "1696: loss=0.477, rw_mean=0.020, rw_bound=0.000, batch=7\n",
      "1697: loss=0.383, rw_mean=0.040, rw_bound=0.000, batch=11\n",
      "1698: loss=0.321, rw_mean=0.040, rw_bound=0.000, batch=15\n",
      "1699: loss=0.267, rw_mean=0.060, rw_bound=0.000, batch=21\n",
      "1700: loss=0.222, rw_mean=0.130, rw_bound=0.000, batch=34\n",
      "1701: loss=0.207, rw_mean=0.120, rw_bound=0.000, batch=46\n",
      "1702: loss=0.206, rw_mean=0.090, rw_bound=0.000, batch=55\n",
      "1703: loss=0.197, rw_mean=0.100, rw_bound=0.000, batch=65\n",
      "1704: loss=0.198, rw_mean=0.100, rw_bound=0.000, batch=75\n",
      "1705: loss=0.183, rw_mean=0.070, rw_bound=0.000, batch=82\n",
      "1706: loss=0.180, rw_mean=0.050, rw_bound=0.000, batch=87\n",
      "1707: loss=0.179, rw_mean=0.050, rw_bound=0.000, batch=92\n",
      "1708: loss=0.174, rw_mean=0.070, rw_bound=0.000, batch=99\n",
      "1709: loss=0.173, rw_mean=0.060, rw_bound=0.000, batch=105\n",
      "1710: loss=0.167, rw_mean=0.080, rw_bound=0.000, batch=113\n",
      "1711: loss=0.163, rw_mean=0.100, rw_bound=0.000, batch=123\n",
      "1712: loss=0.165, rw_mean=0.040, rw_bound=0.000, batch=127\n",
      "1713: loss=0.162, rw_mean=0.090, rw_bound=0.000, batch=136\n",
      "1714: loss=0.155, rw_mean=0.110, rw_bound=0.000, batch=147\n",
      "1715: loss=0.154, rw_mean=0.080, rw_bound=0.000, batch=155\n",
      "1716: loss=0.148, rw_mean=0.130, rw_bound=0.000, batch=168\n",
      "1717: loss=0.140, rw_mean=0.100, rw_bound=0.000, batch=178\n",
      "1718: loss=0.140, rw_mean=0.060, rw_bound=0.000, batch=184\n",
      "1719: loss=0.141, rw_mean=0.080, rw_bound=0.000, batch=192\n",
      "1720: loss=0.140, rw_mean=0.060, rw_bound=0.000, batch=198\n",
      "1721: loss=0.136, rw_mean=0.120, rw_bound=0.001, batch=208\n",
      "1722: loss=0.134, rw_mean=0.150, rw_bound=0.008, batch=215\n",
      "1723: loss=0.131, rw_mean=0.150, rw_bound=0.021, batch=220\n",
      "1724: loss=0.133, rw_mean=0.100, rw_bound=0.032, batch=224\n",
      "1725: loss=0.135, rw_mean=0.120, rw_bound=0.042, batch=225\n",
      "1726: loss=0.138, rw_mean=0.060, rw_bound=0.047, batch=225\n",
      "1727: loss=0.138, rw_mean=0.030, rw_bound=0.030, batch=227\n",
      "1728: loss=0.136, rw_mean=0.090, rw_bound=0.058, batch=228\n",
      "1729: loss=0.133, rw_mean=0.110, rw_bound=0.072, batch=221\n",
      "1730: loss=0.135, rw_mean=0.120, rw_bound=0.080, batch=221\n",
      "1731: loss=0.137, rw_mean=0.120, rw_bound=0.089, batch=213\n",
      "1732: loss=0.136, rw_mean=0.130, rw_bound=0.098, batch=212\n",
      "1733: loss=0.135, rw_mean=0.130, rw_bound=0.085, batch=218\n",
      "1734: loss=0.136, rw_mean=0.110, rw_bound=0.100, batch=222\n",
      "1735: loss=0.141, rw_mean=0.090, rw_bound=0.109, batch=221\n",
      "1736: loss=0.148, rw_mean=0.120, rw_bound=0.122, batch=217\n",
      "1737: loss=0.141, rw_mean=0.180, rw_bound=0.135, batch=212\n",
      "1738: loss=0.141, rw_mean=0.080, rw_bound=0.014, batch=218\n",
      "1739: loss=0.139, rw_mean=0.080, rw_bound=0.080, batch=221\n",
      "1740: loss=0.143, rw_mean=0.120, rw_bound=0.150, batch=211\n",
      "1741: loss=0.152, rw_mean=0.120, rw_bound=0.167, batch=198\n",
      "1742: loss=0.147, rw_mean=0.130, rw_bound=0.023, batch=208\n",
      "1743: loss=0.150, rw_mean=0.110, rw_bound=0.065, batch=214\n",
      "1744: loss=0.150, rw_mean=0.090, rw_bound=0.041, batch=220\n",
      "1745: loss=0.152, rw_mean=0.110, rw_bound=0.118, batch=224\n",
      "1746: loss=0.153, rw_mean=0.110, rw_bound=0.122, batch=226\n",
      "1747: loss=0.161, rw_mean=0.160, rw_bound=0.185, batch=211\n",
      "1748: loss=0.158, rw_mean=0.080, rw_bound=0.016, batch=217\n",
      "1749: loss=0.157, rw_mean=0.080, rw_bound=0.042, batch=222\n",
      "1750: loss=0.156, rw_mean=0.050, rw_bound=0.051, batch=225\n",
      "1751: loss=0.160, rw_mean=0.140, rw_bound=0.150, batch=224\n",
      "1752: loss=0.160, rw_mean=0.090, rw_bound=0.202, batch=227\n",
      "1753: loss=0.160, rw_mean=0.060, rw_bound=0.202, batch=229\n",
      "1754: loss=0.163, rw_mean=0.100, rw_bound=0.206, batch=202\n",
      "1755: loss=0.159, rw_mean=0.100, rw_bound=0.007, batch=211\n",
      "1756: loss=0.157, rw_mean=0.080, rw_bound=0.018, batch=217\n",
      "1757: loss=0.153, rw_mean=0.110, rw_bound=0.051, batch=222\n",
      "1758: loss=0.152, rw_mean=0.100, rw_bound=0.060, batch=225\n",
      "1759: loss=0.154, rw_mean=0.090, rw_bound=0.091, batch=227\n",
      "1760: loss=0.157, rw_mean=0.110, rw_bound=0.135, batch=228\n",
      "1761: loss=0.157, rw_mean=0.070, rw_bound=0.150, batch=228\n",
      "1762: loss=0.157, rw_mean=0.160, rw_bound=0.206, batch=228\n",
      "1763: loss=0.159, rw_mean=0.130, rw_bound=0.229, batch=189\n",
      "1764: loss=0.150, rw_mean=0.110, rw_bound=0.000, batch=200\n",
      "1765: loss=0.145, rw_mean=0.070, rw_bound=0.000, batch=207\n",
      "1766: loss=0.145, rw_mean=0.140, rw_bound=0.046, batch=215\n",
      "1767: loss=0.144, rw_mean=0.090, rw_bound=0.047, batch=219\n",
      "1768: loss=0.149, rw_mean=0.120, rw_bound=0.072, batch=221\n",
      "1769: loss=0.150, rw_mean=0.120, rw_bound=0.109, batch=224\n",
      "1770: loss=0.150, rw_mean=0.110, rw_bound=0.149, batch=227\n",
      "1771: loss=0.150, rw_mean=0.110, rw_bound=0.182, batch=229\n",
      "1772: loss=0.150, rw_mean=0.060, rw_bound=0.185, batch=228\n",
      "1773: loss=0.150, rw_mean=0.060, rw_bound=0.206, batch=228\n",
      "1774: loss=0.156, rw_mean=0.060, rw_bound=0.229, batch=224\n",
      "1775: loss=0.154, rw_mean=0.060, rw_bound=0.115, batch=227\n",
      "1776: loss=0.167, rw_mean=0.160, rw_bound=0.254, batch=201\n",
      "1777: loss=0.161, rw_mean=0.050, rw_bound=0.000, batch=206\n",
      "1778: loss=0.154, rw_mean=0.070, rw_bound=0.000, batch=213\n",
      "1779: loss=0.151, rw_mean=0.070, rw_bound=0.005, batch=219\n",
      "1780: loss=0.157, rw_mean=0.130, rw_bound=0.040, batch=223\n",
      "1781: loss=0.159, rw_mean=0.060, rw_bound=0.089, batch=225\n",
      "1782: loss=0.160, rw_mean=0.130, rw_bound=0.206, batch=223\n",
      "1783: loss=0.162, rw_mean=0.150, rw_bound=0.220, batch=226\n",
      "1784: loss=0.162, rw_mean=0.090, rw_bound=0.229, batch=223\n",
      "1785: loss=0.162, rw_mean=0.070, rw_bound=0.244, batch=226\n",
      "1786: loss=0.162, rw_mean=0.110, rw_bound=0.196, batch=228\n",
      "1787: loss=0.161, rw_mean=0.090, rw_bound=0.254, batch=223\n",
      "1788: loss=0.161, rw_mean=0.100, rw_bound=0.252, batch=226\n",
      "1789: loss=0.161, rw_mean=0.080, rw_bound=0.234, batch=228\n",
      "1790: loss=0.166, rw_mean=0.130, rw_bound=0.282, batch=191\n",
      "1791: loss=0.160, rw_mean=0.140, rw_bound=0.009, batch=203\n",
      "1792: loss=0.154, rw_mean=0.070, rw_bound=0.000, batch=210\n",
      "1793: loss=0.150, rw_mean=0.070, rw_bound=0.002, batch=217\n",
      "1794: loss=0.155, rw_mean=0.100, rw_bound=0.034, batch=221\n",
      "1795: loss=0.161, rw_mean=0.110, rw_bound=0.058, batch=224\n",
      "1796: loss=0.158, rw_mean=0.080, rw_bound=0.072, batch=223\n",
      "1797: loss=0.160, rw_mean=0.110, rw_bound=0.122, batch=222\n",
      "1798: loss=0.160, rw_mean=0.050, rw_bound=0.081, batch=225\n",
      "1799: loss=0.162, rw_mean=0.110, rw_bound=0.135, batch=226\n",
      "1800: loss=0.164, rw_mean=0.100, rw_bound=0.150, batch=225\n",
      "1801: loss=0.165, rw_mean=0.130, rw_bound=0.153, batch=227\n",
      "1802: loss=0.166, rw_mean=0.140, rw_bound=0.185, batch=226\n",
      "1803: loss=0.169, rw_mean=0.110, rw_bound=0.206, batch=225\n",
      "1804: loss=0.172, rw_mean=0.140, rw_bound=0.229, batch=219\n",
      "1805: loss=0.170, rw_mean=0.140, rw_bound=0.141, batch=223\n",
      "1806: loss=0.169, rw_mean=0.100, rw_bound=0.235, batch=226\n",
      "1807: loss=0.169, rw_mean=0.080, rw_bound=0.241, batch=228\n",
      "1808: loss=0.167, rw_mean=0.110, rw_bound=0.254, batch=223\n",
      "1809: loss=0.167, rw_mean=0.090, rw_bound=0.165, batch=226\n",
      "1810: loss=0.165, rw_mean=0.110, rw_bound=0.234, batch=228\n",
      "1811: loss=0.166, rw_mean=0.070, rw_bound=0.195, batch=229\n",
      "1812: loss=0.166, rw_mean=0.120, rw_bound=0.282, batch=225\n",
      "1813: loss=0.166, rw_mean=0.080, rw_bound=0.266, batch=227\n",
      "1814: loss=0.165, rw_mean=0.060, rw_bound=0.292, batch=229\n",
      "1815: loss=0.165, rw_mean=0.090, rw_bound=0.278, batch=230\n",
      "1816: loss=0.165, rw_mean=0.130, rw_bound=0.282, batch=230\n",
      "1817: loss=0.166, rw_mean=0.110, rw_bound=0.304, batch=231\n",
      "1818: loss=0.170, rw_mean=0.110, rw_bound=0.314, batch=168\n",
      "1819: loss=0.166, rw_mean=0.050, rw_bound=0.000, batch=173\n",
      "1820: loss=0.166, rw_mean=0.060, rw_bound=0.000, batch=179\n",
      "1821: loss=0.162, rw_mean=0.080, rw_bound=0.000, batch=187\n",
      "1822: loss=0.159, rw_mean=0.050, rw_bound=0.000, batch=192\n",
      "1823: loss=0.164, rw_mean=0.110, rw_bound=0.000, batch=203\n",
      "1824: loss=0.162, rw_mean=0.070, rw_bound=0.000, batch=210\n",
      "1825: loss=0.164, rw_mean=0.130, rw_bound=0.015, batch=217\n",
      "1826: loss=0.166, rw_mean=0.090, rw_bound=0.043, batch=222\n",
      "1827: loss=0.172, rw_mean=0.140, rw_bound=0.074, batch=225\n",
      "1828: loss=0.173, rw_mean=0.130, rw_bound=0.112, batch=227\n",
      "1829: loss=0.174, rw_mean=0.110, rw_bound=0.122, batch=228\n",
      "1830: loss=0.173, rw_mean=0.100, rw_bound=0.137, batch=229\n",
      "1831: loss=0.173, rw_mean=0.070, rw_bound=0.150, batch=226\n",
      "1832: loss=0.170, rw_mean=0.060, rw_bound=0.167, batch=226\n",
      "1833: loss=0.168, rw_mean=0.110, rw_bound=0.206, batch=222\n",
      "1834: loss=0.167, rw_mean=0.110, rw_bound=0.213, batch=225\n",
      "1835: loss=0.173, rw_mean=0.120, rw_bound=0.229, batch=225\n",
      "1836: loss=0.173, rw_mean=0.140, rw_bound=0.254, batch=221\n",
      "1837: loss=0.170, rw_mean=0.140, rw_bound=0.135, batch=224\n",
      "1838: loss=0.169, rw_mean=0.080, rw_bound=0.247, batch=227\n",
      "1839: loss=0.168, rw_mean=0.130, rw_bound=0.245, batch=229\n",
      "1840: loss=0.170, rw_mean=0.120, rw_bound=0.265, batch=230\n",
      "1841: loss=0.174, rw_mean=0.070, rw_bound=0.282, batch=214\n",
      "1842: loss=0.173, rw_mean=0.090, rw_bound=0.072, batch=219\n",
      "1843: loss=0.170, rw_mean=0.080, rw_bound=0.167, batch=222\n",
      "1844: loss=0.168, rw_mean=0.060, rw_bound=0.038, batch=225\n",
      "1845: loss=0.171, rw_mean=0.130, rw_bound=0.229, batch=225\n",
      "1846: loss=0.171, rw_mean=0.130, rw_bound=0.282, batch=226\n",
      "1847: loss=0.170, rw_mean=0.120, rw_bound=0.260, batch=228\n",
      "1848: loss=0.174, rw_mean=0.110, rw_bound=0.314, batch=214\n",
      "1849: loss=0.171, rw_mean=0.090, rw_bound=0.042, batch=220\n",
      "1850: loss=0.169, rw_mean=0.080, rw_bound=0.080, batch=223\n",
      "1851: loss=0.167, rw_mean=0.090, rw_bound=0.150, batch=225\n",
      "1852: loss=0.167, rw_mean=0.080, rw_bound=0.210, batch=227\n",
      "1853: loss=0.168, rw_mean=0.100, rw_bound=0.229, batch=228\n",
      "1854: loss=0.168, rw_mean=0.100, rw_bound=0.257, batch=229\n",
      "1855: loss=0.166, rw_mean=0.100, rw_bound=0.282, batch=228\n",
      "1856: loss=0.170, rw_mean=0.140, rw_bound=0.314, batch=226\n",
      "1857: loss=0.171, rw_mean=0.020, rw_bound=0.075, batch=228\n",
      "1858: loss=0.171, rw_mean=0.100, rw_bound=0.237, batch=229\n",
      "1859: loss=0.173, rw_mean=0.090, rw_bound=0.349, batch=177\n",
      "1860: loss=0.168, rw_mean=0.130, rw_bound=0.000, batch=190\n",
      "1861: loss=0.161, rw_mean=0.120, rw_bound=0.000, batch=202\n",
      "1862: loss=0.155, rw_mean=0.160, rw_bound=0.032, batch=211\n",
      "1863: loss=0.158, rw_mean=0.130, rw_bound=0.065, batch=214\n",
      "1864: loss=0.160, rw_mean=0.110, rw_bound=0.097, batch=220\n",
      "1865: loss=0.163, rw_mean=0.110, rw_bound=0.106, batch=224\n",
      "1866: loss=0.161, rw_mean=0.090, rw_bound=0.120, batch=227\n",
      "1867: loss=0.164, rw_mean=0.130, rw_bound=0.122, batch=228\n",
      "1868: loss=0.163, rw_mean=0.080, rw_bound=0.135, batch=228\n",
      "1869: loss=0.163, rw_mean=0.120, rw_bound=0.152, batch=229\n",
      "1870: loss=0.163, rw_mean=0.060, rw_bound=0.174, batch=230\n",
      "1871: loss=0.163, rw_mean=0.100, rw_bound=0.185, batch=229\n",
      "1872: loss=0.164, rw_mean=0.080, rw_bound=0.206, batch=229\n",
      "1873: loss=0.166, rw_mean=0.120, rw_bound=0.229, batch=228\n",
      "1874: loss=0.160, rw_mean=0.120, rw_bound=0.254, batch=226\n",
      "1875: loss=0.159, rw_mean=0.070, rw_bound=0.206, batch=227\n",
      "1876: loss=0.160, rw_mean=0.090, rw_bound=0.220, batch=229\n",
      "1877: loss=0.160, rw_mean=0.100, rw_bound=0.250, batch=230\n",
      "1878: loss=0.160, rw_mean=0.080, rw_bound=0.243, batch=231\n",
      "1879: loss=0.158, rw_mean=0.140, rw_bound=0.282, batch=224\n",
      "1880: loss=0.157, rw_mean=0.140, rw_bound=0.282, batch=226\n",
      "1881: loss=0.160, rw_mean=0.130, rw_bound=0.314, batch=218\n",
      "1882: loss=0.160, rw_mean=0.120, rw_bound=0.231, batch=222\n",
      "1883: loss=0.159, rw_mean=0.070, rw_bound=0.263, batch=225\n",
      "1884: loss=0.157, rw_mean=0.120, rw_bound=0.210, batch=227\n",
      "1885: loss=0.157, rw_mean=0.080, rw_bound=0.229, batch=227\n",
      "1886: loss=0.159, rw_mean=0.120, rw_bound=0.282, batch=227\n",
      "1887: loss=0.159, rw_mean=0.100, rw_bound=0.282, batch=228\n",
      "1888: loss=0.160, rw_mean=0.110, rw_bound=0.317, batch=229\n",
      "1889: loss=0.170, rw_mean=0.120, rw_bound=0.349, batch=214\n",
      "1890: loss=0.168, rw_mean=0.150, rw_bound=0.108, batch=220\n",
      "1891: loss=0.165, rw_mean=0.060, rw_bound=0.020, batch=224\n",
      "1892: loss=0.173, rw_mean=0.130, rw_bound=0.133, batch=227\n",
      "1893: loss=0.169, rw_mean=0.090, rw_bound=0.150, batch=228\n",
      "1894: loss=0.168, rw_mean=0.120, rw_bound=0.208, batch=229\n",
      "1895: loss=0.169, rw_mean=0.090, rw_bound=0.206, batch=229\n",
      "1896: loss=0.173, rw_mean=0.040, rw_bound=0.239, batch=230\n",
      "1897: loss=0.173, rw_mean=0.110, rw_bound=0.254, batch=228\n",
      "1898: loss=0.173, rw_mean=0.140, rw_bound=0.314, batch=226\n",
      "1899: loss=0.174, rw_mean=0.050, rw_bound=0.128, batch=228\n",
      "1900: loss=0.173, rw_mean=0.120, rw_bound=0.317, batch=229\n",
      "1901: loss=0.174, rw_mean=0.070, rw_bound=0.141, batch=230\n",
      "1902: loss=0.174, rw_mean=0.130, rw_bound=0.329, batch=231\n",
      "1903: loss=0.170, rw_mean=0.080, rw_bound=0.349, batch=228\n",
      "1904: loss=0.177, rw_mean=0.100, rw_bound=0.387, batch=138\n",
      "1905: loss=0.156, rw_mean=0.050, rw_bound=0.000, batch=143\n",
      "1906: loss=0.146, rw_mean=0.060, rw_bound=0.000, batch=149\n",
      "1907: loss=0.141, rw_mean=0.030, rw_bound=0.000, batch=152\n",
      "1908: loss=0.139, rw_mean=0.080, rw_bound=0.000, batch=160\n",
      "1909: loss=0.134, rw_mean=0.110, rw_bound=0.000, batch=171\n",
      "1910: loss=0.128, rw_mean=0.080, rw_bound=0.000, batch=179\n",
      "1911: loss=0.119, rw_mean=0.100, rw_bound=0.000, batch=189\n",
      "1912: loss=0.120, rw_mean=0.150, rw_bound=0.002, batch=202\n",
      "1913: loss=0.119, rw_mean=0.140, rw_bound=0.009, batch=209\n",
      "1914: loss=0.121, rw_mean=0.140, rw_bound=0.028, batch=214\n",
      "1915: loss=0.123, rw_mean=0.100, rw_bound=0.034, batch=217\n",
      "1916: loss=0.129, rw_mean=0.160, rw_bound=0.051, batch=222\n",
      "1917: loss=0.128, rw_mean=0.130, rw_bound=0.072, batch=222\n",
      "1918: loss=0.131, rw_mean=0.170, rw_bound=0.080, batch=222\n",
      "1919: loss=0.131, rw_mean=0.140, rw_bound=0.089, batch=224\n",
      "1920: loss=0.136, rw_mean=0.110, rw_bound=0.108, batch=227\n",
      "1921: loss=0.138, rw_mean=0.090, rw_bound=0.109, batch=227\n",
      "1922: loss=0.135, rw_mean=0.060, rw_bound=0.122, batch=228\n",
      "1923: loss=0.139, rw_mean=0.080, rw_bound=0.135, batch=224\n",
      "1924: loss=0.139, rw_mean=0.090, rw_bound=0.150, batch=220\n",
      "1925: loss=0.138, rw_mean=0.100, rw_bound=0.146, batch=224\n",
      "1926: loss=0.136, rw_mean=0.020, rw_bound=0.000, batch=226\n",
      "1927: loss=0.138, rw_mean=0.110, rw_bound=0.167, batch=227\n",
      "1928: loss=0.142, rw_mean=0.110, rw_bound=0.185, batch=222\n",
      "1929: loss=0.147, rw_mean=0.100, rw_bound=0.161, batch=225\n",
      "1930: loss=0.150, rw_mean=0.170, rw_bound=0.206, batch=220\n",
      "1931: loss=0.148, rw_mean=0.080, rw_bound=0.135, batch=223\n",
      "1932: loss=0.150, rw_mean=0.140, rw_bound=0.150, batch=225\n",
      "1933: loss=0.146, rw_mean=0.120, rw_bound=0.229, batch=222\n",
      "1934: loss=0.145, rw_mean=0.120, rw_bound=0.191, batch=225\n",
      "1935: loss=0.157, rw_mean=0.130, rw_bound=0.254, batch=213\n",
      "1936: loss=0.157, rw_mean=0.120, rw_bound=0.177, batch=219\n",
      "1937: loss=0.154, rw_mean=0.120, rw_bound=0.229, batch=222\n",
      "1938: loss=0.152, rw_mean=0.130, rw_bound=0.236, batch=225\n",
      "1939: loss=0.152, rw_mean=0.110, rw_bound=0.234, batch=227\n",
      "1940: loss=0.151, rw_mean=0.060, rw_bound=0.090, batch=229\n",
      "1941: loss=0.153, rw_mean=0.160, rw_bound=0.215, batch=230\n",
      "1942: loss=0.155, rw_mean=0.100, rw_bound=0.254, batch=229\n",
      "1943: loss=0.154, rw_mean=0.140, rw_bound=0.282, batch=221\n",
      "1944: loss=0.155, rw_mean=0.060, rw_bound=0.089, batch=224\n",
      "1945: loss=0.157, rw_mean=0.140, rw_bound=0.229, batch=224\n",
      "1946: loss=0.155, rw_mean=0.080, rw_bound=0.069, batch=227\n",
      "1947: loss=0.154, rw_mean=0.130, rw_bound=0.277, batch=229\n",
      "1948: loss=0.154, rw_mean=0.050, rw_bound=0.237, batch=230\n",
      "1949: loss=0.155, rw_mean=0.080, rw_bound=0.282, batch=230\n",
      "1950: loss=0.160, rw_mean=0.110, rw_bound=0.314, batch=216\n",
      "1951: loss=0.153, rw_mean=0.060, rw_bound=0.002, batch=221\n",
      "1952: loss=0.156, rw_mean=0.120, rw_bound=0.098, batch=224\n",
      "1953: loss=0.158, rw_mean=0.060, rw_bound=0.162, batch=227\n",
      "1954: loss=0.158, rw_mean=0.130, rw_bound=0.206, batch=228\n",
      "1955: loss=0.156, rw_mean=0.120, rw_bound=0.229, batch=228\n",
      "1956: loss=0.159, rw_mean=0.050, rw_bound=0.254, batch=227\n",
      "1957: loss=0.159, rw_mean=0.070, rw_bound=0.272, batch=229\n",
      "1958: loss=0.158, rw_mean=0.070, rw_bound=0.203, batch=230\n",
      "1959: loss=0.158, rw_mean=0.140, rw_bound=0.282, batch=229\n",
      "1960: loss=0.156, rw_mean=0.130, rw_bound=0.314, batch=226\n",
      "1961: loss=0.157, rw_mean=0.090, rw_bound=0.158, batch=228\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m full_batch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterate_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreward_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_bound\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilter_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPERCENTILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36miterate_batches\u001b[0;34m(env, net, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     obs_v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([obs])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m     act_probs_v \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_v\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     act_probs \u001b[38;5;241m=\u001b[39m act_probs_v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(act_probs), p\u001b[38;5;241m=\u001b[39mact_probs)\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/activation.py:1545\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/functional.py:1881\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply a softmax function.\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \n\u001b[1;32m   1858\u001b[0m \u001b[38;5;124;03mSoftmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \n\u001b[1;32m   1879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m-> 1881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stacklevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1883\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/utils/_device.py:76\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, types, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     75\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_device_constructors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_batch = []\n",
    "\n",
    "with torch.device(device):\n",
    "    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        \n",
    "        reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "\n",
    "        full_batch, obs, acts, reward_bound = filter_batch(full_batch + batch, PERCENTILE)\n",
    "\n",
    "        if not full_batch:\n",
    "            continue\n",
    "\n",
    "        obs_v = torch.FloatTensor(obs).to(device)\n",
    "        acts_v = torch.LongTensor(acts).to(device)\n",
    "        full_batch = full_batch[-500:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        action_scores_v = net(obs_v)\n",
    "\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"%d: loss=%.3f, rw_mean=%.3f, rw_bound=%.3f, batch=%d\" % (\n",
    "            iter_no, loss_v.item(), reward_mean, reward_bound, len(full_batch))\n",
    "        )\n",
    "\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "\n",
    "        if reward_mean > 0.8:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from collections import OrderedDict\n",
    "from lib.architecture import Search\n",
    "from lib.sample import SampleNormal, SampleUniform\n",
    "\n",
    "def create_model(input_size, hidden_size, output_size):\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.LayerNorm(hidden_size)\n",
    "    )\n",
    "\n",
    "    search = Search(\n",
    "        transition=nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 2*hidden_size),\n",
    "        ),\n",
    "        fitness=nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        ),\n",
    "        sample=nn.Sequential(\n",
    "            SampleNormal(hidden_size, num_samples=4),\n",
    "            nn.LayerNorm(hidden_size)\n",
    "        ),\n",
    "        max_depth=2,\n",
    "        beam_width=4\n",
    "    )\n",
    "\n",
    "    decoder = nn.Sequential(\n",
    "        nn.Linear(hidden_size, output_size)\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('encoder', encoder),\n",
    "        ('search', search),\n",
    "        ('decoder', decoder)\n",
    "    ]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "env = DiscreteOneHotWrapper(gym.make(\"FrozenLake-v1\", desc=generate_random_map(size=4), is_slippery=True))\n",
    "\n",
    "# env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = create_model(obs_size, 16, n_actions).to(device)\n",
    "\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "writer = SummaryWriter(comment=\"-frozenlake-search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('number of parameters', 1509)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'number of parameters', sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahim/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/utils/_device.py:78: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3679.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=1.374, rw_mean=0.070, rw_bound=0.000000, batch=7\n",
      "1: loss=1.411, rw_mean=0.090, rw_bound=0.000000, batch=16\n",
      "2: loss=1.375, rw_mean=0.040, rw_bound=0.000000, batch=20\n",
      "3: loss=1.380, rw_mean=0.050, rw_bound=0.000000, batch=25\n",
      "4: loss=1.384, rw_mean=0.050, rw_bound=0.000000, batch=30\n",
      "5: loss=1.369, rw_mean=0.070, rw_bound=0.000000, batch=37\n",
      "6: loss=1.357, rw_mean=0.070, rw_bound=0.000000, batch=44\n",
      "7: loss=1.370, rw_mean=0.040, rw_bound=0.000000, batch=48\n",
      "8: loss=1.364, rw_mean=0.060, rw_bound=0.000000, batch=54\n",
      "9: loss=1.362, rw_mean=0.040, rw_bound=0.000000, batch=58\n",
      "10: loss=1.363, rw_mean=0.080, rw_bound=0.000000, batch=66\n",
      "11: loss=1.360, rw_mean=0.050, rw_bound=0.000000, batch=71\n",
      "12: loss=1.349, rw_mean=0.070, rw_bound=0.000000, batch=78\n",
      "13: loss=1.360, rw_mean=0.090, rw_bound=0.000000, batch=87\n",
      "14: loss=1.362, rw_mean=0.050, rw_bound=0.000000, batch=92\n",
      "15: loss=1.361, rw_mean=0.070, rw_bound=0.000000, batch=99\n",
      "16: loss=1.353, rw_mean=0.100, rw_bound=0.000000, batch=109\n",
      "17: loss=1.351, rw_mean=0.090, rw_bound=0.000000, batch=118\n",
      "18: loss=1.353, rw_mean=0.070, rw_bound=0.000000, batch=125\n",
      "19: loss=1.352, rw_mean=0.060, rw_bound=0.000000, batch=131\n",
      "20: loss=1.352, rw_mean=0.040, rw_bound=0.000000, batch=135\n",
      "21: loss=1.352, rw_mean=0.060, rw_bound=0.000000, batch=141\n",
      "22: loss=1.351, rw_mean=0.060, rw_bound=0.000000, batch=147\n",
      "23: loss=1.349, rw_mean=0.100, rw_bound=0.000000, batch=157\n",
      "24: loss=1.347, rw_mean=0.070, rw_bound=0.000000, batch=164\n",
      "25: loss=1.345, rw_mean=0.120, rw_bound=0.000000, batch=176\n",
      "26: loss=1.347, rw_mean=0.050, rw_bound=0.000000, batch=181\n",
      "27: loss=1.345, rw_mean=0.040, rw_bound=0.000000, batch=185\n",
      "28: loss=1.344, rw_mean=0.110, rw_bound=0.000000, batch=196\n",
      "29: loss=1.343, rw_mean=0.070, rw_bound=0.000000, batch=203\n",
      "30: loss=1.343, rw_mean=0.040, rw_bound=0.000000, batch=207\n",
      "31: loss=1.343, rw_mean=0.050, rw_bound=0.000000, batch=212\n",
      "32: loss=1.340, rw_mean=0.080, rw_bound=0.000745, batch=218\n",
      "33: loss=1.338, rw_mean=0.030, rw_bound=0.000000, batch=221\n",
      "34: loss=1.339, rw_mean=0.070, rw_bound=0.001617, batch=224\n",
      "35: loss=1.334, rw_mean=0.100, rw_bound=0.007706, batch=227\n",
      "36: loss=1.333, rw_mean=0.050, rw_bound=0.010775, batch=228\n",
      "37: loss=1.331, rw_mean=0.070, rw_bound=0.016606, batch=229\n",
      "38: loss=1.333, rw_mean=0.040, rw_bound=0.020276, batch=229\n",
      "39: loss=1.332, rw_mean=0.080, rw_bound=0.026144, batch=230\n",
      "40: loss=1.329, rw_mean=0.060, rw_bound=0.034337, batch=230\n",
      "41: loss=1.330, rw_mean=0.040, rw_bound=0.038152, batch=230\n",
      "42: loss=1.330, rw_mean=0.050, rw_bound=0.047101, batch=230\n",
      "43: loss=1.325, rw_mean=0.120, rw_bound=0.058150, batch=228\n",
      "44: loss=1.321, rw_mean=0.120, rw_bound=0.079766, batch=225\n",
      "45: loss=1.319, rw_mean=0.050, rw_bound=0.088629, batch=220\n",
      "46: loss=1.319, rw_mean=0.080, rw_bound=0.098477, batch=218\n",
      "47: loss=1.315, rw_mean=0.070, rw_bound=0.109419, batch=216\n",
      "48: loss=1.315, rw_mean=0.070, rw_bound=0.109419, batch=220\n",
      "49: loss=1.315, rw_mean=0.030, rw_bound=0.000000, batch=223\n",
      "50: loss=1.311, rw_mean=0.080, rw_bound=0.090993, batch=226\n",
      "51: loss=1.311, rw_mean=0.040, rw_bound=0.121577, batch=222\n",
      "52: loss=1.310, rw_mean=0.080, rw_bound=0.135085, batch=214\n",
      "53: loss=1.306, rw_mean=0.090, rw_bound=0.096606, batch=220\n",
      "54: loss=1.305, rw_mean=0.070, rw_bound=0.150095, batch=216\n",
      "55: loss=1.301, rw_mean=0.100, rw_bound=0.150928, batch=221\n",
      "56: loss=1.299, rw_mean=0.080, rw_bound=0.079766, batch=224\n",
      "57: loss=1.295, rw_mean=0.040, rw_bound=0.148594, batch=227\n",
      "58: loss=1.293, rw_mean=0.090, rw_bound=0.166772, batch=216\n",
      "59: loss=1.287, rw_mean=0.090, rw_bound=0.185302, batch=213\n",
      "60: loss=1.289, rw_mean=0.080, rw_bound=0.135515, batch=219\n",
      "61: loss=1.288, rw_mean=0.130, rw_bound=0.182420, batch=223\n",
      "62: loss=1.278, rw_mean=0.100, rw_bound=0.205891, batch=204\n",
      "63: loss=1.276, rw_mean=0.110, rw_bound=0.177714, batch=213\n",
      "64: loss=1.274, rw_mean=0.050, rw_bound=0.000000, batch=218\n",
      "65: loss=1.277, rw_mean=0.090, rw_bound=0.150095, batch=221\n",
      "66: loss=1.276, rw_mean=0.050, rw_bound=0.185302, batch=223\n",
      "67: loss=1.277, rw_mean=0.090, rw_bound=0.228768, batch=208\n",
      "68: loss=1.271, rw_mean=0.070, rw_bound=0.000376, batch=215\n",
      "69: loss=1.275, rw_mean=0.050, rw_bound=0.000113, batch=220\n",
      "70: loss=1.276, rw_mean=0.060, rw_bound=0.027834, batch=224\n",
      "71: loss=1.275, rw_mean=0.040, rw_bound=0.014500, batch=227\n",
      "72: loss=1.270, rw_mean=0.100, rw_bound=0.132383, batch=229\n",
      "73: loss=1.270, rw_mean=0.080, rw_bound=0.228768, batch=229\n",
      "74: loss=1.267, rw_mean=0.110, rw_bound=0.254187, batch=203\n",
      "75: loss=1.265, rw_mean=0.120, rw_bound=0.160101, batch=212\n",
      "76: loss=1.264, rw_mean=0.110, rw_bound=0.166772, batch=217\n",
      "77: loss=1.260, rw_mean=0.120, rw_bound=0.205891, batch=219\n",
      "78: loss=1.256, rw_mean=0.150, rw_bound=0.282430, batch=188\n",
      "79: loss=1.255, rw_mean=0.080, rw_bound=0.000000, batch=196\n",
      "80: loss=1.249, rw_mean=0.110, rw_bound=0.006651, batch=207\n",
      "81: loss=1.250, rw_mean=0.100, rw_bound=0.019505, batch=215\n",
      "82: loss=1.250, rw_mean=0.080, rw_bound=0.071790, batch=219\n",
      "83: loss=1.247, rw_mean=0.100, rw_bound=0.083312, batch=223\n",
      "84: loss=1.248, rw_mean=0.070, rw_bound=0.120442, batch=226\n",
      "85: loss=1.251, rw_mean=0.080, rw_bound=0.142590, batch=228\n",
      "86: loss=1.250, rw_mean=0.090, rw_bound=0.168625, batch=229\n",
      "87: loss=1.247, rw_mean=0.090, rw_bound=0.215042, batch=230\n",
      "88: loss=1.245, rw_mean=0.110, rw_bound=0.246561, batch=231\n",
      "89: loss=1.245, rw_mean=0.030, rw_bound=0.254187, batch=228\n",
      "90: loss=1.245, rw_mean=0.130, rw_bound=0.282430, batch=220\n",
      "91: loss=1.246, rw_mean=0.050, rw_bound=0.069967, batch=224\n",
      "92: loss=1.241, rw_mean=0.100, rw_bound=0.185302, batch=226\n",
      "93: loss=1.242, rw_mean=0.100, rw_bound=0.268308, batch=228\n",
      "94: loss=1.241, rw_mean=0.070, rw_bound=0.149820, batch=229\n",
      "95: loss=1.242, rw_mean=0.090, rw_bound=0.265484, batch=230\n",
      "96: loss=1.239, rw_mean=0.110, rw_bound=0.313811, batch=193\n",
      "97: loss=1.241, rw_mean=0.070, rw_bound=0.000000, batch=200\n",
      "98: loss=1.244, rw_mean=0.100, rw_bound=0.001553, batch=210\n",
      "99: loss=1.241, rw_mean=0.120, rw_bound=0.075220, batch=217\n",
      "100: loss=1.239, rw_mean=0.070, rw_bound=0.079766, batch=221\n",
      "101: loss=1.238, rw_mean=0.090, rw_bound=0.098477, batch=223\n",
      "102: loss=1.232, rw_mean=0.080, rw_bound=0.150095, batch=225\n",
      "103: loss=1.231, rw_mean=0.050, rw_bound=0.141423, batch=227\n",
      "104: loss=1.231, rw_mean=0.060, rw_bound=0.166772, batch=227\n",
      "105: loss=1.229, rw_mean=0.070, rw_bound=0.201773, batch=229\n",
      "106: loss=1.227, rw_mean=0.060, rw_bound=0.163408, batch=230\n",
      "107: loss=1.229, rw_mean=0.100, rw_bound=0.205891, batch=230\n",
      "108: loss=1.226, rw_mean=0.110, rw_bound=0.282430, batch=228\n",
      "109: loss=1.226, rw_mean=0.100, rw_bound=0.313811, batch=227\n",
      "110: loss=1.222, rw_mean=0.120, rw_bound=0.341705, batch=229\n",
      "111: loss=1.209, rw_mean=0.080, rw_bound=0.348678, batch=174\n",
      "112: loss=1.194, rw_mean=0.120, rw_bound=0.000000, batch=186\n",
      "113: loss=1.183, rw_mean=0.140, rw_bound=0.015452, batch=200\n",
      "114: loss=1.189, rw_mean=0.140, rw_bound=0.054835, batch=210\n",
      "115: loss=1.187, rw_mean=0.090, rw_bound=0.062672, batch=217\n",
      "116: loss=1.183, rw_mean=0.090, rw_bound=0.098477, batch=221\n",
      "117: loss=1.191, rw_mean=0.190, rw_bound=0.150095, batch=224\n",
      "118: loss=1.187, rw_mean=0.110, rw_bound=0.203832, batch=227\n",
      "119: loss=1.189, rw_mean=0.130, rw_bound=0.228768, batch=226\n",
      "120: loss=1.191, rw_mean=0.160, rw_bound=0.254187, batch=223\n",
      "121: loss=1.188, rw_mean=0.100, rw_bound=0.282430, batch=220\n",
      "122: loss=1.182, rw_mean=0.070, rw_bound=0.150095, batch=223\n",
      "123: loss=1.186, rw_mean=0.080, rw_bound=0.185302, batch=225\n",
      "124: loss=1.188, rw_mean=0.140, rw_bound=0.313811, batch=221\n",
      "125: loss=1.188, rw_mean=0.070, rw_bound=0.282430, batch=224\n",
      "126: loss=1.182, rw_mean=0.010, rw_bound=0.000000, batch=225\n",
      "127: loss=1.184, rw_mean=0.100, rw_bound=0.179171, batch=227\n",
      "128: loss=1.186, rw_mean=0.090, rw_bound=0.254187, batch=228\n",
      "129: loss=1.185, rw_mean=0.120, rw_bound=0.348678, batch=216\n",
      "130: loss=1.185, rw_mean=0.080, rw_bound=0.158433, batch=221\n",
      "131: loss=1.182, rw_mean=0.140, rw_bound=0.282430, batch=224\n",
      "132: loss=1.183, rw_mean=0.070, rw_bound=0.249357, batch=227\n",
      "133: loss=1.184, rw_mean=0.100, rw_bound=0.282430, batch=228\n",
      "134: loss=1.182, rw_mean=0.150, rw_bound=0.313811, batch=228\n",
      "135: loss=1.181, rw_mean=0.160, rw_bound=0.348678, batch=228\n",
      "136: loss=1.167, rw_mean=0.120, rw_bound=0.387420, batch=159\n",
      "137: loss=1.175, rw_mean=0.100, rw_bound=0.000000, batch=169\n",
      "138: loss=1.167, rw_mean=0.090, rw_bound=0.000000, batch=178\n",
      "139: loss=1.162, rw_mean=0.130, rw_bound=0.000000, batch=191\n",
      "140: loss=1.160, rw_mean=0.080, rw_bound=0.000000, batch=199\n",
      "141: loss=1.157, rw_mean=0.130, rw_bound=0.027813, batch=207\n",
      "142: loss=1.160, rw_mean=0.070, rw_bound=0.000000, batch=214\n",
      "143: loss=1.158, rw_mean=0.120, rw_bound=0.057568, batch=220\n",
      "144: loss=1.156, rw_mean=0.150, rw_bound=0.098477, batch=220\n",
      "145: loss=1.155, rw_mean=0.050, rw_bound=0.109419, batch=221\n",
      "146: loss=1.157, rw_mean=0.120, rw_bound=0.135085, batch=224\n",
      "147: loss=1.157, rw_mean=0.160, rw_bound=0.185302, batch=222\n",
      "148: loss=1.154, rw_mean=0.120, rw_bound=0.205891, batch=221\n",
      "149: loss=1.147, rw_mean=0.130, rw_bound=0.254187, batch=213\n",
      "150: loss=1.143, rw_mean=0.140, rw_bound=0.254187, batch=218\n",
      "151: loss=1.147, rw_mean=0.100, rw_bound=0.282430, batch=217\n",
      "152: loss=1.146, rw_mean=0.060, rw_bound=0.104892, batch=222\n",
      "153: loss=1.144, rw_mean=0.110, rw_bound=0.185371, batch=225\n",
      "154: loss=1.146, rw_mean=0.140, rw_bound=0.282430, batch=224\n",
      "155: loss=1.144, rw_mean=0.150, rw_bound=0.313811, batch=216\n",
      "156: loss=1.146, rw_mean=0.120, rw_bound=0.348678, batch=203\n",
      "157: loss=1.139, rw_mean=0.140, rw_bound=0.139454, batch=212\n",
      "158: loss=1.139, rw_mean=0.090, rw_bound=0.073107, batch=218\n",
      "159: loss=1.143, rw_mean=0.120, rw_bound=0.166772, batch=221\n",
      "160: loss=1.145, rw_mean=0.100, rw_bound=0.205891, batch=223\n",
      "161: loss=1.145, rw_mean=0.180, rw_bound=0.282430, batch=225\n",
      "162: loss=1.146, rw_mean=0.100, rw_bound=0.204728, batch=227\n",
      "163: loss=1.143, rw_mean=0.100, rw_bound=0.307534, batch=229\n",
      "164: loss=1.143, rw_mean=0.110, rw_bound=0.313811, batch=228\n",
      "165: loss=1.139, rw_mean=0.100, rw_bound=0.348678, batch=225\n",
      "166: loss=1.138, rw_mean=0.190, rw_bound=0.387420, batch=205\n",
      "167: loss=1.141, rw_mean=0.090, rw_bound=0.004151, batch=213\n",
      "168: loss=1.131, rw_mean=0.140, rw_bound=0.139454, batch=219\n",
      "169: loss=1.135, rw_mean=0.120, rw_bound=0.254187, batch=220\n",
      "170: loss=1.135, rw_mean=0.140, rw_bound=0.221905, batch=224\n",
      "171: loss=1.132, rw_mean=0.140, rw_bound=0.282430, batch=224\n",
      "172: loss=1.135, rw_mean=0.120, rw_bound=0.279605, batch=227\n",
      "173: loss=1.135, rw_mean=0.090, rw_bound=0.307534, batch=229\n",
      "174: loss=1.134, rw_mean=0.060, rw_bound=0.348678, batch=226\n",
      "175: loss=1.136, rw_mean=0.150, rw_bound=0.387420, batch=225\n",
      "176: loss=1.132, rw_mean=0.210, rw_bound=0.430467, batch=113\n",
      "177: loss=1.120, rw_mean=0.090, rw_bound=0.000000, batch=122\n",
      "178: loss=1.121, rw_mean=0.110, rw_bound=0.000000, batch=133\n",
      "179: loss=1.118, rw_mean=0.120, rw_bound=0.000000, batch=145\n",
      "180: loss=1.120, rw_mean=0.120, rw_bound=0.000000, batch=157\n",
      "181: loss=1.122, rw_mean=0.120, rw_bound=0.000000, batch=169\n",
      "182: loss=1.123, rw_mean=0.160, rw_bound=0.000000, batch=185\n",
      "183: loss=1.121, rw_mean=0.120, rw_bound=0.000000, batch=197\n",
      "184: loss=1.124, rw_mean=0.120, rw_bound=0.001155, batch=208\n",
      "185: loss=1.124, rw_mean=0.110, rw_bound=0.006512, batch=215\n",
      "186: loss=1.121, rw_mean=0.120, rw_bound=0.023585, batch=220\n",
      "187: loss=1.122, rw_mean=0.110, rw_bound=0.058150, batch=223\n",
      "188: loss=1.126, rw_mean=0.110, rw_bound=0.088629, batch=222\n",
      "189: loss=1.124, rw_mean=0.170, rw_bound=0.109419, batch=222\n",
      "190: loss=1.118, rw_mean=0.180, rw_bound=0.166772, batch=224\n",
      "191: loss=1.115, rw_mean=0.130, rw_bound=0.185302, batch=223\n",
      "192: loss=1.118, rw_mean=0.160, rw_bound=0.205891, batch=221\n",
      "193: loss=1.106, rw_mean=0.090, rw_bound=0.228768, batch=208\n",
      "194: loss=1.104, rw_mean=0.100, rw_bound=0.124428, batch=215\n",
      "195: loss=1.107, rw_mean=0.110, rw_bound=0.170478, batch=220\n",
      "196: loss=1.103, rw_mean=0.100, rw_bound=0.221905, batch=224\n",
      "197: loss=1.102, rw_mean=0.130, rw_bound=0.251645, batch=227\n",
      "198: loss=1.100, rw_mean=0.100, rw_bound=0.254187, batch=224\n",
      "199: loss=1.101, rw_mean=0.050, rw_bound=0.274776, batch=227\n",
      "200: loss=1.094, rw_mean=0.180, rw_bound=0.282430, batch=216\n",
      "201: loss=1.088, rw_mean=0.160, rw_bound=0.313811, batch=199\n",
      "202: loss=1.083, rw_mean=0.110, rw_bound=0.052636, batch=209\n",
      "203: loss=1.084, rw_mean=0.140, rw_bound=0.141089, batch=216\n",
      "204: loss=1.087, rw_mean=0.170, rw_bound=0.254187, batch=219\n",
      "205: loss=1.086, rw_mean=0.170, rw_bound=0.250233, batch=223\n",
      "206: loss=1.080, rw_mean=0.130, rw_bound=0.301258, batch=226\n",
      "207: loss=1.081, rw_mean=0.140, rw_bound=0.313811, batch=225\n",
      "208: loss=1.082, rw_mean=0.080, rw_bound=0.176562, batch=227\n",
      "209: loss=1.082, rw_mean=0.120, rw_bound=0.341705, batch=229\n",
      "210: loss=1.079, rw_mean=0.140, rw_bound=0.348678, batch=205\n",
      "211: loss=1.078, rw_mean=0.180, rw_bound=0.199079, batch=213\n",
      "212: loss=1.073, rw_mean=0.090, rw_bound=0.219221, batch=219\n",
      "213: loss=1.068, rw_mean=0.100, rw_bound=0.238935, batch=223\n",
      "214: loss=1.068, rw_mean=0.140, rw_bound=0.254187, batch=225\n",
      "215: loss=1.068, rw_mean=0.070, rw_bound=0.288706, batch=227\n",
      "216: loss=1.068, rw_mean=0.110, rw_bound=0.313811, batch=228\n",
      "217: loss=1.058, rw_mean=0.160, rw_bound=0.387420, batch=197\n",
      "218: loss=1.060, rw_mean=0.110, rw_bound=0.011825, batch=208\n",
      "219: loss=1.052, rw_mean=0.110, rw_bound=0.059514, batch=215\n",
      "220: loss=1.050, rw_mean=0.070, rw_bound=0.036608, batch=220\n",
      "221: loss=1.052, rw_mean=0.110, rw_bound=0.174740, batch=224\n",
      "222: loss=1.051, rw_mean=0.140, rw_bound=0.228768, batch=226\n",
      "223: loss=1.056, rw_mean=0.110, rw_bound=0.282430, batch=225\n",
      "224: loss=1.054, rw_mean=0.150, rw_bound=0.348678, batch=222\n",
      "225: loss=1.057, rw_mean=0.150, rw_bound=0.387420, batch=218\n",
      "226: loss=1.059, rw_mean=0.090, rw_bound=0.348678, batch=220\n",
      "227: loss=1.056, rw_mean=0.110, rw_bound=0.288298, batch=224\n",
      "228: loss=1.056, rw_mean=0.130, rw_bound=0.348678, batch=226\n",
      "229: loss=1.055, rw_mean=0.130, rw_bound=0.350616, batch=228\n",
      "230: loss=1.056, rw_mean=0.090, rw_bound=0.387420, batch=227\n",
      "231: loss=1.055, rw_mean=0.070, rw_bound=0.366422, batch=229\n",
      "232: loss=1.053, rw_mean=0.100, rw_bound=0.364175, batch=230\n",
      "233: loss=1.053, rw_mean=0.110, rw_bound=0.199714, batch=231\n",
      "234: loss=1.054, rw_mean=0.140, rw_bound=0.387420, batch=230\n",
      "235: loss=1.074, rw_mean=0.120, rw_bound=0.430467, batch=187\n",
      "236: loss=1.079, rw_mean=0.140, rw_bound=0.002705, batch=201\n",
      "237: loss=1.074, rw_mean=0.140, rw_bound=0.047101, batch=210\n",
      "238: loss=1.074, rw_mean=0.130, rw_bound=0.145592, batch=217\n",
      "239: loss=1.066, rw_mean=0.140, rw_bound=0.185302, batch=221\n",
      "240: loss=1.066, rw_mean=0.200, rw_bound=0.282430, batch=224\n",
      "241: loss=1.061, rw_mean=0.150, rw_bound=0.313811, batch=223\n",
      "242: loss=1.064, rw_mean=0.130, rw_bound=0.310882, batch=226\n",
      "243: loss=1.064, rw_mean=0.170, rw_bound=0.331245, batch=228\n",
      "244: loss=1.067, rw_mean=0.160, rw_bound=0.348678, batch=222\n",
      "245: loss=1.067, rw_mean=0.110, rw_bound=0.264741, batch=225\n",
      "246: loss=1.064, rw_mean=0.170, rw_bound=0.356427, batch=227\n",
      "247: loss=1.062, rw_mean=0.140, rw_bound=0.387420, batch=220\n",
      "248: loss=1.061, rw_mean=0.160, rw_bound=0.387420, batch=223\n",
      "249: loss=1.061, rw_mean=0.180, rw_bound=0.397752, batch=226\n",
      "250: loss=1.061, rw_mean=0.090, rw_bound=0.408944, batch=228\n",
      "251: loss=1.064, rw_mean=0.060, rw_bound=0.430467, batch=212\n",
      "252: loss=1.058, rw_mean=0.070, rw_bound=0.077999, batch=218\n",
      "253: loss=1.061, rw_mean=0.130, rw_bound=0.234134, batch=222\n",
      "254: loss=1.061, rw_mean=0.120, rw_bound=0.282430, batch=224\n",
      "255: loss=1.061, rw_mean=0.100, rw_bound=0.310672, batch=227\n",
      "256: loss=1.060, rw_mean=0.100, rw_bound=0.313811, batch=228\n",
      "257: loss=1.056, rw_mean=0.120, rw_bound=0.348678, batch=228\n",
      "258: loss=1.056, rw_mean=0.100, rw_bound=0.387420, batch=228\n",
      "259: loss=1.059, rw_mean=0.130, rw_bound=0.391725, batch=229\n",
      "260: loss=1.060, rw_mean=0.180, rw_bound=0.430467, batch=224\n",
      "261: loss=1.059, rw_mean=0.140, rw_bound=0.478297, batch=128\n",
      "262: loss=1.036, rw_mean=0.170, rw_bound=0.000000, batch=145\n",
      "263: loss=1.035, rw_mean=0.140, rw_bound=0.000000, batch=159\n",
      "264: loss=1.029, rw_mean=0.140, rw_bound=0.000000, batch=173\n",
      "265: loss=1.029, rw_mean=0.080, rw_bound=0.000000, batch=181\n",
      "266: loss=1.019, rw_mean=0.140, rw_bound=0.000000, batch=195\n",
      "267: loss=1.021, rw_mean=0.100, rw_bound=0.000000, batch=205\n",
      "268: loss=1.023, rw_mean=0.170, rw_bound=0.054790, batch=213\n",
      "269: loss=1.021, rw_mean=0.090, rw_bound=0.064611, batch=218\n",
      "270: loss=1.028, rw_mean=0.090, rw_bound=0.089614, batch=222\n",
      "271: loss=1.020, rw_mean=0.120, rw_bound=0.098477, batch=223\n",
      "272: loss=1.018, rw_mean=0.110, rw_bound=0.129682, batch=226\n",
      "273: loss=1.023, rw_mean=0.170, rw_bound=0.166772, batch=222\n",
      "274: loss=1.027, rw_mean=0.100, rw_bound=0.205891, batch=216\n",
      "275: loss=1.029, rw_mean=0.120, rw_bound=0.228768, batch=215\n",
      "276: loss=1.030, rw_mean=0.140, rw_bound=0.170478, batch=220\n",
      "277: loss=1.032, rw_mean=0.170, rw_bound=0.254187, batch=217\n",
      "278: loss=1.033, rw_mean=0.110, rw_bound=0.282430, batch=212\n",
      "279: loss=1.030, rw_mean=0.130, rw_bound=0.205891, batch=217\n",
      "280: loss=1.028, rw_mean=0.080, rw_bound=0.194732, batch=222\n",
      "281: loss=1.030, rw_mean=0.150, rw_bound=0.313811, batch=214\n",
      "282: loss=1.031, rw_mean=0.150, rw_bound=0.342054, batch=220\n",
      "283: loss=1.027, rw_mean=0.090, rw_bound=0.348678, batch=204\n",
      "284: loss=1.022, rw_mean=0.100, rw_bound=0.113658, batch=213\n",
      "285: loss=1.016, rw_mean=0.090, rw_bound=0.203969, batch=219\n",
      "286: loss=1.015, rw_mean=0.160, rw_bound=0.215042, batch=223\n",
      "287: loss=1.016, rw_mean=0.100, rw_bound=0.254187, batch=224\n",
      "288: loss=1.015, rw_mean=0.160, rw_bound=0.282430, batch=224\n",
      "289: loss=1.013, rw_mean=0.080, rw_bound=0.305306, batch=227\n",
      "290: loss=1.018, rw_mean=0.120, rw_bound=0.313811, batch=227\n",
      "291: loss=1.015, rw_mean=0.140, rw_bound=0.348678, batch=223\n",
      "292: loss=1.008, rw_mean=0.140, rw_bound=0.387420, batch=199\n",
      "293: loss=1.000, rw_mean=0.110, rw_bound=0.068020, batch=209\n",
      "294: loss=0.997, rw_mean=0.130, rw_bound=0.156766, batch=216\n",
      "295: loss=1.004, rw_mean=0.090, rw_bound=0.230039, batch=221\n",
      "296: loss=1.010, rw_mean=0.150, rw_bound=0.282430, batch=222\n",
      "297: loss=1.007, rw_mean=0.130, rw_bound=0.348678, batch=222\n",
      "298: loss=1.008, rw_mean=0.130, rw_bound=0.387420, batch=219\n",
      "299: loss=1.006, rw_mean=0.120, rw_bound=0.265484, batch=223\n",
      "300: loss=1.001, rw_mean=0.150, rw_bound=0.313811, batch=225\n",
      "301: loss=1.001, rw_mean=0.100, rw_bound=0.348678, batch=225\n",
      "302: loss=1.010, rw_mean=0.140, rw_bound=0.430467, batch=189\n",
      "303: loss=0.999, rw_mean=0.160, rw_bound=0.078526, batch=202\n",
      "304: loss=1.009, rw_mean=0.190, rw_bound=0.150095, batch=210\n",
      "305: loss=1.011, rw_mean=0.060, rw_bound=0.000000, batch=216\n",
      "306: loss=1.004, rw_mean=0.100, rw_bound=0.158433, batch=221\n",
      "307: loss=1.002, rw_mean=0.110, rw_bound=0.185302, batch=223\n",
      "308: loss=0.997, rw_mean=0.140, rw_bound=0.219617, batch=226\n",
      "309: loss=1.000, rw_mean=0.110, rw_bound=0.228768, batch=227\n",
      "310: loss=0.999, rw_mean=0.150, rw_bound=0.282430, batch=224\n",
      "311: loss=0.994, rw_mean=0.100, rw_bound=0.313811, batch=222\n",
      "312: loss=0.995, rw_mean=0.100, rw_bound=0.236394, batch=225\n",
      "313: loss=1.001, rw_mean=0.150, rw_bound=0.348678, batch=218\n",
      "314: loss=0.998, rw_mean=0.090, rw_bound=0.292929, batch=222\n",
      "315: loss=0.997, rw_mean=0.130, rw_bound=0.387420, batch=221\n",
      "316: loss=0.996, rw_mean=0.080, rw_bound=0.282430, batch=224\n",
      "317: loss=0.997, rw_mean=0.140, rw_bound=0.345192, batch=227\n",
      "318: loss=0.996, rw_mean=0.080, rw_bound=0.335429, batch=229\n",
      "319: loss=0.995, rw_mean=0.080, rw_bound=0.348678, batch=227\n",
      "320: loss=0.994, rw_mean=0.090, rw_bound=0.387420, batch=227\n",
      "321: loss=0.994, rw_mean=0.100, rw_bound=0.421858, batch=229\n",
      "322: loss=0.992, rw_mean=0.140, rw_bound=0.360473, batch=230\n",
      "323: loss=0.999, rw_mean=0.080, rw_bound=0.430467, batch=214\n",
      "324: loss=1.002, rw_mean=0.110, rw_bound=0.228768, batch=219\n",
      "325: loss=0.996, rw_mean=0.110, rw_bound=0.282430, batch=222\n",
      "326: loss=0.994, rw_mean=0.100, rw_bound=0.324271, batch=225\n",
      "327: loss=0.996, rw_mean=0.090, rw_bound=0.348678, batch=226\n",
      "328: loss=0.997, rw_mean=0.100, rw_bound=0.387420, batch=227\n",
      "329: loss=0.995, rw_mean=0.090, rw_bound=0.430467, batch=226\n",
      "330: loss=0.997, rw_mean=0.080, rw_bound=0.210479, batch=228\n",
      "331: loss=0.996, rw_mean=0.110, rw_bound=0.387420, batch=227\n",
      "332: loss=0.996, rw_mean=0.090, rw_bound=0.421858, batch=229\n",
      "333: loss=0.996, rw_mean=0.090, rw_bound=0.294982, batch=230\n",
      "334: loss=0.992, rw_mean=0.070, rw_bound=0.430467, batch=230\n",
      "335: loss=0.992, rw_mean=0.120, rw_bound=0.463948, batch=231\n",
      "336: loss=0.992, rw_mean=0.090, rw_bound=0.387420, batch=231\n",
      "337: loss=1.016, rw_mean=0.120, rw_bound=0.478297, batch=179\n",
      "338: loss=1.015, rw_mean=0.140, rw_bound=0.000000, batch=193\n",
      "339: loss=1.004, rw_mean=0.090, rw_bound=0.000000, batch=202\n",
      "340: loss=1.004, rw_mean=0.120, rw_bound=0.042391, batch=210\n",
      "341: loss=1.016, rw_mean=0.150, rw_bound=0.117929, batch=217\n",
      "342: loss=1.011, rw_mean=0.100, rw_bound=0.135085, batch=220\n",
      "343: loss=1.014, rw_mean=0.140, rw_bound=0.166772, batch=221\n",
      "344: loss=1.015, rw_mean=0.130, rw_bound=0.185302, batch=224\n",
      "345: loss=1.016, rw_mean=0.120, rw_bound=0.228768, batch=223\n",
      "346: loss=1.015, rw_mean=0.080, rw_bound=0.219617, batch=226\n",
      "347: loss=1.016, rw_mean=0.100, rw_bound=0.254187, batch=227\n",
      "348: loss=1.013, rw_mean=0.210, rw_bound=0.313811, batch=220\n",
      "349: loss=1.011, rw_mean=0.140, rw_bound=0.348678, batch=221\n",
      "350: loss=1.014, rw_mean=0.110, rw_bound=0.313811, batch=223\n",
      "351: loss=1.010, rw_mean=0.100, rw_bound=0.387420, batch=217\n",
      "352: loss=1.010, rw_mean=0.160, rw_bound=0.348678, batch=219\n",
      "353: loss=1.010, rw_mean=0.080, rw_bound=0.155172, batch=223\n",
      "354: loss=1.006, rw_mean=0.150, rw_bound=0.387420, batch=223\n",
      "355: loss=1.005, rw_mean=0.120, rw_bound=0.228768, batch=225\n",
      "356: loss=1.008, rw_mean=0.130, rw_bound=0.430467, batch=210\n",
      "357: loss=1.008, rw_mean=0.160, rw_bound=0.338218, batch=217\n",
      "358: loss=1.009, rw_mean=0.160, rw_bound=0.313811, batch=221\n",
      "359: loss=1.012, rw_mean=0.120, rw_bound=0.313811, batch=224\n",
      "360: loss=1.010, rw_mean=0.140, rw_bound=0.348678, batch=224\n",
      "361: loss=1.008, rw_mean=0.130, rw_bound=0.387420, batch=222\n",
      "362: loss=1.008, rw_mean=0.110, rw_bound=0.400335, batch=225\n",
      "363: loss=1.007, rw_mean=0.160, rw_bound=0.430467, batch=223\n",
      "364: loss=1.009, rw_mean=0.090, rw_bound=0.300714, batch=226\n",
      "365: loss=1.006, rw_mean=0.140, rw_bound=0.408944, batch=228\n",
      "366: loss=1.004, rw_mean=0.190, rw_bound=0.391725, batch=229\n",
      "367: loss=1.004, rw_mean=0.260, rw_bound=0.430467, batch=229\n",
      "368: loss=1.008, rw_mean=0.090, rw_bound=0.478297, batch=213\n",
      "369: loss=1.007, rw_mean=0.140, rw_bound=0.310882, batch=219\n",
      "370: loss=1.008, rw_mean=0.090, rw_bound=0.224153, batch=223\n",
      "371: loss=1.003, rw_mean=0.140, rw_bound=0.348678, batch=225\n",
      "372: loss=1.004, rw_mean=0.060, rw_bound=0.387420, batch=225\n",
      "373: loss=1.003, rw_mean=0.110, rw_bound=0.430467, batch=225\n",
      "374: loss=1.004, rw_mean=0.110, rw_bound=0.405596, batch=227\n",
      "375: loss=1.003, rw_mean=0.150, rw_bound=0.430467, batch=228\n",
      "376: loss=1.002, rw_mean=0.190, rw_bound=0.435250, batch=229\n",
      "377: loss=1.003, rw_mean=0.160, rw_bound=0.478297, batch=226\n",
      "378: loss=1.006, rw_mean=0.040, rw_bound=0.051326, batch=228\n",
      "379: loss=1.003, rw_mean=0.130, rw_bound=0.356857, batch=229\n",
      "380: loss=1.003, rw_mean=0.140, rw_bound=0.430467, batch=229\n",
      "381: loss=1.004, rw_mean=0.110, rw_bound=0.348678, batch=229\n",
      "382: loss=1.003, rw_mean=0.110, rw_bound=0.449599, batch=230\n",
      "383: loss=1.002, rw_mean=0.170, rw_bound=0.478297, batch=229\n",
      "384: loss=1.005, rw_mean=0.110, rw_bound=0.379605, batch=230\n",
      "385: loss=1.003, rw_mean=0.090, rw_bound=0.451034, batch=231\n",
      "386: loss=1.002, rw_mean=0.130, rw_bound=0.478297, batch=230\n",
      "387: loss=1.001, rw_mean=0.130, rw_bound=0.463948, batch=231\n",
      "388: loss=1.001, rw_mean=0.130, rw_bound=0.478297, batch=231\n",
      "390: loss=1.002, rw_mean=0.110, rw_bound=0.000000, batch=11\n",
      "391: loss=0.978, rw_mean=0.140, rw_bound=0.000000, batch=25\n",
      "392: loss=0.953, rw_mean=0.150, rw_bound=0.000000, batch=40\n",
      "393: loss=0.934, rw_mean=0.200, rw_bound=0.000000, batch=60\n",
      "394: loss=0.927, rw_mean=0.190, rw_bound=0.000000, batch=79\n",
      "395: loss=0.909, rw_mean=0.270, rw_bound=0.000000, batch=106\n",
      "396: loss=0.909, rw_mean=0.250, rw_bound=0.000000, batch=131\n",
      "397: loss=0.910, rw_mean=0.200, rw_bound=0.000000, batch=151\n",
      "398: loss=0.917, rw_mean=0.190, rw_bound=0.000000, batch=170\n",
      "399: loss=0.918, rw_mean=0.110, rw_bound=0.000000, batch=181\n",
      "400: loss=0.910, rw_mean=0.230, rw_bound=0.007855, batch=195\n",
      "401: loss=0.911, rw_mean=0.260, rw_bound=0.016788, batch=206\n",
      "402: loss=0.905, rw_mean=0.170, rw_bound=0.022528, batch=212\n",
      "403: loss=0.903, rw_mean=0.230, rw_bound=0.034337, batch=217\n",
      "404: loss=0.900, rw_mean=0.250, rw_bound=0.064611, batch=219\n",
      "405: loss=0.905, rw_mean=0.260, rw_bound=0.074980, batch=223\n",
      "406: loss=0.897, rw_mean=0.150, rw_bound=0.088629, batch=221\n",
      "407: loss=0.902, rw_mean=0.170, rw_bound=0.098477, batch=224\n",
      "408: loss=0.898, rw_mean=0.210, rw_bound=0.120361, batch=227\n",
      "409: loss=0.894, rw_mean=0.220, rw_bound=0.135085, batch=222\n",
      "410: loss=0.890, rw_mean=0.200, rw_bound=0.150095, batch=222\n",
      "411: loss=0.885, rw_mean=0.210, rw_bound=0.166772, batch=220\n",
      "412: loss=0.887, rw_mean=0.220, rw_bound=0.185302, batch=215\n",
      "413: loss=0.885, rw_mean=0.180, rw_bound=0.205891, batch=198\n",
      "414: loss=0.879, rw_mean=0.280, rw_bound=0.228768, batch=191\n",
      "415: loss=0.882, rw_mean=0.270, rw_bound=0.254187, batch=182\n",
      "416: loss=0.873, rw_mean=0.160, rw_bound=0.006575, batch=197\n",
      "417: loss=0.874, rw_mean=0.260, rw_bound=0.088629, batch=206\n",
      "418: loss=0.866, rw_mean=0.240, rw_bound=0.115498, batch=214\n",
      "419: loss=0.860, rw_mean=0.240, rw_bound=0.165104, batch=220\n",
      "420: loss=0.864, rw_mean=0.170, rw_bound=0.166772, batch=221\n",
      "421: loss=0.869, rw_mean=0.210, rw_bound=0.205891, batch=223\n",
      "422: loss=0.877, rw_mean=0.230, rw_bound=0.228768, batch=223\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterate_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreward_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_bound\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilter_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPERCENTILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36miterate_batches\u001b[0;34m(env, net, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     obs_v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([obs])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m     act_probs_v \u001b[38;5;241m=\u001b[39m sm(\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_v\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     act_probs \u001b[38;5;241m=\u001b[39m act_probs_v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(act_probs), p\u001b[38;5;241m=\u001b[39mact_probs)\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/deep-search/lib/architecture.py:27\u001b[0m, in \u001b[0;36mSearch.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/lib/architecture.py:36\u001b[0m, in \u001b[0;36mSearch.search\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m next_states \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth):\n\u001b[0;32m---> 36\u001b[0m     next_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# attention on current beam\u001b[39;00m\n\u001b[1;32m     39\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvecdot(next_states, torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness(next_states), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/deep-search/lib/architecture.py:48\u001b[0m, in \u001b[0;36mSearch.next_states\u001b[0;34m(self, current_states)\u001b[0m\n\u001b[1;32m     45\u001b[0m next_state_distributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransition(current_states)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# candidates: (num_samples * n_candidates), n_batch, ..., n_dim\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state_distributions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# candidates_fitness: (max_width * n_candidates), n_batch, ..., n_dim\u001b[39;00m\n\u001b[1;32m     51\u001b[0m candidates_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness(candidates)\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2570\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply Layer Normalization for last certain number of dimensions.\u001b[39;00m\n\u001b[1;32m   2566\u001b[0m \n\u001b[1;32m   2567\u001b[0m \u001b[38;5;124;03mSee :class:`~torch.nn.LayerNorm` for details.\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m-> 2570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled)\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/deep-search/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2573\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2571\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2572\u001b[0m     )\n\u001b[0;32m-> 2573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_batch = []\n",
    "\n",
    "temperature = 3.0\n",
    "gamma = 0.99\n",
    "\n",
    "with torch.device(device):\n",
    "    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        \n",
    "        reward_mean = float(np.mean(list(map(lambda s: s.reward, batch))))\n",
    "\n",
    "        full_batch, obs, acts, reward_bound = filter_batch(full_batch + batch, PERCENTILE)\n",
    "\n",
    "        if not full_batch:\n",
    "            continue\n",
    "\n",
    "        obs_v = torch.FloatTensor(obs).to(device)\n",
    "        acts_v = torch.LongTensor(acts).to(device)\n",
    "        full_batch = full_batch[-500:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        temperature = max(temperature * gamma, 1.0)\n",
    "\n",
    "        net.search.set_temperature(temperature)\n",
    "\n",
    "        action_scores_v = net(obs_v)\n",
    "\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"%d: loss=%.3f, rw_mean=%.3f, rw_bound=%.6f, batch=%d\" % (\n",
    "            iter_no, loss_v.item(), reward_mean, reward_bound, len(full_batch))\n",
    "        )\n",
    "\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_mean, iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_bound, iter_no)\n",
    "\n",
    "        if reward_mean > 0.8:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
