{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,),(0.3081,))])\n",
    "train_dataset = datasets.MNIST(root = './MNIST_data', train  = True, download = True, transform = transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, generator=torch.Generator(device))\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.layers import Residual, UnpackGrid, MultiBatchConv2d\n",
    "from lib.quantumsearch import FitnessFunction, OneToManyNetwork, QuantumSearch\n",
    "from lib.quantumsearch import TransitionFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\"Basic redisual block.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_filters: int,\n",
    "        num_output_filters: int\n",
    "\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            MultiBatchConv2d(\n",
    "                in_channels = num_input_filters,\n",
    "                out_channels = num_input_filters,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1,\n",
    "                bias = False,\n",
    "            ),\n",
    "            # nn.BatchNorm2d(num_features=num_filters),\n",
    "\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            MultiBatchConv2d(\n",
    "                in_channels = num_input_filters,\n",
    "                out_channels = num_output_filters,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1,\n",
    "                bias = False,\n",
    "            ),\n",
    "            # nn.BatchNorm2d(num_features=num_filters),\n",
    "        )\n",
    "        self.conv_block3 = MultiBatchConv2d(\n",
    "                in_channels = num_input_filters,\n",
    "                out_channels = num_output_filters,\n",
    "                kernel_size = 1,\n",
    "                stride = 1,\n",
    "                bias = False,\n",
    "            )\n",
    "        self.layer_norm1 = None\n",
    "        self.layer_norm2 = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = self.conv_block3(x)\n",
    "        out = self.conv_block1(x)\n",
    "        _,_,C,H,W = out.shape\n",
    "        if self.layer_norm1 is None:\n",
    "            self.layer_norm1 = nn.LayerNorm([C, H, W])\n",
    "        out = self.layer_norm1(out)\n",
    "        out = self.conv_block2(out)\n",
    "        _,_,C,H,W = out.shape\n",
    "        if self.layer_norm2 is None:\n",
    "            self.layer_norm2 = nn.LayerNorm([C, H, W])\n",
    "        out = self.layer_norm2(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): MultiBatchConv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (1): QuantumSearch(\n",
       "    (transition): TransitionFunction(\n",
       "      (one_to_many): OneToManyNetwork(\n",
       "        (network): Sequential(\n",
       "          (0): ResNetBlock(\n",
       "            (conv_block1): Sequential(\n",
       "              (0): MultiBatchConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ReLU()\n",
       "            )\n",
       "            (conv_block2): Sequential(\n",
       "              (0): MultiBatchConv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "            (conv_block3): MultiBatchConv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): UnpackGrid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fitness): FitnessFunction(\n",
       "      (one_to_many): OneToManyNetwork(\n",
       "        (network): Sequential(\n",
       "          (0): ResNetBlock(\n",
       "            (conv_block1): Sequential(\n",
       "              (0): MultiBatchConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): ReLU()\n",
       "            )\n",
       "            (conv_block2): Sequential(\n",
       "              (0): MultiBatchConv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "            (conv_block3): MultiBatchConv2d(32, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): UnpackGrid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=676, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=10, bias=True)\n",
       "    (6): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_filters = 32\n",
    "encoder = nn.Sequential(\n",
    "    MultiBatchConv2d(1, num_filters, 3, 1),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "search = QuantumSearch(\n",
    "    transition = TransitionFunction(OneToManyNetwork(\n",
    "            nn.Sequential(\n",
    "                ResNetBlock(num_input_filters = num_filters, num_output_filters = 3*num_filters),\n",
    "                UnpackGrid(3) # Batch, ...,  3 * H -> Batch, ..., H, 3\n",
    "            )\n",
    "        ),\n",
    "    ),\n",
    "    fitness=FitnessFunction(\n",
    "        OneToManyNetwork(\n",
    "            nn.Sequential(\n",
    "\n",
    "               ResNetBlock(num_input_filters = num_filters, num_output_filters = 3),\n",
    "               UnpackGrid(3) # Batch, ...,  3 * H -> Batch, ..., 1, 3\n",
    "            )\n",
    "        ),\n",
    "    ),\n",
    "    max_depth=1,\n",
    "    beam_width=3,\n",
    "    branching_width=3\n",
    ")\n",
    "# decoder = nn.Sequential(\n",
    "#     nn.AvgPool2d(3),\n",
    "#    nn.Flatten(1),\n",
    "#    nn.Linear(2048, 10)\n",
    "# )\n",
    "\n",
    "# decoder_policy = nn.Sequential(\n",
    "#             nn.Conv2d(\n",
    "#                 in_channels=num_filters,\n",
    "#                 out_channels=2,\n",
    "#                 kernel_size=1,\n",
    "#                 stride=1,\n",
    "#                 bias=False,\n",
    "#             ),\n",
    "#             # nn.BatchNorm2d(num_features=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Flatten(1),\n",
    "#             nn.Linear(1352, 10),\n",
    "#         )\n",
    "decoder = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=num_filters,\n",
    "                out_channels=1,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            # nn.BatchNorm2d(num_features=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(676, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "\n",
    "model = nn.Sequential(encoder,\n",
    "                      search,\n",
    "                      decoder)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of parameters: 72458\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\" Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "# nn package also has different loss functions.\n",
    "# we use cross entropy loss for our classification task\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# we use the optim package to apply\n",
    "# ADAM for our parameter updates\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2\n",
    "\n",
    "\n",
    "temperature = 3.0\n",
    "gamma = 0.99\n",
    "\n",
    "with device:\n",
    "\n",
    "\n",
    "    # Training\n",
    "    for t in range(100):\n",
    "\n",
    "        for batch, targets in train_loader:\n",
    "\n",
    "            # Feed forward to get the logits\n",
    "            batch, targets = batch.to(device), targets.to(device)\n",
    "            y_pred = model(batch)\n",
    "\n",
    "            # loss\n",
    "            loss = criterion(y_pred, targets)\n",
    "\n",
    "            # accuracy\n",
    "            score, predicted = torch.max(y_pred, 1)\n",
    "            acc = (targets == predicted).sum().float() / len(targets)\n",
    "\n",
    "            print(\"[EPOCH]: %i, [LOSS]: %.6f, [ACCURACY]: %.3f\" % (t, loss.item(), acc))\n",
    "            # display.clear_output(wait=False)\n",
    "\n",
    "            # zero the gradients before running\n",
    "            # the backward pass.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass to compute the gradient\n",
    "            # of loss w.r.t our learnable params.\n",
    "            loss.backward()\n",
    "\n",
    "            # # clip gradient\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-2)\n",
    "\n",
    "            # Update params\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hook_fn(module, input, output):\n",
    "#     print(f\"Input shape: {module}, {input[0].shape}\")  # input is a tuple; get the shape of the first element\n",
    "#     print(f\"Output shape:{module}, {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the hook on the first layer of conv_block1\n",
    "# hook_handle = model[2][0].register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_batch, _ = next(iter(train_loader))  # Get a batch from the dataloader\n",
    "# sample_batch = sample_batch\n",
    "# output = model(sample_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
