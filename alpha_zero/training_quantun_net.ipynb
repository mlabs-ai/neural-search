{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains the AlphaZero agent on a single machine for the game of Go.\"\"\"\n",
    "import os\n",
    "\n",
    "# This forces OpenMP to use 1 single thread, which is needed to\n",
    "# prevent contention between multiple process.\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# Tell numpy to only use one core.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer('board_size', 9, 'Board size for Go.')\n",
    "flags.DEFINE_float('komi', 7.5, 'Komi rule for Go.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_stack',\n",
    "    8,\n",
    "    'Stack N previous states, the state is an image of N x 2 + 1 binary planes.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer('num_filters', 32, 'Number of filters for the conv2d layers in the neural network.')\n",
    "flags.DEFINE_integer('max_depth', 10, ' maximum depth for quantum search')\n",
    "flags.DEFINE_integer('branching_width', 3, ' branching_width for quantum search')\n",
    "flags.DEFINE_integer('beam_width', 3, ' beam_width for quantum search')\n",
    "flags.DEFINE_integer(\n",
    "    'num_fc_units',\n",
    "    128,\n",
    "    'Number of hidden units in the linear layer of the neural network.',\n",
    ")\n",
    "\n",
    "\n",
    "flags.DEFINE_integer('min_games', 20000, 'Collect number of self-play games before learning starts.')\n",
    "flags.DEFINE_integer(\n",
    "    'games_per_ckpt',\n",
    "    100,\n",
    "    'Collect minimum number of self-play games using the last checkpoint before creating the next checkpoint.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'replay_capacity',\n",
    "    250000 * 50,\n",
    "    'Replay buffer capacity is number of game * average game length.' 'Note, 250000 games may need ~30GB of RAM',\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'batch_size',\n",
    "    1024,\n",
    "    'To avoid overfitting, we want to make sure the agent only sees ~10% of samples in the replay over one checkpoint.'\n",
    "    'That is, batch_size * ckpt_interval <= replay_capacity * 0.1',\n",
    ")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    'argument_data',\n",
    "    True,\n",
    "    'Apply random rotation and mirroring to the training data, default on.',\n",
    ")\n",
    "flags.DEFINE_bool('compress_data', False, 'Compress state when saving in replay buffer, default off.')\n",
    "\n",
    "flags.DEFINE_float('init_lr', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_float('lr_decay', 0.1, 'Learning rate decay rate.')\n",
    "flags.DEFINE_multi_integer(\n",
    "    'lr_milestones',\n",
    "    [10000, 20000, 40000],\n",
    "    'The number of training steps at which the learning rate will be decayed.',\n",
    ")\n",
    "flags.DEFINE_float('l2_regularization', 1e-4, 'The L2 regularization parameter applied to weights.')\n",
    "flags.DEFINE_float('sgd_momentum', 0.9, '')\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'max_training_steps',\n",
    "    int(5e4),\n",
    "    'Number of training steps (measured in network parameter update, one batch is one training step).',\n",
    ")\n",
    "flags.DEFINE_integer('num_actors',32, 'Number of self-play actor processes.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_simulations',\n",
    "    200,\n",
    "    'Number of simulations per MCTS search, this applies to both self-play and evaluation processes.',\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'num_parallel',\n",
    "    8,\n",
    "    'Number of leaves to collect before using the neural network to evaluate the positions during MCTS search,'\n",
    "    '1 means no parallel search.',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'c_puct_base',\n",
    "    19652,\n",
    "    'Exploration constants balancing priors vs. search values. Original paper use 19652',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'c_puct_init',\n",
    "    1.25,\n",
    "    'Exploration constants balancing priors vs. search values. Original paper use 1.25',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'warm_up_steps',\n",
    "    16,\n",
    "    'Number of steps at the beginning of a self-play game where the search temperature is set to 1.',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'init_resign_threshold',\n",
    "    -0.88,\n",
    "    'The self-play game is resigned if MCTS search values are lesser than this threshold.'\n",
    "    'This value is also dynamically adjusted (decreased) during training to keep the false positive below the target level.'\n",
    "    '-1 means no resign and it disables all the features related to resignations during self-play.',\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'check_resign_after_steps',\n",
    "    40,\n",
    "    'Number steps into the self-play game before checking for resign.',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'target_fp_rate',\n",
    "    0.05,\n",
    "    'Target resignation false positives rate, the resignation threshold is dynamically adjusted to keep the false positives rate below this value.',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'disable_resign_ratio',\n",
    "    0.1,\n",
    "    'Disable resign for proportion of self-play games so we can measure resignation false positives.',\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'reset_fp_interval',\n",
    "    100000,\n",
    "    'The frequency (measured in number of self-play games) to reset resignation threshold,'\n",
    "    'so statistics from old games do not influence current play.',\n",
    ")\n",
    "flags.DEFINE_integer(\n",
    "    'no_resign_games',\n",
    "    50000,\n",
    "    'Initial games played with resignation disable. '\n",
    "    'This makes sense as when starting out, the prediction from the neural network is not accurate.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    'default_rating',\n",
    "    0,\n",
    "    'Default elo rating, change to the rating (for black) from last checkpoint when resume training.',\n",
    ")\n",
    "flags.DEFINE_integer('ckpt_interval', 500, 'The frequency (in training step) to create new checkpoint.')\n",
    "flags.DEFINE_integer('log_interval', 200, 'The frequency (in training step) to log training statistics.')\n",
    "flags.DEFINE_string('ckpt_dir', './checkpoints/go/9x9/quantum', 'Path for checkpoint file.')\n",
    "flags.DEFINE_string(\n",
    "    'logs_dir',\n",
    "    './logs/go/9x9/quantum',\n",
    "    'Path to save statistics for self-play, training, and evaluation.',\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    'dataset_dir',\n",
    "    'go_dataset.pth',\n",
    "    'Go dataset',\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    'eval_games_dir',\n",
    "    './games/pro_games/go/9x9',\n",
    "    'Path contains evaluation games in sgf format.',\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    'save_sgf_dir',\n",
    "    './games/selfplay_games/go/9x9',\n",
    "    'Path to selfplay and evaluation games in sgf format.',\n",
    ")\n",
    "flags.DEFINE_integer('save_sgf_interval', 500, 'How often to save self-play games.')\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'save_replay_interval',\n",
    "    0,\n",
    "    'The frequency (in number of self-play games) to save the replay buffer state.'\n",
    "    'So we can resume training without staring from zero. 0 means do not save replay state.'\n",
    "    'If you set this to a non-zero value, you should make sure the path specified by \"FLAGS.ckpt_dir\" have at least 100GB of free space.',\n",
    ")\n",
    "flags.DEFINE_string('load_ckpt', '', 'Resume training by starting from last checkpoint.')\n",
    "flags.DEFINE_string('load_replay', '', 'Resume training by loading saved replay buffer state.')\n",
    "\n",
    "flags.DEFINE_string('log_level', 'INFO', '')\n",
    "flags.DEFINE_integer('seed', 1, 'Seed the runtime.')\n",
    "\n",
    "flags.register_validator('num_simulations', lambda x: x > 1)\n",
    "flags.register_validator('log_level', lambda x: x in ['INFO', 'DEBUG'])\n",
    "flags.register_multi_flags_validator(\n",
    "    ['num_parallel', 'c_puct_base'],\n",
    "    lambda flags: flags['c_puct_base'] >= 19652 * (flags['num_parallel'] / 800),\n",
    "    '',\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize flags\n",
    "FLAGS(sys.argv, known_only = True)\n",
    "\n",
    "os.environ['BOARD_SIZE'] = str(FLAGS.board_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink failed to import tkinter.\n"
     ]
    }
   ],
   "source": [
    "from alpha_zero.envs.go import GoEnv\n",
    "from alpha_zero.core.pipeline import (\n",
    "    supervised_learner_loop,\n",
    "    set_seed,\n",
    "    maybe_create_dir,\n",
    ")\n",
    "from alpha_zero.core.quantum_net import QuantumAlphaZeroNet\n",
    "from alpha_zero.utils.util import extract_args_from_flags_dict, create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_builder():\n",
    "        return GoEnv(komi=FLAGS.komi, num_stack=FLAGS.num_stack)\n",
    "eval_env = env_builder()\n",
    "\n",
    "input_shape = eval_env.observation_space.shape\n",
    "num_actions = eval_env.action_space.n\n",
    "def network_builder():\n",
    "        return QuantumAlphaZeroNet(\n",
    "            input_shape,\n",
    "            num_actions,\n",
    "            FLAGS.num_filters,\n",
    "            FLAGS.max_depth,\n",
    "            FLAGS.branching_width,\n",
    "            FLAGS.beam_width,\n",
    "            FLAGS.num_fc_units,\n",
    "\n",
    "        )\n",
    "network = network_builder()\n",
    "optimizer = torch.optim.SGD(\n",
    "    network.parameters(),\n",
    "    lr=FLAGS.init_lr,\n",
    "    momentum=FLAGS.sgd_momentum,\n",
    "    weight_decay=FLAGS.l2_regularization,\n",
    ")\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=FLAGS.lr_milestones, gamma=FLAGS.lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of parameters: 79581\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in network.parameters())\n",
    "print(f\" Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 9, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2024-11-12 09:19:43 1757406542.py:9] {'board_size': 9, 'komi': 7.5, 'num_stack': 8, 'num_filters': 32, 'max_depth': 10, 'branching_width': 3, 'beam_width': 3, 'num_fc_units': 128, 'min_games': 20000, 'games_per_ckpt': 100, 'replay_capacity': 12500000, 'batch_size': 1024, 'argument_data': True, 'compress_data': False, 'init_lr': 0.01, 'lr_decay': 0.1, 'lr_milestones': [10000, 20000, 40000], 'l2_regularization': 0.0001, 'sgd_momentum': 0.9, 'max_training_steps': 50000, 'num_actors': 32, 'num_simulations': 200, 'num_parallel': 8, 'c_puct_base': 19652.0, 'c_puct_init': 1.25, 'warm_up_steps': 16, 'init_resign_threshold': -0.88, 'check_resign_after_steps': 40, 'target_fp_rate': 0.05, 'disable_resign_ratio': 0.1, 'reset_fp_interval': 100000, 'no_resign_games': 50000, 'default_rating': 0.0, 'ckpt_interval': 500, 'log_interval': 200, 'ckpt_dir': './checkpoints/go/9x9/quantum', 'logs_dir': './logs/go/9x9/quantum', 'dataset_dir': 'go_dataset.pth', 'eval_games_dir': './games/pro_games/go/9x9', 'save_sgf_dir': './games/selfplay_games/go/9x9', 'save_sgf_interval': 500, 'save_replay_interval': 0, 'load_ckpt': '', 'load_replay': '', 'log_level': 'INFO', 'seed': 1}\n",
      "/home/banashree/neural-search/alpha_zero/core/pipeline.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  go_dataset = torch.load(data_dir)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "UnpackedResidual.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     12\u001b[0m     learner_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43msupervised_learner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlearner_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margument_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_training_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/alpha_zero/core/pipeline.py:695\u001b[0m, in \u001b[0;36msupervised_learner_loop\u001b[0;34m(seed, network, data_dir, optimizer, lr_scheduler, device, logger, argument_data, batch_size, ckpt_interval, log_interval, max_training_steps, patience, ckpt_dir, logs_dir)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    694\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 695\u001b[0m     pi_loss, v_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_supervised_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     loss \u001b[38;5;241m=\u001b[39m pi_loss \u001b[38;5;241m+\u001b[39m v_loss\n\u001b[1;32m    697\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/neural-search/alpha_zero/core/pipeline.py:764\u001b[0m, in \u001b[0;36mcompute_supervised_losses\u001b[0;34m(network, device, transitions, argument_data)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# [B, ]\u001b[39;00m\n\u001b[1;32m    762\u001b[0m target_v \u001b[38;5;241m=\u001b[39m target_v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 764\u001b[0m pred_pi_logits, pred_v\u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m policy_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(pred_pi_logits, target_pi, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# State value MSE loss\u001b[39;00m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/neural-search/alpha_zero/core/quantum_net.py:222\u001b[0m, in \u001b[0;36mQuantumAlphaZeroNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given raw state x, predict the raw logits probability distribution for all actions,\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03mand the evaluated value, all from current player's perspective.\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_block(x)\n\u001b[0;32m--> 222\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Predict raw logits distributions wrt policy\u001b[39;00m\n\u001b[1;32m    225\u001b[0m pi_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_head(out)\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/neural-search/lib/quantumsearch.py:28\u001b[0m, in \u001b[0;36mQuantumSearch.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/lib/quantumsearch.py:34\u001b[0m, in \u001b[0;36mQuantumSearch.search\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m beam \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth):\n\u001b[0;32m---> 34\u001b[0m     beam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m beam\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/neural-search/lib/quantumsearch.py:42\u001b[0m, in \u001b[0;36mQuantumSearch.next_states\u001b[0;34m(self, beam)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext_states\u001b[39m(\u001b[38;5;28mself\u001b[39m, beam: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# current_states: (branching_width * n_candidates), n_batch, ..., n_dim\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranching_width\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# candidates_fitness: beam_width, (branching_width * n_candidates), n_batch, ..., (n_dim or 1)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     candidates_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness(candidates, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_width)\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: UnpackedResidual.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "set_seed(FLAGS.seed)\n",
    "\n",
    "maybe_create_dir(FLAGS.ckpt_dir)\n",
    "maybe_create_dir(FLAGS.logs_dir)\n",
    "maybe_create_dir(FLAGS.save_sgf_dir)\n",
    "\n",
    "logger = create_logger(FLAGS.log_level)\n",
    "\n",
    "logger.info(extract_args_from_flags_dict(FLAGS.flag_values_dict()))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    learner_device = torch.device('cuda')\n",
    "supervised_learner_loop(\n",
    "    seed = FLAGS.seed,\n",
    "    network = network,\n",
    "    data_dir = FLAGS.dataset_dir,\n",
    "    device = learner_device,\n",
    "    optimizer = optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    logger = logger,\n",
    "    argument_data = FLAGS.argument_data,\n",
    "    batch_size = FLAGS.batch_size,\n",
    "    ckpt_interval = FLAGS.ckpt_interval,\n",
    "    log_interval = FLAGS.log_interval,\n",
    "    max_training_steps = FLAGS.max_training_steps,\n",
    "    patience = 10,\n",
    "    ckpt_dir = FLAGS.ckpt_dir,\n",
    "    logs_dir = FLAGS.logs_dir,\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hook_fn(module, input, output):\n",
    "#     print(f\"Input shape: {module}, {input[0].shape}\")  # input is a tuple; get the shape of the first element\n",
    "#     print(f\"Output shape:{module}, {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the hook on the first layer of conv_block1\n",
    "# hook_handle = network.conv_block.register_forward_hook(hook_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
