{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains the AlphaZero agent on a single machine for the game of Go.\"\"\"\n",
    "import os\n",
    "\n",
    "# This forces OpenMP to use 1 single thread, which is needed to\n",
    "# prevent contention between multiple process.\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# Tell numpy to only use one core.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer('board_size', 9, 'Board size for Go.')\n",
    "flags.DEFINE_float('komi', 7.5, 'Komi rule for Go.')\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'num_stack',\n",
    "    8,\n",
    "    'Stack N previous states, the state is an image of N x 2 + 1 binary planes.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer('num_filters', 236, 'Number of filters for the conv2d layers in the neural network.')\n",
    "flags.DEFINE_integer('max_depth', 10, ' maximum depth for quantum search')\n",
    "flags.DEFINE_integer('branching_width', 3, ' branching_width for quantum search')\n",
    "flags.DEFINE_integer('beam_width', 1, ' beam_width for quantum search')\n",
    "flags.DEFINE_integer(\n",
    "    'num_fc_units',\n",
    "    128,\n",
    "    'Number of hidden units in the linear layer of the neural network.',\n",
    ")\n",
    "flags.DEFINE_integer('num_search', 1, ' number of search modules for quantum search')\n",
    "\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'batch_size',\n",
    "    1024,\n",
    "    'To avoid overfitting, we want to make sure the agent only sees ~10% of samples in the replay over one checkpoint.'\n",
    "    'That is, batch_size * ckpt_interval <= replay_capacity * 0.1',\n",
    ")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    'argument_data',\n",
    "    True,\n",
    "    'Apply random rotation and mirroring to the training data, default on.',\n",
    ")\n",
    "\n",
    "\n",
    "flags.DEFINE_float('init_lr', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_float('lr_decay', 0.1, 'Learning rate decay rate.')\n",
    "flags.DEFINE_multi_integer(\n",
    "    'lr_milestones',\n",
    "    [10000, 20000, 40000],\n",
    "    'The number of training steps at which the learning rate will be decayed.',\n",
    ")\n",
    "flags.DEFINE_float('l2_regularization', 1e-4, 'The L2 regularization parameter applied to weights.')\n",
    "flags.DEFINE_float('sgd_momentum', 0.9, '')\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'max_training_steps',\n",
    "    int(5e4),\n",
    "    'Number of training steps (measured in network parameter update, one batch is one training step).',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer('ckpt_interval', 500, 'The frequency (in training step) to create new checkpoint.')\n",
    "flags.DEFINE_integer('log_interval', 20, 'The frequency (in training step) to log training statistics.')\n",
    "\n",
    "flags.DEFINE_string('ckpt_dir', '', 'Checkpoint directory (to be generated dynamically)')\n",
    "flags.DEFINE_string('logs_dir', '', 'Logs directory (to be generated dynamically)')\n",
    "flags.DEFINE_string(\n",
    "    'dataset_dir',\n",
    "    'go_dataset.pth',\n",
    "    'Go dataset',\n",
    ")\n",
    "\n",
    "flags.DEFINE_string('log_level', 'INFO', '')\n",
    "flags.DEFINE_integer('seed', 1, 'Seed the runtime.')\n",
    "\n",
    "\n",
    "# Initialize flags\n",
    "FLAGS(sys.argv, known_only = True)\n",
    "\n",
    "os.environ['BOARD_SIZE'] = str(FLAGS.board_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folder_name(depth, search, branching, filters, beam):\n",
    "    return f\"d_{depth}s_{search}br_{branching}f_{filters}be_{beam}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = generate_folder_name(\n",
    "        FLAGS.max_depth, FLAGS.num_search, FLAGS.branching_width, FLAGS.num_filters, FLAGS.beam_width\n",
    "    )\n",
    "\n",
    "# Update ckpt_dir and logs_dir with the generated folder name\n",
    "FLAGS.ckpt_dir = f'./checkpoints/go/9x9/quantum/{folder_name}'\n",
    "FLAGS.logs_dir = f'./logs/go/9x9/quantum/{folder_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink failed to import tkinter.\n"
     ]
    }
   ],
   "source": [
    "from alpha_zero.envs.go import GoEnv\n",
    "from alpha_zero.core.pipeline import (\n",
    "    supervised_learner_loop,\n",
    "    set_seed,\n",
    "    maybe_create_dir,\n",
    ")\n",
    "from alpha_zero.core.quantum_net import QuantumAlphaZeroNet\n",
    "from alpha_zero.utils.util import extract_args_from_flags_dict, create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_builder():\n",
    "        return GoEnv(komi=FLAGS.komi, num_stack=FLAGS.num_stack)\n",
    "eval_env = env_builder()\n",
    "\n",
    "input_shape = eval_env.observation_space.shape\n",
    "num_actions = eval_env.action_space.n\n",
    "def network_builder():\n",
    "        return QuantumAlphaZeroNet(\n",
    "            input_shape,\n",
    "            num_actions,\n",
    "            FLAGS.num_filters,\n",
    "            FLAGS.max_depth,\n",
    "            FLAGS.branching_width,\n",
    "            FLAGS.beam_width,\n",
    "            FLAGS.num_fc_units,\n",
    "            FLAGS.num_search\n",
    "\n",
    "        )\n",
    "network = network_builder()\n",
    "network = torch.compile(network)\n",
    "optimizer = torch.optim.SGD(\n",
    "    network.parameters(),\n",
    "    lr=FLAGS.init_lr,\n",
    "    momentum=FLAGS.sgd_momentum,\n",
    "    weight_decay=FLAGS.l2_regularization,\n",
    ")\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=FLAGS.lr_milestones, gamma=FLAGS.lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of parameters: 2761051\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in network.parameters())\n",
    "print(f\" Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 9, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2024-12-04 15:22:05 501677995.py:11] {'board_size': 9, 'komi': 7.5, 'num_stack': 8, 'num_filters': 72, 'max_depth': 1, 'branching_width': 3, 'beam_width': 1, 'num_fc_units': 128, 'num_search': 10, 'batch_size': 1024, 'argument_data': True, 'init_lr': 0.01, 'lr_decay': 0.1, 'lr_milestones': [10000, 20000, 40000], 'l2_regularization': 0.0001, 'sgd_momentum': 0.9, 'max_training_steps': 50000, 'ckpt_interval': 500, 'log_interval': 20, 'ckpt_dir': './checkpoints/go/9x9/quantum/d_1s_10br_3f_72be_1', 'logs_dir': './logs/go/9x9/quantum/d_1s_10br_3f_72be_1', 'dataset_dir': 'go_dataset.pth', 'log_level': 'INFO', 'seed': 1}\n",
      "/home/banashree/neural-search/alpha_zero/core/pipeline.py:669: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  go_dataset = torch.load(data_dir)\n",
      "INFO 2024-12-04 15:22:27 pipeline.py:712] Training Step 20: Policy loss = 4.420924186706543, value loss = 0.9570783972740173\n",
      "INFO 2024-12-04 15:22:37 pipeline.py:712] Training Step 40: Policy loss = 4.376986980438232, value loss = 0.9390320181846619\n",
      "INFO 2024-12-04 15:22:47 pipeline.py:712] Training Step 60: Policy loss = 4.367087364196777, value loss = 0.939379870891571\n",
      "INFO 2024-12-04 15:22:56 pipeline.py:712] Training Step 80: Policy loss = 4.333428382873535, value loss = 0.9449597597122192\n",
      "INFO 2024-12-04 15:23:06 pipeline.py:712] Training Step 100: Policy loss = 4.289957523345947, value loss = 0.9340044856071472\n",
      "INFO 2024-12-04 15:23:16 pipeline.py:712] Training Step 120: Policy loss = 4.266568183898926, value loss = 0.9350994825363159\n",
      "INFO 2024-12-04 15:23:25 pipeline.py:712] Training Step 140: Policy loss = 4.247622489929199, value loss = 0.9439676403999329\n",
      "INFO 2024-12-04 15:23:35 pipeline.py:712] Training Step 160: Policy loss = 4.220257759094238, value loss = 0.9332665801048279\n",
      "INFO 2024-12-04 15:23:45 pipeline.py:712] Training Step 180: Policy loss = 4.228189468383789, value loss = 0.9461793303489685\n",
      "INFO 2024-12-04 15:23:54 pipeline.py:712] Training Step 200: Policy loss = 4.201605796813965, value loss = 0.9437767863273621\n",
      "INFO 2024-12-04 15:24:04 pipeline.py:712] Training Step 220: Policy loss = 4.202805519104004, value loss = 0.9355548620223999\n",
      "INFO 2024-12-04 15:24:14 pipeline.py:712] Training Step 240: Policy loss = 4.187471389770508, value loss = 0.9353931546211243\n",
      "INFO 2024-12-04 15:24:23 pipeline.py:712] Training Step 260: Policy loss = 4.186359882354736, value loss = 0.9397244453430176\n",
      "INFO 2024-12-04 15:24:33 pipeline.py:712] Training Step 280: Policy loss = 4.186451435089111, value loss = 0.9318991899490356\n",
      "INFO 2024-12-04 15:24:43 pipeline.py:712] Training Step 300: Policy loss = 4.182844161987305, value loss = 0.9521129131317139\n",
      "INFO 2024-12-04 15:24:52 pipeline.py:712] Training Step 320: Policy loss = 4.175902366638184, value loss = 0.9520727396011353\n",
      "INFO 2024-12-04 15:25:02 pipeline.py:712] Training Step 340: Policy loss = 4.139917850494385, value loss = 0.9460285305976868\n",
      "INFO 2024-12-04 15:25:11 pipeline.py:712] Training Step 360: Policy loss = 4.174668312072754, value loss = 0.9223936796188354\n",
      "INFO 2024-12-04 15:25:21 pipeline.py:712] Training Step 380: Policy loss = 4.133701801300049, value loss = 0.935451328754425\n",
      "INFO 2024-12-04 15:25:31 pipeline.py:712] Training Step 400: Policy loss = 4.121664047241211, value loss = 0.9285593032836914\n",
      "INFO 2024-12-04 15:25:41 pipeline.py:712] Training Step 420: Policy loss = 4.131067276000977, value loss = 0.9428750276565552\n",
      "INFO 2024-12-04 15:25:51 pipeline.py:712] Training Step 440: Policy loss = 4.109614372253418, value loss = 0.9226562976837158\n",
      "INFO 2024-12-04 15:26:00 pipeline.py:712] Training Step 460: Policy loss = 4.1482744216918945, value loss = 0.9332373142242432\n",
      "INFO 2024-12-04 15:26:10 pipeline.py:712] Training Step 480: Policy loss = 4.112032890319824, value loss = 0.9468835592269897\n",
      "INFO 2024-12-04 15:26:38 pipeline.py:738] training_steps 484: Validation loss: Poliy loss 4.111765650452161, value_loss 0.9387934486396977\n",
      "INFO 2024-12-04 15:26:56 pipeline.py:712] Training Step 500: Policy loss = 4.118096351623535, value loss = 0.9379247426986694\n",
      "INFO 2024-12-04 15:27:06 pipeline.py:712] Training Step 520: Policy loss = 4.093021869659424, value loss = 0.9355915784835815\n",
      "INFO 2024-12-04 15:27:16 pipeline.py:712] Training Step 540: Policy loss = 4.071925163269043, value loss = 0.9290149807929993\n",
      "INFO 2024-12-04 15:27:25 pipeline.py:712] Training Step 560: Policy loss = 4.07590389251709, value loss = 0.9347050189971924\n",
      "INFO 2024-12-04 15:27:35 pipeline.py:712] Training Step 580: Policy loss = 4.065850257873535, value loss = 0.9315106272697449\n",
      "INFO 2024-12-04 15:27:44 pipeline.py:712] Training Step 600: Policy loss = 4.127575874328613, value loss = 0.9438858032226562\n",
      "INFO 2024-12-04 15:27:54 pipeline.py:712] Training Step 620: Policy loss = 4.040409088134766, value loss = 0.9488057494163513\n",
      "INFO 2024-12-04 15:28:04 pipeline.py:712] Training Step 640: Policy loss = 4.031604290008545, value loss = 0.936994731426239\n",
      "INFO 2024-12-04 15:28:14 pipeline.py:712] Training Step 660: Policy loss = 4.100658893585205, value loss = 0.9458106756210327\n",
      "INFO 2024-12-04 15:28:23 pipeline.py:712] Training Step 680: Policy loss = 4.05269718170166, value loss = 0.9454827308654785\n",
      "INFO 2024-12-04 15:28:33 pipeline.py:712] Training Step 700: Policy loss = 4.00506591796875, value loss = 0.9451261758804321\n",
      "INFO 2024-12-04 15:28:42 pipeline.py:712] Training Step 720: Policy loss = 4.033685684204102, value loss = 0.9359126091003418\n",
      "INFO 2024-12-04 15:28:52 pipeline.py:712] Training Step 740: Policy loss = 4.008096218109131, value loss = 0.9409583806991577\n",
      "INFO 2024-12-04 15:29:02 pipeline.py:712] Training Step 760: Policy loss = 3.9907898902893066, value loss = 0.9290118217468262\n",
      "INFO 2024-12-04 15:29:11 pipeline.py:712] Training Step 780: Policy loss = 4.022965908050537, value loss = 0.9398223161697388\n",
      "INFO 2024-12-04 15:29:21 pipeline.py:712] Training Step 800: Policy loss = 4.023515701293945, value loss = 0.9517048001289368\n",
      "INFO 2024-12-04 15:29:30 pipeline.py:712] Training Step 820: Policy loss = 4.0263237953186035, value loss = 0.9398508667945862\n",
      "INFO 2024-12-04 15:29:40 pipeline.py:712] Training Step 840: Policy loss = 4.026006698608398, value loss = 0.9333745241165161\n",
      "INFO 2024-12-04 15:29:50 pipeline.py:712] Training Step 860: Policy loss = 4.0085554122924805, value loss = 0.939473569393158\n",
      "INFO 2024-12-04 15:30:00 pipeline.py:712] Training Step 880: Policy loss = 4.030159950256348, value loss = 0.9373230934143066\n",
      "INFO 2024-12-04 15:30:09 pipeline.py:712] Training Step 900: Policy loss = 3.9662792682647705, value loss = 0.9277825951576233\n",
      "INFO 2024-12-04 15:30:19 pipeline.py:712] Training Step 920: Policy loss = 3.9524037837982178, value loss = 0.9353845715522766\n",
      "INFO 2024-12-04 15:30:28 pipeline.py:712] Training Step 940: Policy loss = 3.9638187885284424, value loss = 0.9335920810699463\n",
      "INFO 2024-12-04 15:30:38 pipeline.py:712] Training Step 960: Policy loss = 3.917328357696533, value loss = 0.9395873546600342\n",
      "INFO 2024-12-04 15:30:59 pipeline.py:738] training_steps 968: Validation loss: Poliy loss 3.9669586674111788, value_loss 0.9368815842221995\n",
      "INFO 2024-12-04 15:31:05 pipeline.py:712] Training Step 980: Policy loss = 3.9504456520080566, value loss = 0.9386447668075562\n",
      "INFO 2024-12-04 15:31:15 pipeline.py:712] Training Step 1000: Policy loss = 3.9488539695739746, value loss = 0.9186141490936279\n",
      "INFO 2024-12-04 15:31:25 pipeline.py:712] Training Step 1020: Policy loss = 3.957761764526367, value loss = 0.9264179468154907\n",
      "INFO 2024-12-04 15:31:34 pipeline.py:712] Training Step 1040: Policy loss = 3.9121057987213135, value loss = 0.9448645710945129\n",
      "INFO 2024-12-04 15:31:44 pipeline.py:712] Training Step 1060: Policy loss = 3.91933536529541, value loss = 0.9346506595611572\n",
      "INFO 2024-12-04 15:31:53 pipeline.py:712] Training Step 1080: Policy loss = 3.8360776901245117, value loss = 0.939647376537323\n",
      "INFO 2024-12-04 15:32:03 pipeline.py:712] Training Step 1100: Policy loss = 3.8528738021850586, value loss = 0.930353581905365\n",
      "INFO 2024-12-04 15:32:12 pipeline.py:712] Training Step 1120: Policy loss = 3.8419857025146484, value loss = 0.9393792152404785\n",
      "INFO 2024-12-04 15:32:22 pipeline.py:712] Training Step 1140: Policy loss = 3.8323135375976562, value loss = 0.9428185224533081\n",
      "INFO 2024-12-04 15:32:31 pipeline.py:712] Training Step 1160: Policy loss = 3.8206605911254883, value loss = 0.933255672454834\n",
      "INFO 2024-12-04 15:32:41 pipeline.py:712] Training Step 1180: Policy loss = 3.8528690338134766, value loss = 0.9334087371826172\n",
      "INFO 2024-12-04 15:32:50 pipeline.py:712] Training Step 1200: Policy loss = 3.8259329795837402, value loss = 0.9305388927459717\n",
      "INFO 2024-12-04 15:33:00 pipeline.py:712] Training Step 1220: Policy loss = 3.769989013671875, value loss = 0.9390653371810913\n",
      "INFO 2024-12-04 15:33:10 pipeline.py:712] Training Step 1240: Policy loss = 3.841984272003174, value loss = 0.9254008531570435\n",
      "INFO 2024-12-04 15:33:19 pipeline.py:712] Training Step 1260: Policy loss = 3.769775390625, value loss = 0.9344082474708557\n",
      "INFO 2024-12-04 15:33:29 pipeline.py:712] Training Step 1280: Policy loss = 3.66538667678833, value loss = 0.9382864832878113\n",
      "INFO 2024-12-04 15:33:38 pipeline.py:712] Training Step 1300: Policy loss = 3.684100389480591, value loss = 0.9247397780418396\n",
      "INFO 2024-12-04 15:33:48 pipeline.py:712] Training Step 1320: Policy loss = 3.583305835723877, value loss = 0.9379482269287109\n",
      "INFO 2024-12-04 15:33:57 pipeline.py:712] Training Step 1340: Policy loss = 3.645416736602783, value loss = 0.9327744245529175\n",
      "INFO 2024-12-04 15:34:07 pipeline.py:712] Training Step 1360: Policy loss = 3.604691505432129, value loss = 0.9386897087097168\n",
      "INFO 2024-12-04 15:34:17 pipeline.py:712] Training Step 1380: Policy loss = 3.6033120155334473, value loss = 0.9456000924110413\n",
      "INFO 2024-12-04 15:34:26 pipeline.py:712] Training Step 1400: Policy loss = 3.544552803039551, value loss = 0.931371808052063\n",
      "INFO 2024-12-04 15:34:36 pipeline.py:712] Training Step 1420: Policy loss = 3.493661403656006, value loss = 0.9187276363372803\n",
      "INFO 2024-12-04 15:34:45 pipeline.py:712] Training Step 1440: Policy loss = 3.4756011962890625, value loss = 0.943096935749054\n",
      "INFO 2024-12-04 15:35:09 pipeline.py:738] training_steps 1452: Validation loss: Poliy loss 3.4881854213652064, value_loss 0.9357256522921266\n",
      "INFO 2024-12-04 15:35:13 pipeline.py:712] Training Step 1460: Policy loss = 3.3970179557800293, value loss = 0.9434947967529297\n",
      "INFO 2024-12-04 15:35:22 pipeline.py:712] Training Step 1480: Policy loss = 3.4644806385040283, value loss = 0.9385235905647278\n",
      "INFO 2024-12-04 15:35:32 pipeline.py:712] Training Step 1500: Policy loss = 3.362550735473633, value loss = 0.9405890703201294\n",
      "INFO 2024-12-04 15:35:42 pipeline.py:712] Training Step 1520: Policy loss = 3.4153685569763184, value loss = 0.9283725023269653\n",
      "INFO 2024-12-04 15:35:51 pipeline.py:712] Training Step 1540: Policy loss = 3.2678380012512207, value loss = 0.9255043268203735\n",
      "INFO 2024-12-04 15:36:01 pipeline.py:712] Training Step 1560: Policy loss = 3.295246124267578, value loss = 0.9399927854537964\n",
      "INFO 2024-12-04 15:36:10 pipeline.py:712] Training Step 1580: Policy loss = 3.2749361991882324, value loss = 0.9365992546081543\n",
      "INFO 2024-12-04 15:36:20 pipeline.py:712] Training Step 1600: Policy loss = 3.222367286682129, value loss = 0.9429484009742737\n",
      "INFO 2024-12-04 15:36:30 pipeline.py:712] Training Step 1620: Policy loss = 3.180948495864868, value loss = 0.9408019185066223\n",
      "INFO 2024-12-04 15:36:39 pipeline.py:712] Training Step 1640: Policy loss = 3.2156543731689453, value loss = 0.9285109043121338\n",
      "INFO 2024-12-04 15:36:49 pipeline.py:712] Training Step 1660: Policy loss = 3.1478729248046875, value loss = 0.9420329928398132\n",
      "INFO 2024-12-04 15:36:58 pipeline.py:712] Training Step 1680: Policy loss = 3.058485269546509, value loss = 0.9318416118621826\n",
      "INFO 2024-12-04 15:37:08 pipeline.py:712] Training Step 1700: Policy loss = 3.0978496074676514, value loss = 0.9359719753265381\n",
      "INFO 2024-12-04 15:37:18 pipeline.py:712] Training Step 1720: Policy loss = 3.143716335296631, value loss = 0.939756453037262\n",
      "INFO 2024-12-04 15:37:27 pipeline.py:712] Training Step 1740: Policy loss = 2.9523839950561523, value loss = 0.9339431524276733\n",
      "INFO 2024-12-04 15:37:37 pipeline.py:712] Training Step 1760: Policy loss = 2.9041528701782227, value loss = 0.9334815144538879\n",
      "INFO 2024-12-04 15:37:46 pipeline.py:712] Training Step 1780: Policy loss = 2.956387519836426, value loss = 0.9408701658248901\n",
      "INFO 2024-12-04 15:37:55 pipeline.py:712] Training Step 1800: Policy loss = 2.9218597412109375, value loss = 0.9227667450904846\n",
      "INFO 2024-12-04 15:38:05 pipeline.py:712] Training Step 1820: Policy loss = 2.788011312484741, value loss = 0.9404746294021606\n",
      "INFO 2024-12-04 15:38:15 pipeline.py:712] Training Step 1840: Policy loss = 2.870938777923584, value loss = 0.9412225484848022\n",
      "INFO 2024-12-04 15:38:24 pipeline.py:712] Training Step 1860: Policy loss = 2.751749038696289, value loss = 0.9458497762680054\n",
      "INFO 2024-12-04 15:38:34 pipeline.py:712] Training Step 1880: Policy loss = 2.8361947536468506, value loss = 0.9336353540420532\n",
      "INFO 2024-12-04 15:38:43 pipeline.py:712] Training Step 1900: Policy loss = 2.858640670776367, value loss = 0.9369375109672546\n",
      "INFO 2024-12-04 15:38:53 pipeline.py:712] Training Step 1920: Policy loss = 2.7900967597961426, value loss = 0.9214963912963867\n",
      "INFO 2024-12-04 15:39:18 pipeline.py:738] training_steps 1936: Validation loss: Poliy loss 2.744887457519281, value_loss 0.9341558418313011\n",
      "INFO 2024-12-04 15:39:20 pipeline.py:712] Training Step 1940: Policy loss = 2.723673105239868, value loss = 0.9231380224227905\n",
      "INFO 2024-12-04 15:39:30 pipeline.py:712] Training Step 1960: Policy loss = 2.6898207664489746, value loss = 0.9373670816421509\n",
      "INFO 2024-12-04 15:39:39 pipeline.py:712] Training Step 1980: Policy loss = 2.6909685134887695, value loss = 0.930161714553833\n",
      "INFO 2024-12-04 15:39:49 pipeline.py:712] Training Step 2000: Policy loss = 2.670994520187378, value loss = 0.9266587495803833\n",
      "INFO 2024-12-04 15:39:58 pipeline.py:712] Training Step 2020: Policy loss = 2.6546268463134766, value loss = 0.9249618053436279\n",
      "INFO 2024-12-04 15:40:08 pipeline.py:712] Training Step 2040: Policy loss = 2.6056888103485107, value loss = 0.9246302843093872\n",
      "INFO 2024-12-04 15:40:17 pipeline.py:712] Training Step 2060: Policy loss = 2.6286227703094482, value loss = 0.9176516532897949\n",
      "INFO 2024-12-04 15:40:27 pipeline.py:712] Training Step 2080: Policy loss = 2.565865993499756, value loss = 0.9218025207519531\n",
      "INFO 2024-12-04 15:40:36 pipeline.py:712] Training Step 2100: Policy loss = 2.557299852371216, value loss = 0.931412398815155\n",
      "INFO 2024-12-04 15:40:46 pipeline.py:712] Training Step 2120: Policy loss = 2.5354151725769043, value loss = 0.931486964225769\n",
      "INFO 2024-12-04 15:40:56 pipeline.py:712] Training Step 2140: Policy loss = 2.5749220848083496, value loss = 0.9336399435997009\n",
      "INFO 2024-12-04 15:41:05 pipeline.py:712] Training Step 2160: Policy loss = 2.542717933654785, value loss = 0.9362448453903198\n",
      "INFO 2024-12-04 15:41:14 pipeline.py:712] Training Step 2180: Policy loss = 2.5494003295898438, value loss = 0.930079996585846\n",
      "INFO 2024-12-04 15:41:24 pipeline.py:712] Training Step 2200: Policy loss = 2.429593801498413, value loss = 0.9230505228042603\n",
      "INFO 2024-12-04 15:41:34 pipeline.py:712] Training Step 2220: Policy loss = 2.496011734008789, value loss = 0.9396756887435913\n",
      "INFO 2024-12-04 15:41:43 pipeline.py:712] Training Step 2240: Policy loss = 2.4739181995391846, value loss = 0.932625412940979\n",
      "INFO 2024-12-04 15:41:53 pipeline.py:712] Training Step 2260: Policy loss = 2.423646926879883, value loss = 0.9338481426239014\n",
      "INFO 2024-12-04 15:42:02 pipeline.py:712] Training Step 2280: Policy loss = 2.446641445159912, value loss = 0.9291722774505615\n",
      "INFO 2024-12-04 15:42:12 pipeline.py:712] Training Step 2300: Policy loss = 2.400846242904663, value loss = 0.9263679385185242\n",
      "INFO 2024-12-04 15:42:22 pipeline.py:712] Training Step 2320: Policy loss = 2.3150691986083984, value loss = 0.9476704001426697\n",
      "INFO 2024-12-04 15:42:31 pipeline.py:712] Training Step 2340: Policy loss = 2.4663994312286377, value loss = 0.927810788154602\n",
      "INFO 2024-12-04 15:42:41 pipeline.py:712] Training Step 2360: Policy loss = 2.453300952911377, value loss = 0.9362815618515015\n",
      "INFO 2024-12-04 15:42:50 pipeline.py:712] Training Step 2380: Policy loss = 2.3206114768981934, value loss = 0.9348753094673157\n",
      "INFO 2024-12-04 15:43:00 pipeline.py:712] Training Step 2400: Policy loss = 2.384343147277832, value loss = 0.9475619196891785\n",
      "INFO 2024-12-04 15:43:09 pipeline.py:712] Training Step 2420: Policy loss = 2.2907142639160156, value loss = 0.9289387464523315\n",
      "INFO 2024-12-04 15:43:27 pipeline.py:738] training_steps 2420: Validation loss: Poliy loss 2.3775192284193194, value_loss 0.9310735073245939\n",
      "INFO 2024-12-04 15:43:37 pipeline.py:712] Training Step 2440: Policy loss = 2.2794179916381836, value loss = 0.916813850402832\n",
      "INFO 2024-12-04 15:43:47 pipeline.py:712] Training Step 2460: Policy loss = 2.2506980895996094, value loss = 0.9348752498626709\n",
      "INFO 2024-12-04 15:43:57 pipeline.py:712] Training Step 2480: Policy loss = 2.2288436889648438, value loss = 0.9325685501098633\n",
      "INFO 2024-12-04 15:44:06 pipeline.py:712] Training Step 2500: Policy loss = 2.296278476715088, value loss = 0.9410386085510254\n",
      "INFO 2024-12-04 15:44:16 pipeline.py:712] Training Step 2520: Policy loss = 2.3361687660217285, value loss = 0.9128435254096985\n",
      "INFO 2024-12-04 15:44:26 pipeline.py:712] Training Step 2540: Policy loss = 2.3253471851348877, value loss = 0.9276355504989624\n",
      "INFO 2024-12-04 15:44:36 pipeline.py:712] Training Step 2560: Policy loss = 2.3108558654785156, value loss = 0.9322628378868103\n",
      "INFO 2024-12-04 15:44:45 pipeline.py:712] Training Step 2580: Policy loss = 2.2868709564208984, value loss = 0.9270238876342773\n",
      "INFO 2024-12-04 15:44:55 pipeline.py:712] Training Step 2600: Policy loss = 2.3189446926116943, value loss = 0.9395339488983154\n",
      "INFO 2024-12-04 15:45:04 pipeline.py:712] Training Step 2620: Policy loss = 2.1438677310943604, value loss = 0.9333434104919434\n",
      "INFO 2024-12-04 15:45:14 pipeline.py:712] Training Step 2640: Policy loss = 2.324068546295166, value loss = 0.9472918510437012\n",
      "INFO 2024-12-04 15:45:24 pipeline.py:712] Training Step 2660: Policy loss = 2.3040518760681152, value loss = 0.9415671825408936\n",
      "INFO 2024-12-04 15:45:34 pipeline.py:712] Training Step 2680: Policy loss = 2.322816848754883, value loss = 0.9088523387908936\n",
      "INFO 2024-12-04 15:45:43 pipeline.py:712] Training Step 2700: Policy loss = 2.2975192070007324, value loss = 0.9486904740333557\n",
      "INFO 2024-12-04 15:45:53 pipeline.py:712] Training Step 2720: Policy loss = 2.284761428833008, value loss = 0.9315901398658752\n",
      "INFO 2024-12-04 15:46:02 pipeline.py:712] Training Step 2740: Policy loss = 2.2368805408477783, value loss = 0.9284853935241699\n",
      "INFO 2024-12-04 15:46:12 pipeline.py:712] Training Step 2760: Policy loss = 2.2588589191436768, value loss = 0.9282852411270142\n",
      "INFO 2024-12-04 15:46:22 pipeline.py:712] Training Step 2780: Policy loss = 2.214177131652832, value loss = 0.9137024879455566\n",
      "INFO 2024-12-04 15:46:31 pipeline.py:712] Training Step 2800: Policy loss = 2.267444610595703, value loss = 0.9235388040542603\n",
      "INFO 2024-12-04 15:46:41 pipeline.py:712] Training Step 2820: Policy loss = 2.1511049270629883, value loss = 0.9223562479019165\n",
      "INFO 2024-12-04 15:46:51 pipeline.py:712] Training Step 2840: Policy loss = 2.099391460418701, value loss = 0.9303123950958252\n",
      "INFO 2024-12-04 15:47:00 pipeline.py:712] Training Step 2860: Policy loss = 2.1110081672668457, value loss = 0.9346692562103271\n",
      "INFO 2024-12-04 15:47:10 pipeline.py:712] Training Step 2880: Policy loss = 2.251986026763916, value loss = 0.9049592018127441\n",
      "INFO 2024-12-04 15:47:20 pipeline.py:712] Training Step 2900: Policy loss = 2.1876602172851562, value loss = 0.9411941766738892\n",
      "INFO 2024-12-04 15:47:40 pipeline.py:738] training_steps 2904: Validation loss: Poliy loss 2.195623837533544, value_loss 0.9236063581021106\n",
      "INFO 2024-12-04 15:47:47 pipeline.py:712] Training Step 2920: Policy loss = 2.1292567253112793, value loss = 0.9390469789505005\n",
      "INFO 2024-12-04 15:47:57 pipeline.py:712] Training Step 2940: Policy loss = 2.154106378555298, value loss = 0.8984123468399048\n",
      "INFO 2024-12-04 15:48:07 pipeline.py:712] Training Step 2960: Policy loss = 2.0962445735931396, value loss = 0.9317657351493835\n",
      "INFO 2024-12-04 15:48:16 pipeline.py:712] Training Step 2980: Policy loss = 2.073211193084717, value loss = 0.914770245552063\n",
      "INFO 2024-12-04 15:48:26 pipeline.py:712] Training Step 3000: Policy loss = 2.0819029808044434, value loss = 0.9160640239715576\n",
      "INFO 2024-12-04 15:48:36 pipeline.py:712] Training Step 3020: Policy loss = 2.0906436443328857, value loss = 0.9139013290405273\n",
      "INFO 2024-12-04 15:48:45 pipeline.py:712] Training Step 3040: Policy loss = 2.1219594478607178, value loss = 0.9155124425888062\n",
      "INFO 2024-12-04 15:48:55 pipeline.py:712] Training Step 3060: Policy loss = 2.138292074203491, value loss = 0.9174733757972717\n",
      "INFO 2024-12-04 15:49:05 pipeline.py:712] Training Step 3080: Policy loss = 2.1347780227661133, value loss = 0.9172612428665161\n",
      "INFO 2024-12-04 15:49:14 pipeline.py:712] Training Step 3100: Policy loss = 2.1201510429382324, value loss = 0.9121458530426025\n",
      "INFO 2024-12-04 15:49:24 pipeline.py:712] Training Step 3120: Policy loss = 2.1538896560668945, value loss = 0.9306234121322632\n",
      "INFO 2024-12-04 15:49:33 pipeline.py:712] Training Step 3140: Policy loss = 2.1344656944274902, value loss = 0.9158703684806824\n",
      "INFO 2024-12-04 15:49:43 pipeline.py:712] Training Step 3160: Policy loss = 2.12970232963562, value loss = 0.9168492555618286\n",
      "INFO 2024-12-04 15:49:53 pipeline.py:712] Training Step 3180: Policy loss = 2.011627197265625, value loss = 0.9243460893630981\n",
      "INFO 2024-12-04 15:50:03 pipeline.py:712] Training Step 3200: Policy loss = 2.0735089778900146, value loss = 0.9060200452804565\n",
      "INFO 2024-12-04 15:50:12 pipeline.py:712] Training Step 3220: Policy loss = 2.147378921508789, value loss = 0.9421510696411133\n",
      "INFO 2024-12-04 15:50:22 pipeline.py:712] Training Step 3240: Policy loss = 2.162531852722168, value loss = 0.9039554595947266\n",
      "INFO 2024-12-04 15:50:31 pipeline.py:712] Training Step 3260: Policy loss = 2.0814342498779297, value loss = 0.9107320308685303\n",
      "INFO 2024-12-04 15:50:41 pipeline.py:712] Training Step 3280: Policy loss = 2.1727914810180664, value loss = 0.902124285697937\n",
      "INFO 2024-12-04 15:50:51 pipeline.py:712] Training Step 3300: Policy loss = 2.15565824508667, value loss = 0.9267827868461609\n",
      "INFO 2024-12-04 15:51:00 pipeline.py:712] Training Step 3320: Policy loss = 2.060847759246826, value loss = 0.9302972555160522\n",
      "INFO 2024-12-04 15:51:10 pipeline.py:712] Training Step 3340: Policy loss = 2.046079397201538, value loss = 0.9017493724822998\n",
      "INFO 2024-12-04 15:51:19 pipeline.py:712] Training Step 3360: Policy loss = 2.0932908058166504, value loss = 0.9172693490982056\n",
      "INFO 2024-12-04 15:51:29 pipeline.py:712] Training Step 3380: Policy loss = 2.1298398971557617, value loss = 0.9195411205291748\n",
      "INFO 2024-12-04 15:51:51 pipeline.py:738] training_steps 3388: Validation loss: Poliy loss 2.108368936132212, value_loss 0.9057239924297958\n",
      "INFO 2024-12-04 15:51:57 pipeline.py:712] Training Step 3400: Policy loss = 2.0163822174072266, value loss = 0.9169400930404663\n",
      "INFO 2024-12-04 15:52:07 pipeline.py:712] Training Step 3420: Policy loss = 2.0714149475097656, value loss = 0.8915804028511047\n",
      "INFO 2024-12-04 15:52:16 pipeline.py:712] Training Step 3440: Policy loss = 2.0037357807159424, value loss = 0.9065937995910645\n",
      "INFO 2024-12-04 15:52:26 pipeline.py:712] Training Step 3460: Policy loss = 2.0961415767669678, value loss = 0.9123544096946716\n",
      "INFO 2024-12-04 15:52:35 pipeline.py:712] Training Step 3480: Policy loss = 1.997704029083252, value loss = 0.9204067587852478\n",
      "INFO 2024-12-04 15:52:45 pipeline.py:712] Training Step 3500: Policy loss = 1.9726874828338623, value loss = 0.9200505018234253\n",
      "INFO 2024-12-04 15:52:55 pipeline.py:712] Training Step 3520: Policy loss = 2.0272254943847656, value loss = 0.8691286444664001\n",
      "INFO 2024-12-04 15:53:05 pipeline.py:712] Training Step 3540: Policy loss = 1.9706354141235352, value loss = 0.9014414548873901\n",
      "INFO 2024-12-04 15:53:14 pipeline.py:712] Training Step 3560: Policy loss = 1.9997583627700806, value loss = 0.8948180079460144\n",
      "INFO 2024-12-04 15:53:24 pipeline.py:712] Training Step 3580: Policy loss = 2.0489697456359863, value loss = 0.9166451692581177\n",
      "INFO 2024-12-04 15:53:33 pipeline.py:712] Training Step 3600: Policy loss = 1.9314327239990234, value loss = 0.8869014978408813\n",
      "INFO 2024-12-04 15:53:43 pipeline.py:712] Training Step 3620: Policy loss = 2.010166645050049, value loss = 0.9202548861503601\n",
      "INFO 2024-12-04 15:53:53 pipeline.py:712] Training Step 3640: Policy loss = 1.974700927734375, value loss = 0.8951871395111084\n",
      "INFO 2024-12-04 15:54:02 pipeline.py:712] Training Step 3660: Policy loss = 1.9838333129882812, value loss = 0.9228376746177673\n",
      "INFO 2024-12-04 15:54:12 pipeline.py:712] Training Step 3680: Policy loss = 1.9541070461273193, value loss = 0.9052347540855408\n",
      "INFO 2024-12-04 15:54:22 pipeline.py:712] Training Step 3700: Policy loss = 2.0551812648773193, value loss = 0.9025324583053589\n",
      "INFO 2024-12-04 15:54:31 pipeline.py:712] Training Step 3720: Policy loss = 2.026339292526245, value loss = 0.9305570125579834\n",
      "INFO 2024-12-04 15:54:41 pipeline.py:712] Training Step 3740: Policy loss = 2.1377692222595215, value loss = 0.8886129856109619\n",
      "INFO 2024-12-04 15:54:51 pipeline.py:712] Training Step 3760: Policy loss = 1.9812424182891846, value loss = 0.8969444036483765\n",
      "INFO 2024-12-04 15:55:00 pipeline.py:712] Training Step 3780: Policy loss = 2.0015177726745605, value loss = 0.8751888275146484\n",
      "INFO 2024-12-04 15:55:10 pipeline.py:712] Training Step 3800: Policy loss = 1.9232430458068848, value loss = 0.8700910210609436\n",
      "INFO 2024-12-04 15:55:19 pipeline.py:712] Training Step 3820: Policy loss = 1.962183952331543, value loss = 0.8944205045700073\n",
      "INFO 2024-12-04 15:55:29 pipeline.py:712] Training Step 3840: Policy loss = 1.965731143951416, value loss = 0.885790228843689\n",
      "INFO 2024-12-04 15:55:39 pipeline.py:712] Training Step 3860: Policy loss = 2.0122036933898926, value loss = 0.8828873634338379\n",
      "INFO 2024-12-04 15:56:03 pipeline.py:738] training_steps 3872: Validation loss: Poliy loss 2.05547631568596, value_loss 0.894088410451764\n",
      "INFO 2024-12-04 15:56:06 pipeline.py:712] Training Step 3880: Policy loss = 1.9794574975967407, value loss = 0.8797106742858887\n",
      "INFO 2024-12-04 15:56:16 pipeline.py:712] Training Step 3900: Policy loss = 1.9958080053329468, value loss = 0.8800426721572876\n",
      "INFO 2024-12-04 15:56:26 pipeline.py:712] Training Step 3920: Policy loss = 1.929015874862671, value loss = 0.8775620460510254\n",
      "INFO 2024-12-04 15:56:35 pipeline.py:712] Training Step 3940: Policy loss = 1.968231439590454, value loss = 0.9327329993247986\n",
      "INFO 2024-12-04 15:56:45 pipeline.py:712] Training Step 3960: Policy loss = 1.9489691257476807, value loss = 0.898806631565094\n",
      "INFO 2024-12-04 15:56:55 pipeline.py:712] Training Step 3980: Policy loss = 1.9640252590179443, value loss = 0.8745721578598022\n",
      "INFO 2024-12-04 15:57:05 pipeline.py:712] Training Step 4000: Policy loss = 1.9716376066207886, value loss = 0.8872516751289368\n",
      "INFO 2024-12-04 15:57:14 pipeline.py:712] Training Step 4020: Policy loss = 1.9269042015075684, value loss = 0.8895282745361328\n",
      "INFO 2024-12-04 15:57:24 pipeline.py:712] Training Step 4040: Policy loss = 1.9247806072235107, value loss = 0.8989737033843994\n",
      "INFO 2024-12-04 15:57:33 pipeline.py:712] Training Step 4060: Policy loss = 2.0061073303222656, value loss = 0.8640422224998474\n",
      "INFO 2024-12-04 15:57:43 pipeline.py:712] Training Step 4080: Policy loss = 2.033083438873291, value loss = 0.8974122405052185\n",
      "INFO 2024-12-04 15:57:53 pipeline.py:712] Training Step 4100: Policy loss = 1.892942190170288, value loss = 0.8605886697769165\n",
      "INFO 2024-12-04 15:58:02 pipeline.py:712] Training Step 4120: Policy loss = 1.9540278911590576, value loss = 0.8747994899749756\n",
      "INFO 2024-12-04 15:58:12 pipeline.py:712] Training Step 4140: Policy loss = 1.9982258081436157, value loss = 0.8771742582321167\n",
      "INFO 2024-12-04 15:58:22 pipeline.py:712] Training Step 4160: Policy loss = 2.0317423343658447, value loss = 0.8716251254081726\n",
      "INFO 2024-12-04 15:58:31 pipeline.py:712] Training Step 4180: Policy loss = 1.9980285167694092, value loss = 0.8489980697631836\n",
      "INFO 2024-12-04 15:58:41 pipeline.py:712] Training Step 4200: Policy loss = 1.9668861627578735, value loss = 0.8828111886978149\n",
      "INFO 2024-12-04 15:58:51 pipeline.py:712] Training Step 4220: Policy loss = 2.0042881965637207, value loss = 0.8947502374649048\n",
      "INFO 2024-12-04 15:59:00 pipeline.py:712] Training Step 4240: Policy loss = 1.8669731616973877, value loss = 0.8757920861244202\n",
      "INFO 2024-12-04 15:59:10 pipeline.py:712] Training Step 4260: Policy loss = 2.026407241821289, value loss = 0.8894914388656616\n",
      "INFO 2024-12-04 15:59:19 pipeline.py:712] Training Step 4280: Policy loss = 1.8994001150131226, value loss = 0.9181891083717346\n",
      "INFO 2024-12-04 15:59:29 pipeline.py:712] Training Step 4300: Policy loss = 1.9856364727020264, value loss = 0.8735866546630859\n",
      "INFO 2024-12-04 15:59:39 pipeline.py:712] Training Step 4320: Policy loss = 2.0234780311584473, value loss = 0.8551038503646851\n",
      "INFO 2024-12-04 15:59:49 pipeline.py:712] Training Step 4340: Policy loss = 1.9522154331207275, value loss = 0.8899950385093689\n",
      "INFO 2024-12-04 16:00:14 pipeline.py:738] training_steps 4356: Validation loss: Poliy loss 2.0371497263673874, value_loss 0.8763532511523513\n",
      "INFO 2024-12-04 16:00:16 pipeline.py:712] Training Step 4360: Policy loss = 1.890864610671997, value loss = 0.8797461986541748\n",
      "INFO 2024-12-04 16:00:26 pipeline.py:712] Training Step 4380: Policy loss = 1.8416950702667236, value loss = 0.8693344593048096\n",
      "INFO 2024-12-04 16:00:35 pipeline.py:712] Training Step 4400: Policy loss = 1.955822467803955, value loss = 0.8825247883796692\n",
      "INFO 2024-12-04 16:00:45 pipeline.py:712] Training Step 4420: Policy loss = 1.9307529926300049, value loss = 0.8796528577804565\n",
      "INFO 2024-12-04 16:00:55 pipeline.py:712] Training Step 4440: Policy loss = 2.013805627822876, value loss = 0.8740458488464355\n",
      "INFO 2024-12-04 16:01:05 pipeline.py:712] Training Step 4460: Policy loss = 2.0280003547668457, value loss = 0.8890122175216675\n",
      "INFO 2024-12-04 16:01:14 pipeline.py:712] Training Step 4480: Policy loss = 1.875401496887207, value loss = 0.8698848485946655\n",
      "INFO 2024-12-04 16:01:24 pipeline.py:712] Training Step 4500: Policy loss = 1.9462463855743408, value loss = 0.8341124057769775\n",
      "INFO 2024-12-04 16:01:33 pipeline.py:712] Training Step 4520: Policy loss = 1.903357982635498, value loss = 0.8432221412658691\n",
      "INFO 2024-12-04 16:01:43 pipeline.py:712] Training Step 4540: Policy loss = 2.0598807334899902, value loss = 0.8517991304397583\n",
      "INFO 2024-12-04 16:01:53 pipeline.py:712] Training Step 4560: Policy loss = 1.906792163848877, value loss = 0.8918136954307556\n",
      "INFO 2024-12-04 16:02:03 pipeline.py:712] Training Step 4580: Policy loss = 1.8850736618041992, value loss = 0.916643500328064\n",
      "INFO 2024-12-04 16:02:12 pipeline.py:712] Training Step 4600: Policy loss = 1.997135043144226, value loss = 0.8456050753593445\n",
      "INFO 2024-12-04 16:02:22 pipeline.py:712] Training Step 4620: Policy loss = 1.906343698501587, value loss = 0.8583821058273315\n",
      "INFO 2024-12-04 16:02:31 pipeline.py:712] Training Step 4640: Policy loss = 1.9586260318756104, value loss = 0.8758059740066528\n",
      "INFO 2024-12-04 16:02:41 pipeline.py:712] Training Step 4660: Policy loss = 1.8886311054229736, value loss = 0.8876453638076782\n",
      "INFO 2024-12-04 16:02:51 pipeline.py:712] Training Step 4680: Policy loss = 1.9286303520202637, value loss = 0.8719813823699951\n",
      "INFO 2024-12-04 16:03:00 pipeline.py:712] Training Step 4700: Policy loss = 1.9827817678451538, value loss = 0.8382093906402588\n",
      "INFO 2024-12-04 16:03:10 pipeline.py:712] Training Step 4720: Policy loss = 1.9671275615692139, value loss = 0.8738327026367188\n",
      "INFO 2024-12-04 16:03:20 pipeline.py:712] Training Step 4740: Policy loss = 1.9748141765594482, value loss = 0.8617753982543945\n",
      "INFO 2024-12-04 16:03:29 pipeline.py:712] Training Step 4760: Policy loss = 1.9450769424438477, value loss = 0.8523618578910828\n",
      "INFO 2024-12-04 16:03:39 pipeline.py:712] Training Step 4780: Policy loss = 1.9170186519622803, value loss = 0.8787497878074646\n",
      "INFO 2024-12-04 16:03:48 pipeline.py:712] Training Step 4800: Policy loss = 1.9624786376953125, value loss = 0.8572399616241455\n",
      "INFO 2024-12-04 16:03:58 pipeline.py:712] Training Step 4820: Policy loss = 1.9506912231445312, value loss = 0.8127794861793518\n",
      "INFO 2024-12-04 16:04:08 pipeline.py:712] Training Step 4840: Policy loss = 1.821512222290039, value loss = 0.8641964197158813\n",
      "INFO 2024-12-04 16:04:26 pipeline.py:738] training_steps 4840: Validation loss: Poliy loss 1.9851669639837546, value_loss 0.8642557473456274\n",
      "INFO 2024-12-04 16:04:35 pipeline.py:712] Training Step 4860: Policy loss = 1.9537838697433472, value loss = 0.8360755443572998\n",
      "INFO 2024-12-04 16:04:45 pipeline.py:712] Training Step 4880: Policy loss = 1.891209363937378, value loss = 0.8967668414115906\n",
      "INFO 2024-12-04 16:04:55 pipeline.py:712] Training Step 4900: Policy loss = 1.9256665706634521, value loss = 0.8561465740203857\n",
      "INFO 2024-12-04 16:05:04 pipeline.py:712] Training Step 4920: Policy loss = 1.900005578994751, value loss = 0.8396140336990356\n",
      "INFO 2024-12-04 16:05:14 pipeline.py:712] Training Step 4940: Policy loss = 1.8885583877563477, value loss = 0.8551687002182007\n",
      "INFO 2024-12-04 16:05:24 pipeline.py:712] Training Step 4960: Policy loss = 1.8796427249908447, value loss = 0.8420641422271729\n",
      "INFO 2024-12-04 16:05:33 pipeline.py:712] Training Step 4980: Policy loss = 1.9786251783370972, value loss = 0.8419182896614075\n",
      "INFO 2024-12-04 16:05:43 pipeline.py:712] Training Step 5000: Policy loss = 1.9218038320541382, value loss = 0.841722846031189\n",
      "INFO 2024-12-04 16:05:53 pipeline.py:712] Training Step 5020: Policy loss = 1.9086589813232422, value loss = 0.8704569339752197\n",
      "INFO 2024-12-04 16:06:02 pipeline.py:712] Training Step 5040: Policy loss = 1.9206395149230957, value loss = 0.8527032136917114\n",
      "INFO 2024-12-04 16:06:12 pipeline.py:712] Training Step 5060: Policy loss = 1.8974995613098145, value loss = 0.8782071471214294\n",
      "INFO 2024-12-04 16:06:21 pipeline.py:712] Training Step 5080: Policy loss = 1.8960638046264648, value loss = 0.8484735488891602\n",
      "INFO 2024-12-04 16:06:31 pipeline.py:712] Training Step 5100: Policy loss = 1.9157156944274902, value loss = 0.8226550221443176\n",
      "INFO 2024-12-04 16:06:41 pipeline.py:712] Training Step 5120: Policy loss = 1.8941805362701416, value loss = 0.8579608201980591\n",
      "INFO 2024-12-04 16:06:50 pipeline.py:712] Training Step 5140: Policy loss = 1.844829797744751, value loss = 0.9147523641586304\n",
      "INFO 2024-12-04 16:07:00 pipeline.py:712] Training Step 5160: Policy loss = 1.8682781457901, value loss = 0.8522124290466309\n",
      "INFO 2024-12-04 16:07:10 pipeline.py:712] Training Step 5180: Policy loss = 1.9314682483673096, value loss = 0.8490481972694397\n",
      "INFO 2024-12-04 16:07:19 pipeline.py:712] Training Step 5200: Policy loss = 1.9148712158203125, value loss = 0.8711313009262085\n",
      "INFO 2024-12-04 16:07:29 pipeline.py:712] Training Step 5220: Policy loss = 1.9031970500946045, value loss = 0.9153439998626709\n",
      "INFO 2024-12-04 16:07:39 pipeline.py:712] Training Step 5240: Policy loss = 1.871591329574585, value loss = 0.8540896773338318\n",
      "INFO 2024-12-04 16:07:48 pipeline.py:712] Training Step 5260: Policy loss = 1.9212135076522827, value loss = 0.8508870601654053\n",
      "INFO 2024-12-04 16:07:58 pipeline.py:712] Training Step 5280: Policy loss = 1.9577136039733887, value loss = 0.8563318848609924\n",
      "INFO 2024-12-04 16:08:07 pipeline.py:712] Training Step 5300: Policy loss = 1.9940879344940186, value loss = 0.853614330291748\n",
      "INFO 2024-12-04 16:08:17 pipeline.py:712] Training Step 5320: Policy loss = 1.9214540719985962, value loss = 0.9041484594345093\n",
      "INFO 2024-12-04 16:08:37 pipeline.py:738] training_steps 5324: Validation loss: Poliy loss 1.9596335702255123, value_loss 0.8751589426251708\n",
      "INFO 2024-12-04 16:08:44 pipeline.py:712] Training Step 5340: Policy loss = 1.8483445644378662, value loss = 0.8460603952407837\n",
      "INFO 2024-12-04 16:08:54 pipeline.py:712] Training Step 5360: Policy loss = 1.9221503734588623, value loss = 0.8656372427940369\n",
      "INFO 2024-12-04 16:09:04 pipeline.py:712] Training Step 5380: Policy loss = 1.8085170984268188, value loss = 0.8206691741943359\n",
      "INFO 2024-12-04 16:09:13 pipeline.py:712] Training Step 5400: Policy loss = 1.8994781970977783, value loss = 0.8759201765060425\n",
      "INFO 2024-12-04 16:09:23 pipeline.py:712] Training Step 5420: Policy loss = 1.8617475032806396, value loss = 0.8188313245773315\n",
      "INFO 2024-12-04 16:09:33 pipeline.py:712] Training Step 5440: Policy loss = 1.7869131565093994, value loss = 0.8180060386657715\n",
      "INFO 2024-12-04 16:09:43 pipeline.py:712] Training Step 5460: Policy loss = 1.9419775009155273, value loss = 0.8081029653549194\n",
      "INFO 2024-12-04 16:09:52 pipeline.py:712] Training Step 5480: Policy loss = 1.8643410205841064, value loss = 0.8185713887214661\n",
      "INFO 2024-12-04 16:10:02 pipeline.py:712] Training Step 5500: Policy loss = 1.7953617572784424, value loss = 0.8250235319137573\n",
      "INFO 2024-12-04 16:10:12 pipeline.py:712] Training Step 5520: Policy loss = 1.8292009830474854, value loss = 0.8042335510253906\n",
      "INFO 2024-12-04 16:10:21 pipeline.py:712] Training Step 5540: Policy loss = 1.9365170001983643, value loss = 0.8270540833473206\n",
      "INFO 2024-12-04 16:10:31 pipeline.py:712] Training Step 5560: Policy loss = 1.9710971117019653, value loss = 0.8015140295028687\n",
      "INFO 2024-12-04 16:10:41 pipeline.py:712] Training Step 5580: Policy loss = 1.876633882522583, value loss = 0.8304508924484253\n",
      "INFO 2024-12-04 16:10:50 pipeline.py:712] Training Step 5600: Policy loss = 1.8245861530303955, value loss = 0.8203984498977661\n",
      "INFO 2024-12-04 16:11:00 pipeline.py:712] Training Step 5620: Policy loss = 1.8765034675598145, value loss = 0.7991862297058105\n",
      "INFO 2024-12-04 16:11:10 pipeline.py:712] Training Step 5640: Policy loss = 1.8423011302947998, value loss = 0.8192891478538513\n",
      "INFO 2024-12-04 16:11:19 pipeline.py:712] Training Step 5660: Policy loss = 1.9623430967330933, value loss = 0.8178581595420837\n",
      "INFO 2024-12-04 16:11:29 pipeline.py:712] Training Step 5680: Policy loss = 1.842824101448059, value loss = 0.8423087000846863\n",
      "INFO 2024-12-04 16:11:39 pipeline.py:712] Training Step 5700: Policy loss = 1.860868215560913, value loss = 0.8322160840034485\n",
      "INFO 2024-12-04 16:11:48 pipeline.py:712] Training Step 5720: Policy loss = 1.8743667602539062, value loss = 0.8782692551612854\n",
      "INFO 2024-12-04 16:11:58 pipeline.py:712] Training Step 5740: Policy loss = 1.8585233688354492, value loss = 0.8255510330200195\n",
      "INFO 2024-12-04 16:12:08 pipeline.py:712] Training Step 5760: Policy loss = 1.7985224723815918, value loss = 0.8298148512840271\n",
      "INFO 2024-12-04 16:12:18 pipeline.py:712] Training Step 5780: Policy loss = 1.8783471584320068, value loss = 0.7766309976577759\n",
      "INFO 2024-12-04 16:12:27 pipeline.py:712] Training Step 5800: Policy loss = 1.8906716108322144, value loss = 0.8115167617797852\n",
      "INFO 2024-12-04 16:12:49 pipeline.py:738] training_steps 5808: Validation loss: Poliy loss 1.9409793361288603, value_loss 0.8193529844284058\n",
      "INFO 2024-12-04 16:12:55 pipeline.py:712] Training Step 5820: Policy loss = 1.8143105506896973, value loss = 0.7965770363807678\n",
      "INFO 2024-12-04 16:13:05 pipeline.py:712] Training Step 5840: Policy loss = 1.7670583724975586, value loss = 0.8082060813903809\n",
      "INFO 2024-12-04 16:13:14 pipeline.py:712] Training Step 5860: Policy loss = 1.8214399814605713, value loss = 0.7932003736495972\n",
      "INFO 2024-12-04 16:13:24 pipeline.py:712] Training Step 5880: Policy loss = 1.8336434364318848, value loss = 0.7521226406097412\n",
      "INFO 2024-12-04 16:13:34 pipeline.py:712] Training Step 5900: Policy loss = 1.8099918365478516, value loss = 0.7904825210571289\n",
      "INFO 2024-12-04 16:13:44 pipeline.py:712] Training Step 5920: Policy loss = 1.8524894714355469, value loss = 0.7656909227371216\n",
      "INFO 2024-12-04 16:13:53 pipeline.py:712] Training Step 5940: Policy loss = 1.7719793319702148, value loss = 0.8455706238746643\n",
      "INFO 2024-12-04 16:14:03 pipeline.py:712] Training Step 5960: Policy loss = 1.7795546054840088, value loss = 0.807675838470459\n",
      "INFO 2024-12-04 16:14:12 pipeline.py:712] Training Step 5980: Policy loss = 1.8591718673706055, value loss = 0.8071264028549194\n",
      "INFO 2024-12-04 16:14:22 pipeline.py:712] Training Step 6000: Policy loss = 1.867748737335205, value loss = 0.7842371463775635\n",
      "INFO 2024-12-04 16:14:32 pipeline.py:712] Training Step 6020: Policy loss = 1.8716766834259033, value loss = 0.7749180793762207\n",
      "INFO 2024-12-04 16:14:41 pipeline.py:712] Training Step 6040: Policy loss = 1.7867858409881592, value loss = 0.7801914215087891\n",
      "INFO 2024-12-04 16:14:51 pipeline.py:712] Training Step 6060: Policy loss = 1.916412591934204, value loss = 0.7872112989425659\n",
      "INFO 2024-12-04 16:15:01 pipeline.py:712] Training Step 6080: Policy loss = 1.9161467552185059, value loss = 0.8305720090866089\n",
      "INFO 2024-12-04 16:15:11 pipeline.py:712] Training Step 6100: Policy loss = 1.8451411724090576, value loss = 0.80266934633255\n",
      "INFO 2024-12-04 16:15:20 pipeline.py:712] Training Step 6120: Policy loss = 1.855724811553955, value loss = 0.7783725261688232\n",
      "INFO 2024-12-04 16:15:30 pipeline.py:712] Training Step 6140: Policy loss = 1.8411142826080322, value loss = 0.7518025636672974\n",
      "INFO 2024-12-04 16:15:40 pipeline.py:712] Training Step 6160: Policy loss = 1.8084267377853394, value loss = 0.7719483375549316\n",
      "INFO 2024-12-04 16:15:49 pipeline.py:712] Training Step 6180: Policy loss = 1.8026565313339233, value loss = 0.8199253082275391\n",
      "INFO 2024-12-04 16:15:59 pipeline.py:712] Training Step 6200: Policy loss = 1.850562572479248, value loss = 0.8231562376022339\n",
      "INFO 2024-12-04 16:16:09 pipeline.py:712] Training Step 6220: Policy loss = 1.8078198432922363, value loss = 0.7941343784332275\n",
      "INFO 2024-12-04 16:16:18 pipeline.py:712] Training Step 6240: Policy loss = 1.906844973564148, value loss = 0.7878696322441101\n",
      "INFO 2024-12-04 16:16:28 pipeline.py:712] Training Step 6260: Policy loss = 1.8083161115646362, value loss = 0.7831963300704956\n",
      "INFO 2024-12-04 16:16:38 pipeline.py:712] Training Step 6280: Policy loss = 1.8420841693878174, value loss = 0.7932192087173462\n",
      "INFO 2024-12-04 16:17:02 pipeline.py:738] training_steps 6292: Validation loss: Poliy loss 1.9429900372614626, value_loss 0.805941534335496\n",
      "INFO 2024-12-04 16:17:05 pipeline.py:712] Training Step 6300: Policy loss = 1.8043206930160522, value loss = 0.733422040939331\n",
      "INFO 2024-12-04 16:17:15 pipeline.py:712] Training Step 6320: Policy loss = 1.6881002187728882, value loss = 0.7707492709159851\n",
      "INFO 2024-12-04 16:17:25 pipeline.py:712] Training Step 6340: Policy loss = 1.8292908668518066, value loss = 0.7719483971595764\n",
      "INFO 2024-12-04 16:17:34 pipeline.py:712] Training Step 6360: Policy loss = 1.8402900695800781, value loss = 0.7698872089385986\n",
      "INFO 2024-12-04 16:17:44 pipeline.py:712] Training Step 6380: Policy loss = 1.820243239402771, value loss = 0.8030368685722351\n",
      "INFO 2024-12-04 16:17:54 pipeline.py:712] Training Step 6400: Policy loss = 1.862885594367981, value loss = 0.7589192390441895\n",
      "INFO 2024-12-04 16:18:03 pipeline.py:712] Training Step 6420: Policy loss = 1.7558023929595947, value loss = 0.751417875289917\n",
      "INFO 2024-12-04 16:18:13 pipeline.py:712] Training Step 6440: Policy loss = 1.747974157333374, value loss = 0.7434253692626953\n",
      "INFO 2024-12-04 16:18:23 pipeline.py:712] Training Step 6460: Policy loss = 1.749679684638977, value loss = 0.8191670775413513\n",
      "INFO 2024-12-04 16:18:32 pipeline.py:712] Training Step 6480: Policy loss = 1.812122106552124, value loss = 0.8189396262168884\n",
      "INFO 2024-12-04 16:18:42 pipeline.py:712] Training Step 6500: Policy loss = 1.801163911819458, value loss = 0.7903905510902405\n",
      "INFO 2024-12-04 16:18:52 pipeline.py:712] Training Step 6520: Policy loss = 1.7713990211486816, value loss = 0.7522573471069336\n",
      "INFO 2024-12-04 16:19:01 pipeline.py:712] Training Step 6540: Policy loss = 1.7867431640625, value loss = 0.7592858672142029\n",
      "INFO 2024-12-04 16:19:11 pipeline.py:712] Training Step 6560: Policy loss = 1.8113394975662231, value loss = 0.7743878364562988\n",
      "INFO 2024-12-04 16:19:21 pipeline.py:712] Training Step 6580: Policy loss = 1.832582950592041, value loss = 0.788740873336792\n",
      "INFO 2024-12-04 16:19:30 pipeline.py:712] Training Step 6600: Policy loss = 1.797594428062439, value loss = 0.7401415109634399\n",
      "INFO 2024-12-04 16:19:40 pipeline.py:712] Training Step 6620: Policy loss = 1.7680633068084717, value loss = 0.786209225654602\n",
      "INFO 2024-12-04 16:19:50 pipeline.py:712] Training Step 6640: Policy loss = 1.7943272590637207, value loss = 0.7996742725372314\n",
      "INFO 2024-12-04 16:19:59 pipeline.py:712] Training Step 6660: Policy loss = 1.7963030338287354, value loss = 0.7781355381011963\n",
      "INFO 2024-12-04 16:20:09 pipeline.py:712] Training Step 6680: Policy loss = 1.80988347530365, value loss = 0.771481454372406\n",
      "INFO 2024-12-04 16:20:18 pipeline.py:712] Training Step 6700: Policy loss = 1.8496654033660889, value loss = 0.7438317537307739\n",
      "INFO 2024-12-04 16:20:28 pipeline.py:712] Training Step 6720: Policy loss = 1.794695496559143, value loss = 0.7360384464263916\n",
      "INFO 2024-12-04 16:20:38 pipeline.py:712] Training Step 6740: Policy loss = 1.8002228736877441, value loss = 0.7710103988647461\n",
      "INFO 2024-12-04 16:20:47 pipeline.py:712] Training Step 6760: Policy loss = 1.7395691871643066, value loss = 0.7314805388450623\n",
      "INFO 2024-12-04 16:21:13 pipeline.py:738] training_steps 6776: Validation loss: Poliy loss 1.923140377294822, value_loss 0.7780428475043812\n",
      "INFO 2024-12-04 16:21:15 pipeline.py:712] Training Step 6780: Policy loss = 1.7201616764068604, value loss = 0.6997743844985962\n",
      "INFO 2024-12-04 16:21:24 pipeline.py:712] Training Step 6800: Policy loss = 1.7404083013534546, value loss = 0.7494033575057983\n",
      "INFO 2024-12-04 16:21:34 pipeline.py:712] Training Step 6820: Policy loss = 1.7004460096359253, value loss = 0.7385290861129761\n",
      "INFO 2024-12-04 16:21:44 pipeline.py:712] Training Step 6840: Policy loss = 1.6862378120422363, value loss = 0.7138900756835938\n",
      "INFO 2024-12-04 16:21:53 pipeline.py:712] Training Step 6860: Policy loss = 1.8417121171951294, value loss = 0.7414932250976562\n",
      "INFO 2024-12-04 16:22:03 pipeline.py:712] Training Step 6880: Policy loss = 1.8367209434509277, value loss = 0.7139538526535034\n",
      "INFO 2024-12-04 16:22:13 pipeline.py:712] Training Step 6900: Policy loss = 1.7697205543518066, value loss = 0.7516922354698181\n",
      "INFO 2024-12-04 16:22:22 pipeline.py:712] Training Step 6920: Policy loss = 1.7412967681884766, value loss = 0.7205373048782349\n",
      "INFO 2024-12-04 16:22:32 pipeline.py:712] Training Step 6940: Policy loss = 1.8955097198486328, value loss = 0.7125358581542969\n",
      "INFO 2024-12-04 16:22:41 pipeline.py:712] Training Step 6960: Policy loss = 1.8175697326660156, value loss = 0.7602512240409851\n",
      "INFO 2024-12-04 16:22:51 pipeline.py:712] Training Step 6980: Policy loss = 1.8152893781661987, value loss = 0.7874307632446289\n",
      "INFO 2024-12-04 16:23:01 pipeline.py:712] Training Step 7000: Policy loss = 1.737121820449829, value loss = 0.7781862020492554\n",
      "INFO 2024-12-04 16:23:11 pipeline.py:712] Training Step 7020: Policy loss = 1.8641166687011719, value loss = 0.7099578976631165\n",
      "INFO 2024-12-04 16:23:20 pipeline.py:712] Training Step 7040: Policy loss = 1.7677435874938965, value loss = 0.7217293977737427\n",
      "INFO 2024-12-04 16:23:30 pipeline.py:712] Training Step 7060: Policy loss = 1.8112062215805054, value loss = 0.6662725806236267\n",
      "INFO 2024-12-04 16:23:39 pipeline.py:712] Training Step 7080: Policy loss = 1.829763412475586, value loss = 0.7190523147583008\n",
      "INFO 2024-12-04 16:23:49 pipeline.py:712] Training Step 7100: Policy loss = 1.7716991901397705, value loss = 0.7283565998077393\n",
      "INFO 2024-12-04 16:23:59 pipeline.py:712] Training Step 7120: Policy loss = 1.7996277809143066, value loss = 0.7188533544540405\n",
      "INFO 2024-12-04 16:24:08 pipeline.py:712] Training Step 7140: Policy loss = 1.7596285343170166, value loss = 0.7402017116546631\n",
      "INFO 2024-12-04 16:24:18 pipeline.py:712] Training Step 7160: Policy loss = 1.808861494064331, value loss = 0.7409441471099854\n",
      "INFO 2024-12-04 16:24:27 pipeline.py:712] Training Step 7180: Policy loss = 1.8371171951293945, value loss = 0.7637711763381958\n",
      "INFO 2024-12-04 16:24:37 pipeline.py:712] Training Step 7200: Policy loss = 1.770588994026184, value loss = 0.7309340238571167\n",
      "INFO 2024-12-04 16:24:47 pipeline.py:712] Training Step 7220: Policy loss = 1.769100308418274, value loss = 0.7429879903793335\n",
      "INFO 2024-12-04 16:24:56 pipeline.py:712] Training Step 7240: Policy loss = 1.8109463453292847, value loss = 0.7190099954605103\n",
      "INFO 2024-12-04 16:25:06 pipeline.py:712] Training Step 7260: Policy loss = 1.8469135761260986, value loss = 0.7341278195381165\n",
      "INFO 2024-12-04 16:25:24 pipeline.py:738] training_steps 7260: Validation loss: Poliy loss 1.9027074399541637, value_loss 0.7515107217382212\n",
      "INFO 2024-12-04 16:25:34 pipeline.py:712] Training Step 7280: Policy loss = 1.8068737983703613, value loss = 0.6960233449935913\n",
      "INFO 2024-12-04 16:25:43 pipeline.py:712] Training Step 7300: Policy loss = 1.7880513668060303, value loss = 0.6870687007904053\n",
      "INFO 2024-12-04 16:25:53 pipeline.py:712] Training Step 7320: Policy loss = 1.725494146347046, value loss = 0.669529139995575\n",
      "INFO 2024-12-04 16:26:02 pipeline.py:712] Training Step 7340: Policy loss = 1.743670105934143, value loss = 0.7346486449241638\n",
      "INFO 2024-12-04 16:26:12 pipeline.py:712] Training Step 7360: Policy loss = 1.8510700464248657, value loss = 0.7088534832000732\n",
      "INFO 2024-12-04 16:26:22 pipeline.py:712] Training Step 7380: Policy loss = 1.7980413436889648, value loss = 0.7645547389984131\n",
      "INFO 2024-12-04 16:26:31 pipeline.py:712] Training Step 7400: Policy loss = 1.8542529344558716, value loss = 0.6970194578170776\n",
      "INFO 2024-12-04 16:26:41 pipeline.py:712] Training Step 7420: Policy loss = 1.8485898971557617, value loss = 0.6304501295089722\n",
      "INFO 2024-12-04 16:26:51 pipeline.py:712] Training Step 7440: Policy loss = 1.8537511825561523, value loss = 0.6508899927139282\n",
      "INFO 2024-12-04 16:27:00 pipeline.py:712] Training Step 7460: Policy loss = 1.808383822441101, value loss = 0.675142765045166\n",
      "INFO 2024-12-04 16:27:10 pipeline.py:712] Training Step 7480: Policy loss = 1.7824898958206177, value loss = 0.7222779989242554\n",
      "INFO 2024-12-04 16:27:20 pipeline.py:712] Training Step 7500: Policy loss = 1.8226211071014404, value loss = 0.7624351382255554\n",
      "INFO 2024-12-04 16:27:29 pipeline.py:712] Training Step 7520: Policy loss = 1.725127935409546, value loss = 0.6598700284957886\n",
      "INFO 2024-12-04 16:27:39 pipeline.py:712] Training Step 7540: Policy loss = 1.7863271236419678, value loss = 0.6737741827964783\n",
      "INFO 2024-12-04 16:27:48 pipeline.py:712] Training Step 7560: Policy loss = 1.7456073760986328, value loss = 0.6794151663780212\n",
      "INFO 2024-12-04 16:27:58 pipeline.py:712] Training Step 7580: Policy loss = 1.7766454219818115, value loss = 0.6684924364089966\n",
      "INFO 2024-12-04 16:28:08 pipeline.py:712] Training Step 7600: Policy loss = 1.8296458721160889, value loss = 0.6682219505310059\n",
      "INFO 2024-12-04 16:28:17 pipeline.py:712] Training Step 7620: Policy loss = 1.7944525480270386, value loss = 0.6515243649482727\n",
      "INFO 2024-12-04 16:28:27 pipeline.py:712] Training Step 7640: Policy loss = 1.7813992500305176, value loss = 0.631777822971344\n",
      "INFO 2024-12-04 16:28:36 pipeline.py:712] Training Step 7660: Policy loss = 1.8496077060699463, value loss = 0.667137861251831\n",
      "INFO 2024-12-04 16:28:46 pipeline.py:712] Training Step 7680: Policy loss = 1.7763352394104004, value loss = 0.7075214385986328\n",
      "INFO 2024-12-04 16:28:56 pipeline.py:712] Training Step 7700: Policy loss = 1.8327465057373047, value loss = 0.705551028251648\n",
      "INFO 2024-12-04 16:29:05 pipeline.py:712] Training Step 7720: Policy loss = 1.8007723093032837, value loss = 0.6289546489715576\n",
      "INFO 2024-12-04 16:29:15 pipeline.py:712] Training Step 7740: Policy loss = 1.750577449798584, value loss = 0.6940621137619019\n",
      "INFO 2024-12-04 16:29:35 pipeline.py:738] training_steps 7744: Validation loss: Poliy loss 1.9083677110124806, value_loss 0.7058921172970631\n",
      "INFO 2024-12-04 16:29:42 pipeline.py:712] Training Step 7760: Policy loss = 1.770045280456543, value loss = 0.7639036178588867\n",
      "INFO 2024-12-04 16:29:52 pipeline.py:712] Training Step 7780: Policy loss = 1.7117846012115479, value loss = 0.6570857763290405\n",
      "INFO 2024-12-04 16:30:02 pipeline.py:712] Training Step 7800: Policy loss = 1.8015153408050537, value loss = 0.6108713746070862\n",
      "INFO 2024-12-04 16:30:11 pipeline.py:712] Training Step 7820: Policy loss = 1.7271697521209717, value loss = 0.6692894697189331\n",
      "INFO 2024-12-04 16:30:21 pipeline.py:712] Training Step 7840: Policy loss = 1.7252171039581299, value loss = 0.6247091293334961\n",
      "INFO 2024-12-04 16:30:31 pipeline.py:712] Training Step 7860: Policy loss = 1.7559256553649902, value loss = 0.62880939245224\n",
      "INFO 2024-12-04 16:30:40 pipeline.py:712] Training Step 7880: Policy loss = 1.7706509828567505, value loss = 0.6405856013298035\n",
      "INFO 2024-12-04 16:30:50 pipeline.py:712] Training Step 7900: Policy loss = 1.7228126525878906, value loss = 0.6316773891448975\n",
      "INFO 2024-12-04 16:30:59 pipeline.py:712] Training Step 7920: Policy loss = 1.8173198699951172, value loss = 0.6672457456588745\n",
      "INFO 2024-12-04 16:31:09 pipeline.py:712] Training Step 7940: Policy loss = 1.7412059307098389, value loss = 0.6282857656478882\n",
      "INFO 2024-12-04 16:31:19 pipeline.py:712] Training Step 7960: Policy loss = 1.7868735790252686, value loss = 0.6146885752677917\n",
      "INFO 2024-12-04 16:31:28 pipeline.py:712] Training Step 7980: Policy loss = 1.7825076580047607, value loss = 0.6667607426643372\n",
      "INFO 2024-12-04 16:31:38 pipeline.py:712] Training Step 8000: Policy loss = 1.737872838973999, value loss = 0.6317782998085022\n",
      "INFO 2024-12-04 16:31:47 pipeline.py:712] Training Step 8020: Policy loss = 1.7680407762527466, value loss = 0.6223545074462891\n",
      "INFO 2024-12-04 16:31:57 pipeline.py:712] Training Step 8040: Policy loss = 1.8513983488082886, value loss = 0.6218748092651367\n",
      "INFO 2024-12-04 16:32:07 pipeline.py:712] Training Step 8060: Policy loss = 1.760643720626831, value loss = 0.5747913122177124\n",
      "INFO 2024-12-04 16:32:16 pipeline.py:712] Training Step 8080: Policy loss = 1.721510887145996, value loss = 0.70643550157547\n",
      "INFO 2024-12-04 16:32:26 pipeline.py:712] Training Step 8100: Policy loss = 1.7979841232299805, value loss = 0.6333029866218567\n",
      "INFO 2024-12-04 16:32:36 pipeline.py:712] Training Step 8120: Policy loss = 1.7359005212783813, value loss = 0.6043941974639893\n",
      "INFO 2024-12-04 16:32:45 pipeline.py:712] Training Step 8140: Policy loss = 1.738361120223999, value loss = 0.6451288461685181\n",
      "INFO 2024-12-04 16:32:55 pipeline.py:712] Training Step 8160: Policy loss = 1.6871330738067627, value loss = 0.6176785230636597\n",
      "INFO 2024-12-04 16:33:05 pipeline.py:712] Training Step 8180: Policy loss = 1.788031816482544, value loss = 0.6495392322540283\n",
      "INFO 2024-12-04 16:33:14 pipeline.py:712] Training Step 8200: Policy loss = 1.8081870079040527, value loss = 0.6413232088088989\n",
      "INFO 2024-12-04 16:33:24 pipeline.py:712] Training Step 8220: Policy loss = 1.7289549112319946, value loss = 0.6090174913406372\n",
      "INFO 2024-12-04 16:33:45 pipeline.py:738] training_steps 8228: Validation loss: Poliy loss 1.8940472417190426, value_loss 0.6605365432676722\n",
      "INFO 2024-12-04 16:33:51 pipeline.py:712] Training Step 8240: Policy loss = 1.7353951930999756, value loss = 0.5497777462005615\n",
      "INFO 2024-12-04 16:34:01 pipeline.py:712] Training Step 8260: Policy loss = 1.7556571960449219, value loss = 0.6012907028198242\n",
      "INFO 2024-12-04 16:34:10 pipeline.py:712] Training Step 8280: Policy loss = 1.725273847579956, value loss = 0.6435133218765259\n",
      "INFO 2024-12-04 16:34:20 pipeline.py:712] Training Step 8300: Policy loss = 1.7290921211242676, value loss = 0.5941590666770935\n",
      "INFO 2024-12-04 16:34:30 pipeline.py:712] Training Step 8320: Policy loss = 1.6950786113739014, value loss = 0.6378128528594971\n",
      "INFO 2024-12-04 16:34:39 pipeline.py:712] Training Step 8340: Policy loss = 1.7937541007995605, value loss = 0.6406452655792236\n",
      "INFO 2024-12-04 16:34:49 pipeline.py:712] Training Step 8360: Policy loss = 1.7576305866241455, value loss = 0.5986231565475464\n",
      "INFO 2024-12-04 16:34:58 pipeline.py:712] Training Step 8380: Policy loss = 1.7007575035095215, value loss = 0.5902221202850342\n",
      "INFO 2024-12-04 16:35:08 pipeline.py:712] Training Step 8400: Policy loss = 1.798112154006958, value loss = 0.5939669013023376\n",
      "INFO 2024-12-04 16:35:18 pipeline.py:712] Training Step 8420: Policy loss = 1.735410213470459, value loss = 0.6853563189506531\n",
      "INFO 2024-12-04 16:35:27 pipeline.py:712] Training Step 8440: Policy loss = 1.7108850479125977, value loss = 0.6195484399795532\n",
      "INFO 2024-12-04 16:35:37 pipeline.py:712] Training Step 8460: Policy loss = 1.8192284107208252, value loss = 0.6026610136032104\n",
      "INFO 2024-12-04 16:35:46 pipeline.py:712] Training Step 8480: Policy loss = 1.7304949760437012, value loss = 0.5412063598632812\n",
      "INFO 2024-12-04 16:35:56 pipeline.py:712] Training Step 8500: Policy loss = 1.691521167755127, value loss = 0.5974156260490417\n",
      "INFO 2024-12-04 16:36:06 pipeline.py:712] Training Step 8520: Policy loss = 1.7512890100479126, value loss = 0.5953608751296997\n",
      "INFO 2024-12-04 16:36:15 pipeline.py:712] Training Step 8540: Policy loss = 1.8469371795654297, value loss = 0.5752320289611816\n",
      "INFO 2024-12-04 16:36:25 pipeline.py:712] Training Step 8560: Policy loss = 1.826319932937622, value loss = 0.5992076396942139\n",
      "INFO 2024-12-04 16:36:35 pipeline.py:712] Training Step 8580: Policy loss = 1.807121992111206, value loss = 0.5934720039367676\n",
      "INFO 2024-12-04 16:36:44 pipeline.py:712] Training Step 8600: Policy loss = 1.7225146293640137, value loss = 0.5954562425613403\n",
      "INFO 2024-12-04 16:36:54 pipeline.py:712] Training Step 8620: Policy loss = 1.7762761116027832, value loss = 0.6515536308288574\n",
      "INFO 2024-12-04 16:37:03 pipeline.py:712] Training Step 8640: Policy loss = 1.7669034004211426, value loss = 0.5608433485031128\n",
      "INFO 2024-12-04 16:37:13 pipeline.py:712] Training Step 8660: Policy loss = 1.7419542074203491, value loss = 0.5808238387107849\n",
      "INFO 2024-12-04 16:37:23 pipeline.py:712] Training Step 8680: Policy loss = 1.7304590940475464, value loss = 0.5612702369689941\n",
      "INFO 2024-12-04 16:37:32 pipeline.py:712] Training Step 8700: Policy loss = 1.851454257965088, value loss = 0.5772390365600586\n",
      "INFO 2024-12-04 16:37:56 pipeline.py:738] training_steps 8712: Validation loss: Poliy loss 1.8986075432574163, value_loss 0.6266503338931037\n",
      "INFO 2024-12-04 16:38:00 pipeline.py:712] Training Step 8720: Policy loss = 1.6729716062545776, value loss = 0.5603858232498169\n",
      "INFO 2024-12-04 16:38:09 pipeline.py:712] Training Step 8740: Policy loss = 1.7016271352767944, value loss = 0.6110519170761108\n",
      "INFO 2024-12-04 16:38:19 pipeline.py:712] Training Step 8760: Policy loss = 1.7115685939788818, value loss = 0.5591989755630493\n",
      "INFO 2024-12-04 16:38:29 pipeline.py:712] Training Step 8780: Policy loss = 1.7599462270736694, value loss = 0.6142914891242981\n",
      "INFO 2024-12-04 16:38:38 pipeline.py:712] Training Step 8800: Policy loss = 1.740558385848999, value loss = 0.5668105483055115\n",
      "INFO 2024-12-04 16:38:48 pipeline.py:712] Training Step 8820: Policy loss = 1.7533528804779053, value loss = 0.5629760026931763\n",
      "INFO 2024-12-04 16:38:58 pipeline.py:712] Training Step 8840: Policy loss = 1.7448780536651611, value loss = 0.5416427850723267\n",
      "INFO 2024-12-04 16:39:07 pipeline.py:712] Training Step 8860: Policy loss = 1.7022944688796997, value loss = 0.5813566446304321\n",
      "INFO 2024-12-04 16:39:17 pipeline.py:712] Training Step 8880: Policy loss = 1.781404972076416, value loss = 0.5263926982879639\n",
      "INFO 2024-12-04 16:39:26 pipeline.py:712] Training Step 8900: Policy loss = 1.7842867374420166, value loss = 0.5414402484893799\n",
      "INFO 2024-12-04 16:39:36 pipeline.py:712] Training Step 8920: Policy loss = 1.698762059211731, value loss = 0.5409250259399414\n",
      "INFO 2024-12-04 16:39:46 pipeline.py:712] Training Step 8940: Policy loss = 1.776339054107666, value loss = 0.591631293296814\n",
      "INFO 2024-12-04 16:39:55 pipeline.py:712] Training Step 8960: Policy loss = 1.7271020412445068, value loss = 0.5262178182601929\n",
      "INFO 2024-12-04 16:40:05 pipeline.py:712] Training Step 8980: Policy loss = 1.7451764345169067, value loss = 0.5643346309661865\n",
      "INFO 2024-12-04 16:40:14 pipeline.py:712] Training Step 9000: Policy loss = 1.7119823694229126, value loss = 0.5864097476005554\n",
      "INFO 2024-12-04 16:40:24 pipeline.py:712] Training Step 9020: Policy loss = 1.7918739318847656, value loss = 0.5390975475311279\n",
      "INFO 2024-12-04 16:40:33 pipeline.py:712] Training Step 9040: Policy loss = 1.7297122478485107, value loss = 0.5488267540931702\n",
      "INFO 2024-12-04 16:40:43 pipeline.py:712] Training Step 9060: Policy loss = 1.7210354804992676, value loss = 0.579068660736084\n",
      "INFO 2024-12-04 16:40:53 pipeline.py:712] Training Step 9080: Policy loss = 1.7957295179367065, value loss = 0.5227341651916504\n",
      "INFO 2024-12-04 16:41:02 pipeline.py:712] Training Step 9100: Policy loss = 1.7701914310455322, value loss = 0.5121988654136658\n",
      "INFO 2024-12-04 16:41:12 pipeline.py:712] Training Step 9120: Policy loss = 1.7795809507369995, value loss = 0.5346034169197083\n",
      "INFO 2024-12-04 16:41:21 pipeline.py:712] Training Step 9140: Policy loss = 1.7834669351577759, value loss = 0.5351114869117737\n",
      "INFO 2024-12-04 16:41:31 pipeline.py:712] Training Step 9160: Policy loss = 1.7486622333526611, value loss = 0.49801573157310486\n",
      "INFO 2024-12-04 16:41:41 pipeline.py:712] Training Step 9180: Policy loss = 1.7800889015197754, value loss = 0.5631886720657349\n",
      "INFO 2024-12-04 16:42:06 pipeline.py:738] training_steps 9196: Validation loss: Poliy loss 1.8881119812121157, value_loss 0.6095621146139552\n",
      "INFO 2024-12-04 16:42:08 pipeline.py:712] Training Step 9200: Policy loss = 1.7121031284332275, value loss = 0.5061386823654175\n",
      "INFO 2024-12-04 16:42:18 pipeline.py:712] Training Step 9220: Policy loss = 1.6924684047698975, value loss = 0.5232111215591431\n",
      "INFO 2024-12-04 16:42:27 pipeline.py:712] Training Step 9240: Policy loss = 1.7332203388214111, value loss = 0.5154029130935669\n",
      "INFO 2024-12-04 16:42:37 pipeline.py:712] Training Step 9260: Policy loss = 1.7790722846984863, value loss = 0.541144847869873\n",
      "INFO 2024-12-04 16:42:46 pipeline.py:712] Training Step 9280: Policy loss = 1.7333287000656128, value loss = 0.5695631504058838\n",
      "INFO 2024-12-04 16:42:56 pipeline.py:712] Training Step 9300: Policy loss = 1.7799451351165771, value loss = 0.5305055379867554\n",
      "INFO 2024-12-04 16:43:06 pipeline.py:712] Training Step 9320: Policy loss = 1.6371281147003174, value loss = 0.4732506275177002\n",
      "INFO 2024-12-04 16:43:15 pipeline.py:712] Training Step 9340: Policy loss = 1.7678983211517334, value loss = 0.5181357860565186\n",
      "INFO 2024-12-04 16:43:25 pipeline.py:712] Training Step 9360: Policy loss = 1.653620958328247, value loss = 0.4966961145401001\n",
      "INFO 2024-12-04 16:43:34 pipeline.py:712] Training Step 9380: Policy loss = 1.7589683532714844, value loss = 0.4986366331577301\n",
      "INFO 2024-12-04 16:43:44 pipeline.py:712] Training Step 9400: Policy loss = 1.696070671081543, value loss = 0.5327097177505493\n",
      "INFO 2024-12-04 16:43:53 pipeline.py:712] Training Step 9420: Policy loss = 1.6574640274047852, value loss = 0.49452701210975647\n",
      "INFO 2024-12-04 16:44:03 pipeline.py:712] Training Step 9440: Policy loss = 1.7175726890563965, value loss = 0.49721676111221313\n",
      "INFO 2024-12-04 16:44:13 pipeline.py:712] Training Step 9460: Policy loss = 1.760331630706787, value loss = 0.47653621435165405\n",
      "INFO 2024-12-04 16:44:22 pipeline.py:712] Training Step 9480: Policy loss = 1.6629178524017334, value loss = 0.5330474376678467\n",
      "INFO 2024-12-04 16:44:32 pipeline.py:712] Training Step 9500: Policy loss = 1.736237645149231, value loss = 0.4877035617828369\n",
      "INFO 2024-12-04 16:44:41 pipeline.py:712] Training Step 9520: Policy loss = 1.7148723602294922, value loss = 0.6027230024337769\n",
      "INFO 2024-12-04 16:44:51 pipeline.py:712] Training Step 9540: Policy loss = 1.7908380031585693, value loss = 0.5470573902130127\n",
      "INFO 2024-12-04 16:45:01 pipeline.py:712] Training Step 9560: Policy loss = 1.8356306552886963, value loss = 0.5447266101837158\n",
      "INFO 2024-12-04 16:45:10 pipeline.py:712] Training Step 9580: Policy loss = 1.6664494276046753, value loss = 0.48440831899642944\n",
      "INFO 2024-12-04 16:45:20 pipeline.py:712] Training Step 9600: Policy loss = 1.7408205270767212, value loss = 0.5181002616882324\n",
      "INFO 2024-12-04 16:45:29 pipeline.py:712] Training Step 9620: Policy loss = 1.8005887269973755, value loss = 0.51121985912323\n",
      "INFO 2024-12-04 16:45:39 pipeline.py:712] Training Step 9640: Policy loss = 1.7563629150390625, value loss = 0.5025844573974609\n",
      "INFO 2024-12-04 16:45:48 pipeline.py:712] Training Step 9660: Policy loss = 1.7978934049606323, value loss = 0.48426154255867004\n",
      "INFO 2024-12-04 16:45:58 pipeline.py:712] Training Step 9680: Policy loss = 1.7611461877822876, value loss = 0.5067058801651001\n",
      "INFO 2024-12-04 16:46:16 pipeline.py:738] training_steps 9680: Validation loss: Poliy loss 1.8766316263402094, value_loss 0.5596052694027541\n",
      "INFO 2024-12-04 16:46:25 pipeline.py:712] Training Step 9700: Policy loss = 1.7095398902893066, value loss = 0.48533737659454346\n",
      "INFO 2024-12-04 16:46:35 pipeline.py:712] Training Step 9720: Policy loss = 1.6932272911071777, value loss = 0.42020928859710693\n",
      "INFO 2024-12-04 16:46:45 pipeline.py:712] Training Step 9740: Policy loss = 1.7293269634246826, value loss = 0.4989013969898224\n",
      "INFO 2024-12-04 16:46:54 pipeline.py:712] Training Step 9760: Policy loss = 1.6707351207733154, value loss = 0.6096203327178955\n",
      "INFO 2024-12-04 16:47:04 pipeline.py:712] Training Step 9780: Policy loss = 1.644669771194458, value loss = 0.47685879468917847\n",
      "INFO 2024-12-04 16:47:13 pipeline.py:712] Training Step 9800: Policy loss = 1.7170552015304565, value loss = 0.4981289505958557\n",
      "INFO 2024-12-04 16:47:23 pipeline.py:712] Training Step 9820: Policy loss = 1.7583410739898682, value loss = 0.5034194588661194\n",
      "INFO 2024-12-04 16:47:32 pipeline.py:712] Training Step 9840: Policy loss = 1.6762926578521729, value loss = 0.5076625943183899\n",
      "INFO 2024-12-04 16:47:42 pipeline.py:712] Training Step 9860: Policy loss = 1.7606520652770996, value loss = 0.46862226724624634\n",
      "INFO 2024-12-04 16:47:52 pipeline.py:712] Training Step 9880: Policy loss = 1.7744758129119873, value loss = 0.4687114357948303\n",
      "INFO 2024-12-04 16:48:01 pipeline.py:712] Training Step 9900: Policy loss = 1.826801061630249, value loss = 0.5004080533981323\n",
      "INFO 2024-12-04 16:48:11 pipeline.py:712] Training Step 9920: Policy loss = 1.6819820404052734, value loss = 0.5062810182571411\n",
      "INFO 2024-12-04 16:48:20 pipeline.py:712] Training Step 9940: Policy loss = 1.7363688945770264, value loss = 0.4679391384124756\n",
      "INFO 2024-12-04 16:48:30 pipeline.py:712] Training Step 9960: Policy loss = 1.72487211227417, value loss = 0.5346658229827881\n",
      "INFO 2024-12-04 16:48:40 pipeline.py:712] Training Step 9980: Policy loss = 1.7791783809661865, value loss = 0.5044560432434082\n",
      "INFO 2024-12-04 16:48:49 pipeline.py:712] Training Step 10000: Policy loss = 1.6225332021713257, value loss = 0.4754241108894348\n",
      "INFO 2024-12-04 16:48:59 pipeline.py:712] Training Step 10020: Policy loss = 1.7401471138000488, value loss = 0.39649397134780884\n",
      "INFO 2024-12-04 16:49:08 pipeline.py:712] Training Step 10040: Policy loss = 1.6448544263839722, value loss = 0.44343897700309753\n",
      "INFO 2024-12-04 16:49:18 pipeline.py:712] Training Step 10060: Policy loss = 1.7671256065368652, value loss = 0.4572482705116272\n",
      "INFO 2024-12-04 16:49:27 pipeline.py:712] Training Step 10080: Policy loss = 1.6623039245605469, value loss = 0.3751382827758789\n",
      "INFO 2024-12-04 16:49:37 pipeline.py:712] Training Step 10100: Policy loss = 1.6419891119003296, value loss = 0.4385358393192291\n",
      "INFO 2024-12-04 16:49:47 pipeline.py:712] Training Step 10120: Policy loss = 1.6836786270141602, value loss = 0.40651533007621765\n",
      "INFO 2024-12-04 16:49:56 pipeline.py:712] Training Step 10140: Policy loss = 1.6376733779907227, value loss = 0.4152781069278717\n",
      "INFO 2024-12-04 16:50:06 pipeline.py:712] Training Step 10160: Policy loss = 1.6776092052459717, value loss = 0.39747166633605957\n",
      "INFO 2024-12-04 16:50:25 pipeline.py:738] training_steps 10164: Validation loss: Poliy loss 1.837533465174378, value_loss 0.4904955864929762\n",
      "INFO 2024-12-04 16:50:33 pipeline.py:712] Training Step 10180: Policy loss = 1.6367486715316772, value loss = 0.35255903005599976\n",
      "INFO 2024-12-04 16:50:43 pipeline.py:712] Training Step 10200: Policy loss = 1.6387310028076172, value loss = 0.365308940410614\n",
      "INFO 2024-12-04 16:50:52 pipeline.py:712] Training Step 10220: Policy loss = 1.6396722793579102, value loss = 0.369973361492157\n",
      "INFO 2024-12-04 16:51:02 pipeline.py:712] Training Step 10240: Policy loss = 1.603760004043579, value loss = 0.3529044985771179\n",
      "INFO 2024-12-04 16:51:11 pipeline.py:712] Training Step 10260: Policy loss = 1.574852705001831, value loss = 0.39571884274482727\n",
      "INFO 2024-12-04 16:51:21 pipeline.py:712] Training Step 10280: Policy loss = 1.6512115001678467, value loss = 0.3474215269088745\n",
      "INFO 2024-12-04 16:51:30 pipeline.py:712] Training Step 10300: Policy loss = 1.5764259099960327, value loss = 0.3923546075820923\n",
      "INFO 2024-12-04 16:51:40 pipeline.py:712] Training Step 10320: Policy loss = 1.6065952777862549, value loss = 0.39451223611831665\n",
      "INFO 2024-12-04 16:51:50 pipeline.py:712] Training Step 10340: Policy loss = 1.6472644805908203, value loss = 0.37778806686401367\n",
      "INFO 2024-12-04 16:51:59 pipeline.py:712] Training Step 10360: Policy loss = 1.5866749286651611, value loss = 0.3747536838054657\n",
      "INFO 2024-12-04 16:52:09 pipeline.py:712] Training Step 10380: Policy loss = 1.5850422382354736, value loss = 0.32726719975471497\n",
      "INFO 2024-12-04 16:52:18 pipeline.py:712] Training Step 10400: Policy loss = 1.599507451057434, value loss = 0.35213717818260193\n",
      "INFO 2024-12-04 16:52:28 pipeline.py:712] Training Step 10420: Policy loss = 1.6381573677062988, value loss = 0.38190844655036926\n",
      "INFO 2024-12-04 16:52:37 pipeline.py:712] Training Step 10440: Policy loss = 1.516709327697754, value loss = 0.3934556841850281\n",
      "INFO 2024-12-04 16:52:47 pipeline.py:712] Training Step 10460: Policy loss = 1.5911635160446167, value loss = 0.377262681722641\n",
      "INFO 2024-12-04 16:52:57 pipeline.py:712] Training Step 10480: Policy loss = 1.6562631130218506, value loss = 0.39329132437705994\n",
      "INFO 2024-12-04 16:53:06 pipeline.py:712] Training Step 10500: Policy loss = 1.5998449325561523, value loss = 0.346709668636322\n",
      "INFO 2024-12-04 16:53:16 pipeline.py:712] Training Step 10520: Policy loss = 1.641813039779663, value loss = 0.37186020612716675\n",
      "INFO 2024-12-04 16:53:25 pipeline.py:712] Training Step 10540: Policy loss = 1.6295017004013062, value loss = 0.34512537717819214\n",
      "INFO 2024-12-04 16:53:35 pipeline.py:712] Training Step 10560: Policy loss = 1.7095874547958374, value loss = 0.37859421968460083\n",
      "INFO 2024-12-04 16:53:45 pipeline.py:712] Training Step 10580: Policy loss = 1.6072864532470703, value loss = 0.3600761592388153\n",
      "INFO 2024-12-04 16:53:54 pipeline.py:712] Training Step 10600: Policy loss = 1.6969910860061646, value loss = 0.35647445917129517\n",
      "INFO 2024-12-04 16:54:04 pipeline.py:712] Training Step 10620: Policy loss = 1.5729953050613403, value loss = 0.3740963339805603\n",
      "INFO 2024-12-04 16:54:13 pipeline.py:712] Training Step 10640: Policy loss = 1.6631969213485718, value loss = 0.34881865978240967\n",
      "INFO 2024-12-04 16:54:35 pipeline.py:738] training_steps 10648: Validation loss: Poliy loss 1.8413570122640641, value_loss 0.4795024265519908\n",
      "INFO 2024-12-04 16:54:41 pipeline.py:712] Training Step 10660: Policy loss = 1.6336036920547485, value loss = 0.3546505570411682\n",
      "INFO 2024-12-04 16:54:50 pipeline.py:712] Training Step 10680: Policy loss = 1.626768946647644, value loss = 0.37499767541885376\n",
      "INFO 2024-12-04 16:55:00 pipeline.py:712] Training Step 10700: Policy loss = 1.6281956434249878, value loss = 0.3426852226257324\n",
      "INFO 2024-12-04 16:55:10 pipeline.py:712] Training Step 10720: Policy loss = 1.6425740718841553, value loss = 0.36310410499572754\n",
      "INFO 2024-12-04 16:55:19 pipeline.py:712] Training Step 10740: Policy loss = 1.6444270610809326, value loss = 0.35674795508384705\n",
      "INFO 2024-12-04 16:55:29 pipeline.py:712] Training Step 10760: Policy loss = 1.5761935710906982, value loss = 0.3740372657775879\n",
      "INFO 2024-12-04 16:55:38 pipeline.py:712] Training Step 10780: Policy loss = 1.6469422578811646, value loss = 0.331900417804718\n",
      "INFO 2024-12-04 16:55:48 pipeline.py:712] Training Step 10800: Policy loss = 1.6634457111358643, value loss = 0.3683561086654663\n",
      "INFO 2024-12-04 16:55:58 pipeline.py:712] Training Step 10820: Policy loss = 1.6536093950271606, value loss = 0.3419815003871918\n",
      "INFO 2024-12-04 16:56:07 pipeline.py:712] Training Step 10840: Policy loss = 1.5640150308609009, value loss = 0.33425772190093994\n",
      "INFO 2024-12-04 16:56:17 pipeline.py:712] Training Step 10860: Policy loss = 1.6318479776382446, value loss = 0.3338983952999115\n",
      "INFO 2024-12-04 16:56:26 pipeline.py:712] Training Step 10880: Policy loss = 1.5929498672485352, value loss = 0.3452850878238678\n",
      "INFO 2024-12-04 16:56:36 pipeline.py:712] Training Step 10900: Policy loss = 1.6192626953125, value loss = 0.36524733901023865\n",
      "INFO 2024-12-04 16:56:45 pipeline.py:712] Training Step 10920: Policy loss = 1.5911633968353271, value loss = 0.362712025642395\n",
      "INFO 2024-12-04 16:56:55 pipeline.py:712] Training Step 10940: Policy loss = 1.5971693992614746, value loss = 0.3107873499393463\n",
      "INFO 2024-12-04 16:57:05 pipeline.py:712] Training Step 10960: Policy loss = 1.645082950592041, value loss = 0.3313409686088562\n",
      "INFO 2024-12-04 16:57:14 pipeline.py:712] Training Step 10980: Policy loss = 1.6157875061035156, value loss = 0.36400941014289856\n",
      "INFO 2024-12-04 16:57:24 pipeline.py:712] Training Step 11000: Policy loss = 1.648048758506775, value loss = 0.3220663070678711\n",
      "INFO 2024-12-04 16:57:33 pipeline.py:712] Training Step 11020: Policy loss = 1.5719112157821655, value loss = 0.34214985370635986\n",
      "INFO 2024-12-04 16:57:43 pipeline.py:712] Training Step 11040: Policy loss = 1.6622971296310425, value loss = 0.34996992349624634\n",
      "INFO 2024-12-04 16:57:53 pipeline.py:712] Training Step 11060: Policy loss = 1.5791451930999756, value loss = 0.3486023247241974\n",
      "INFO 2024-12-04 16:58:02 pipeline.py:712] Training Step 11080: Policy loss = 1.671291470527649, value loss = 0.32300662994384766\n",
      "INFO 2024-12-04 16:58:12 pipeline.py:712] Training Step 11100: Policy loss = 1.5688613653182983, value loss = 0.33233940601348877\n",
      "INFO 2024-12-04 16:58:21 pipeline.py:712] Training Step 11120: Policy loss = 1.689857006072998, value loss = 0.31680798530578613\n",
      "INFO 2024-12-04 16:58:45 pipeline.py:738] training_steps 11132: Validation loss: Poliy loss 1.84114550176214, value_loss 0.470970838040602\n",
      "INFO 2024-12-04 16:58:48 pipeline.py:712] Training Step 11140: Policy loss = 1.6319336891174316, value loss = 0.3367472290992737\n",
      "INFO 2024-12-04 16:58:58 pipeline.py:712] Training Step 11160: Policy loss = 1.6287014484405518, value loss = 0.34073424339294434\n",
      "INFO 2024-12-04 16:59:08 pipeline.py:712] Training Step 11180: Policy loss = 1.618718147277832, value loss = 0.34586232900619507\n",
      "INFO 2024-12-04 16:59:17 pipeline.py:712] Training Step 11200: Policy loss = 1.6589412689208984, value loss = 0.3356214165687561\n",
      "INFO 2024-12-04 16:59:27 pipeline.py:712] Training Step 11220: Policy loss = 1.590404987335205, value loss = 0.34814855456352234\n",
      "INFO 2024-12-04 16:59:36 pipeline.py:712] Training Step 11240: Policy loss = 1.658685564994812, value loss = 0.29474252462387085\n",
      "INFO 2024-12-04 16:59:46 pipeline.py:712] Training Step 11260: Policy loss = 1.6402368545532227, value loss = 0.34657716751098633\n",
      "INFO 2024-12-04 16:59:55 pipeline.py:712] Training Step 11280: Policy loss = 1.5320699214935303, value loss = 0.3368663191795349\n",
      "INFO 2024-12-04 17:00:05 pipeline.py:712] Training Step 11300: Policy loss = 1.6224051713943481, value loss = 0.36175864934921265\n",
      "INFO 2024-12-04 17:00:15 pipeline.py:712] Training Step 11320: Policy loss = 1.6135036945343018, value loss = 0.33243611454963684\n",
      "INFO 2024-12-04 17:00:24 pipeline.py:712] Training Step 11340: Policy loss = 1.5886249542236328, value loss = 0.3397369980812073\n",
      "INFO 2024-12-04 17:00:34 pipeline.py:712] Training Step 11360: Policy loss = 1.5655455589294434, value loss = 0.34918272495269775\n",
      "INFO 2024-12-04 17:00:43 pipeline.py:712] Training Step 11380: Policy loss = 1.5071754455566406, value loss = 0.34112441539764404\n",
      "INFO 2024-12-04 17:00:53 pipeline.py:712] Training Step 11400: Policy loss = 1.6543548107147217, value loss = 0.3425048589706421\n",
      "INFO 2024-12-04 17:01:03 pipeline.py:712] Training Step 11420: Policy loss = 1.5734986066818237, value loss = 0.34519290924072266\n",
      "INFO 2024-12-04 17:01:12 pipeline.py:712] Training Step 11440: Policy loss = 1.5023348331451416, value loss = 0.36373016238212585\n",
      "INFO 2024-12-04 17:01:22 pipeline.py:712] Training Step 11460: Policy loss = 1.6161954402923584, value loss = 0.34319639205932617\n",
      "INFO 2024-12-04 17:01:31 pipeline.py:712] Training Step 11480: Policy loss = 1.6153113842010498, value loss = 0.3318439722061157\n",
      "INFO 2024-12-04 17:01:41 pipeline.py:712] Training Step 11500: Policy loss = 1.7001769542694092, value loss = 0.32303687930107117\n",
      "INFO 2024-12-04 17:01:50 pipeline.py:712] Training Step 11520: Policy loss = 1.5338783264160156, value loss = 0.3356029987335205\n",
      "INFO 2024-12-04 17:02:00 pipeline.py:712] Training Step 11540: Policy loss = 1.7006628513336182, value loss = 0.33454298973083496\n",
      "INFO 2024-12-04 17:02:10 pipeline.py:712] Training Step 11560: Policy loss = 1.5908749103546143, value loss = 0.3418007493019104\n",
      "INFO 2024-12-04 17:02:19 pipeline.py:712] Training Step 11580: Policy loss = 1.5859313011169434, value loss = 0.33862805366516113\n",
      "INFO 2024-12-04 17:02:29 pipeline.py:712] Training Step 11600: Policy loss = 1.6075160503387451, value loss = 0.32309690117836\n",
      "INFO 2024-12-04 17:02:54 pipeline.py:738] training_steps 11616: Validation loss: Poliy loss 1.8423432815270346, value_loss 0.46746446436545885\n",
      "INFO 2024-12-04 17:02:56 pipeline.py:712] Training Step 11620: Policy loss = 1.6079127788543701, value loss = 0.3204272985458374\n",
      "INFO 2024-12-04 17:03:06 pipeline.py:712] Training Step 11640: Policy loss = 1.5369027853012085, value loss = 0.3175830543041229\n",
      "INFO 2024-12-04 17:03:16 pipeline.py:712] Training Step 11660: Policy loss = 1.5710535049438477, value loss = 0.3410550057888031\n",
      "INFO 2024-12-04 17:03:25 pipeline.py:712] Training Step 11680: Policy loss = 1.570063591003418, value loss = 0.3440936207771301\n",
      "INFO 2024-12-04 17:03:35 pipeline.py:712] Training Step 11700: Policy loss = 1.6490508317947388, value loss = 0.32113710045814514\n",
      "INFO 2024-12-04 17:03:44 pipeline.py:712] Training Step 11720: Policy loss = 1.5841341018676758, value loss = 0.32076936960220337\n",
      "INFO 2024-12-04 17:03:54 pipeline.py:712] Training Step 11740: Policy loss = 1.5269412994384766, value loss = 0.3253970742225647\n",
      "INFO 2024-12-04 17:04:03 pipeline.py:712] Training Step 11760: Policy loss = 1.571942925453186, value loss = 0.36259913444519043\n",
      "INFO 2024-12-04 17:04:13 pipeline.py:712] Training Step 11780: Policy loss = 1.6365846395492554, value loss = 0.3327927589416504\n",
      "INFO 2024-12-04 17:04:23 pipeline.py:712] Training Step 11800: Policy loss = 1.6202664375305176, value loss = 0.32645183801651\n",
      "INFO 2024-12-04 17:04:32 pipeline.py:712] Training Step 11820: Policy loss = 1.7024610042572021, value loss = 0.37193459272384644\n",
      "INFO 2024-12-04 17:04:42 pipeline.py:712] Training Step 11840: Policy loss = 1.6446146965026855, value loss = 0.33201873302459717\n",
      "INFO 2024-12-04 17:04:51 pipeline.py:712] Training Step 11860: Policy loss = 1.548262119293213, value loss = 0.30745989084243774\n",
      "INFO 2024-12-04 17:05:01 pipeline.py:712] Training Step 11880: Policy loss = 1.552992582321167, value loss = 0.37973934412002563\n",
      "INFO 2024-12-04 17:05:11 pipeline.py:712] Training Step 11900: Policy loss = 1.624160885810852, value loss = 0.34150099754333496\n",
      "INFO 2024-12-04 17:05:20 pipeline.py:712] Training Step 11920: Policy loss = 1.5771291255950928, value loss = 0.3233588933944702\n",
      "INFO 2024-12-04 17:05:30 pipeline.py:712] Training Step 11940: Policy loss = 1.5698354244232178, value loss = 0.36330971121788025\n",
      "INFO 2024-12-04 17:05:39 pipeline.py:712] Training Step 11960: Policy loss = 1.5702126026153564, value loss = 0.3109775483608246\n",
      "INFO 2024-12-04 17:05:49 pipeline.py:712] Training Step 11980: Policy loss = 1.5964865684509277, value loss = 0.30664682388305664\n",
      "INFO 2024-12-04 17:05:58 pipeline.py:712] Training Step 12000: Policy loss = 1.6000087261199951, value loss = 0.29749348759651184\n",
      "INFO 2024-12-04 17:06:08 pipeline.py:712] Training Step 12020: Policy loss = 1.7341736555099487, value loss = 0.3539034128189087\n",
      "INFO 2024-12-04 17:06:18 pipeline.py:712] Training Step 12040: Policy loss = 1.5779693126678467, value loss = 0.3225499987602234\n",
      "INFO 2024-12-04 17:06:27 pipeline.py:712] Training Step 12060: Policy loss = 1.6487061977386475, value loss = 0.33904463052749634\n",
      "INFO 2024-12-04 17:06:37 pipeline.py:712] Training Step 12080: Policy loss = 1.6017746925354004, value loss = 0.36299532651901245\n",
      "INFO 2024-12-04 17:06:46 pipeline.py:712] Training Step 12100: Policy loss = 1.610351800918579, value loss = 0.3309939503669739\n",
      "INFO 2024-12-04 17:07:04 pipeline.py:738] training_steps 12100: Validation loss: Poliy loss 1.841592739840023, value_loss 0.46839054881549275\n",
      "INFO 2024-12-04 17:07:14 pipeline.py:712] Training Step 12120: Policy loss = 1.6343369483947754, value loss = 0.3073769211769104\n",
      "INFO 2024-12-04 17:07:24 pipeline.py:712] Training Step 12140: Policy loss = 1.5942103862762451, value loss = 0.3545529246330261\n",
      "INFO 2024-12-04 17:07:33 pipeline.py:712] Training Step 12160: Policy loss = 1.6532602310180664, value loss = 0.32204270362854004\n",
      "INFO 2024-12-04 17:07:43 pipeline.py:712] Training Step 12180: Policy loss = 1.6649925708770752, value loss = 0.3174845576286316\n",
      "INFO 2024-12-04 17:07:52 pipeline.py:712] Training Step 12200: Policy loss = 1.5862008333206177, value loss = 0.28397154808044434\n",
      "INFO 2024-12-04 17:08:02 pipeline.py:712] Training Step 12220: Policy loss = 1.599679946899414, value loss = 0.3203284740447998\n",
      "INFO 2024-12-04 17:08:11 pipeline.py:712] Training Step 12240: Policy loss = 1.6162078380584717, value loss = 0.31400585174560547\n",
      "INFO 2024-12-04 17:08:21 pipeline.py:712] Training Step 12260: Policy loss = 1.6217763423919678, value loss = 0.27926212549209595\n",
      "INFO 2024-12-04 17:08:30 pipeline.py:712] Training Step 12280: Policy loss = 1.5556726455688477, value loss = 0.3319983184337616\n",
      "INFO 2024-12-04 17:08:40 pipeline.py:712] Training Step 12300: Policy loss = 1.6236751079559326, value loss = 0.31586459279060364\n",
      "INFO 2024-12-04 17:08:50 pipeline.py:712] Training Step 12320: Policy loss = 1.5996177196502686, value loss = 0.32261669635772705\n",
      "INFO 2024-12-04 17:08:59 pipeline.py:712] Training Step 12340: Policy loss = 1.569744348526001, value loss = 0.32289591431617737\n",
      "INFO 2024-12-04 17:09:09 pipeline.py:712] Training Step 12360: Policy loss = 1.6293655633926392, value loss = 0.3150177597999573\n",
      "INFO 2024-12-04 17:09:18 pipeline.py:712] Training Step 12380: Policy loss = 1.6164517402648926, value loss = 0.334234356880188\n",
      "INFO 2024-12-04 17:09:28 pipeline.py:712] Training Step 12400: Policy loss = 1.6290220022201538, value loss = 0.34045523405075073\n",
      "INFO 2024-12-04 17:09:38 pipeline.py:712] Training Step 12420: Policy loss = 1.617685079574585, value loss = 0.29792967438697815\n",
      "INFO 2024-12-04 17:09:47 pipeline.py:712] Training Step 12440: Policy loss = 1.6015238761901855, value loss = 0.34724652767181396\n",
      "INFO 2024-12-04 17:09:57 pipeline.py:712] Training Step 12460: Policy loss = 1.6130249500274658, value loss = 0.3418729901313782\n",
      "INFO 2024-12-04 17:10:06 pipeline.py:712] Training Step 12480: Policy loss = 1.5621752738952637, value loss = 0.3363681435585022\n",
      "INFO 2024-12-04 17:10:16 pipeline.py:712] Training Step 12500: Policy loss = 1.5818052291870117, value loss = 0.3447512090206146\n",
      "INFO 2024-12-04 17:10:26 pipeline.py:712] Training Step 12520: Policy loss = 1.5614354610443115, value loss = 0.3274972438812256\n",
      "INFO 2024-12-04 17:10:35 pipeline.py:712] Training Step 12540: Policy loss = 1.6332471370697021, value loss = 0.33340930938720703\n",
      "INFO 2024-12-04 17:10:45 pipeline.py:712] Training Step 12560: Policy loss = 1.5389125347137451, value loss = 0.2987896800041199\n",
      "INFO 2024-12-04 17:10:54 pipeline.py:712] Training Step 12580: Policy loss = 1.5393104553222656, value loss = 0.327764093875885\n",
      "INFO 2024-12-04 17:11:14 pipeline.py:738] training_steps 12584: Validation loss: Poliy loss 1.844049768369706, value_loss 0.4624856070416873\n",
      "INFO 2024-12-04 17:11:22 pipeline.py:712] Training Step 12600: Policy loss = 1.5789697170257568, value loss = 0.30824941396713257\n",
      "INFO 2024-12-04 17:11:32 pipeline.py:712] Training Step 12620: Policy loss = 1.5822007656097412, value loss = 0.30604854226112366\n",
      "INFO 2024-12-04 17:11:41 pipeline.py:712] Training Step 12640: Policy loss = 1.5927278995513916, value loss = 0.31051042675971985\n",
      "INFO 2024-12-04 17:11:51 pipeline.py:712] Training Step 12660: Policy loss = 1.6076843738555908, value loss = 0.29553723335266113\n",
      "INFO 2024-12-04 17:12:00 pipeline.py:712] Training Step 12680: Policy loss = 1.594207525253296, value loss = 0.3093865215778351\n",
      "INFO 2024-12-04 17:12:10 pipeline.py:712] Training Step 12700: Policy loss = 1.514733076095581, value loss = 0.3440956175327301\n",
      "INFO 2024-12-04 17:12:20 pipeline.py:712] Training Step 12720: Policy loss = 1.6509568691253662, value loss = 0.30464649200439453\n",
      "INFO 2024-12-04 17:12:29 pipeline.py:712] Training Step 12740: Policy loss = 1.6226340532302856, value loss = 0.24963922798633575\n",
      "INFO 2024-12-04 17:12:39 pipeline.py:712] Training Step 12760: Policy loss = 1.5304731130599976, value loss = 0.3251528739929199\n",
      "INFO 2024-12-04 17:12:49 pipeline.py:712] Training Step 12780: Policy loss = 1.6560719013214111, value loss = 0.3291652202606201\n",
      "INFO 2024-12-04 17:12:58 pipeline.py:712] Training Step 12800: Policy loss = 1.5939288139343262, value loss = 0.3347094655036926\n",
      "INFO 2024-12-04 17:13:08 pipeline.py:712] Training Step 12820: Policy loss = 1.5785880088806152, value loss = 0.33263248205184937\n",
      "INFO 2024-12-04 17:13:18 pipeline.py:712] Training Step 12840: Policy loss = 1.5713495016098022, value loss = 0.29267048835754395\n",
      "INFO 2024-12-04 17:13:27 pipeline.py:712] Training Step 12860: Policy loss = 1.6125164031982422, value loss = 0.3262377679347992\n",
      "INFO 2024-12-04 17:13:37 pipeline.py:712] Training Step 12880: Policy loss = 1.6109697818756104, value loss = 0.29690009355545044\n",
      "INFO 2024-12-04 17:13:47 pipeline.py:712] Training Step 12900: Policy loss = 1.5923421382904053, value loss = 0.3134538233280182\n",
      "INFO 2024-12-04 17:13:56 pipeline.py:712] Training Step 12920: Policy loss = 1.5893259048461914, value loss = 0.307290643453598\n",
      "INFO 2024-12-04 17:14:06 pipeline.py:712] Training Step 12940: Policy loss = 1.6172761917114258, value loss = 0.31106358766555786\n",
      "INFO 2024-12-04 17:14:16 pipeline.py:712] Training Step 12960: Policy loss = 1.6650563478469849, value loss = 0.34167805314064026\n",
      "INFO 2024-12-04 17:14:26 pipeline.py:712] Training Step 12980: Policy loss = 1.5706253051757812, value loss = 0.3162838816642761\n",
      "INFO 2024-12-04 17:14:35 pipeline.py:712] Training Step 13000: Policy loss = 1.5415213108062744, value loss = 0.3114953935146332\n",
      "INFO 2024-12-04 17:14:45 pipeline.py:712] Training Step 13020: Policy loss = 1.60771644115448, value loss = 0.32293951511383057\n",
      "INFO 2024-12-04 17:14:55 pipeline.py:712] Training Step 13040: Policy loss = 1.6293869018554688, value loss = 0.32393673062324524\n",
      "INFO 2024-12-04 17:15:04 pipeline.py:712] Training Step 13060: Policy loss = 1.6358314752578735, value loss = 0.3204382061958313\n",
      "INFO 2024-12-04 17:15:26 pipeline.py:738] training_steps 13068: Validation loss: Poliy loss 1.8428908381305757, value_loss 0.4601804934075621\n",
      "INFO 2024-12-04 17:15:32 pipeline.py:712] Training Step 13080: Policy loss = 1.5642774105072021, value loss = 0.3043486475944519\n",
      "INFO 2024-12-04 17:15:42 pipeline.py:712] Training Step 13100: Policy loss = 1.562232255935669, value loss = 0.277157723903656\n",
      "INFO 2024-12-04 17:15:51 pipeline.py:712] Training Step 13120: Policy loss = 1.5429155826568604, value loss = 0.33277612924575806\n",
      "INFO 2024-12-04 17:16:01 pipeline.py:712] Training Step 13140: Policy loss = 1.6041808128356934, value loss = 0.3062760829925537\n",
      "INFO 2024-12-04 17:16:11 pipeline.py:712] Training Step 13160: Policy loss = 1.6203422546386719, value loss = 0.293464720249176\n",
      "INFO 2024-12-04 17:16:20 pipeline.py:712] Training Step 13180: Policy loss = 1.6872189044952393, value loss = 0.30212104320526123\n",
      "INFO 2024-12-04 17:16:30 pipeline.py:712] Training Step 13200: Policy loss = 1.6059515476226807, value loss = 0.29309213161468506\n",
      "INFO 2024-12-04 17:16:40 pipeline.py:712] Training Step 13220: Policy loss = 1.5751761198043823, value loss = 0.30037111043930054\n",
      "INFO 2024-12-04 17:16:50 pipeline.py:712] Training Step 13240: Policy loss = 1.5919880867004395, value loss = 0.3112972378730774\n",
      "INFO 2024-12-04 17:16:59 pipeline.py:712] Training Step 13260: Policy loss = 1.5695865154266357, value loss = 0.3258060812950134\n",
      "INFO 2024-12-04 17:17:09 pipeline.py:712] Training Step 13280: Policy loss = 1.6369333267211914, value loss = 0.3048703074455261\n",
      "INFO 2024-12-04 17:17:19 pipeline.py:712] Training Step 13300: Policy loss = 1.646662950515747, value loss = 0.32700836658477783\n",
      "INFO 2024-12-04 17:17:29 pipeline.py:712] Training Step 13320: Policy loss = 1.5611916780471802, value loss = 0.3102912902832031\n",
      "INFO 2024-12-04 17:17:39 pipeline.py:712] Training Step 13340: Policy loss = 1.5807929039001465, value loss = 0.29892483353614807\n",
      "INFO 2024-12-04 17:17:48 pipeline.py:712] Training Step 13360: Policy loss = 1.5575168132781982, value loss = 0.30621039867401123\n",
      "INFO 2024-12-04 17:17:58 pipeline.py:712] Training Step 13380: Policy loss = 1.5958001613616943, value loss = 0.29380640387535095\n",
      "INFO 2024-12-04 17:18:08 pipeline.py:712] Training Step 13400: Policy loss = 1.5590711832046509, value loss = 0.3135390877723694\n",
      "INFO 2024-12-04 17:18:17 pipeline.py:712] Training Step 13420: Policy loss = 1.6153931617736816, value loss = 0.3267863094806671\n",
      "INFO 2024-12-04 17:18:27 pipeline.py:712] Training Step 13440: Policy loss = 1.5479602813720703, value loss = 0.2746586203575134\n",
      "INFO 2024-12-04 17:18:37 pipeline.py:712] Training Step 13460: Policy loss = 1.58046293258667, value loss = 0.30856776237487793\n",
      "INFO 2024-12-04 17:18:46 pipeline.py:712] Training Step 13480: Policy loss = 1.588330626487732, value loss = 0.31193193793296814\n",
      "INFO 2024-12-04 17:18:56 pipeline.py:712] Training Step 13500: Policy loss = 1.557942509651184, value loss = 0.3134923577308655\n",
      "INFO 2024-12-04 17:19:06 pipeline.py:712] Training Step 13520: Policy loss = 1.6255778074264526, value loss = 0.3104274272918701\n",
      "INFO 2024-12-04 17:19:15 pipeline.py:712] Training Step 13540: Policy loss = 1.5893129110336304, value loss = 0.2875373363494873\n",
      "INFO 2024-12-04 17:19:39 pipeline.py:738] training_steps 13552: Validation loss: Poliy loss 1.8452880919956771, value_loss 0.45785130413829306\n",
      "INFO 2024-12-04 17:19:43 pipeline.py:712] Training Step 13560: Policy loss = 1.619722843170166, value loss = 0.29101064801216125\n",
      "INFO 2024-12-04 17:19:53 pipeline.py:712] Training Step 13580: Policy loss = 1.5604509115219116, value loss = 0.3076882064342499\n",
      "INFO 2024-12-04 17:20:02 pipeline.py:712] Training Step 13600: Policy loss = 1.5781868696212769, value loss = 0.3109577000141144\n",
      "INFO 2024-12-04 17:20:12 pipeline.py:712] Training Step 13620: Policy loss = 1.664417028427124, value loss = 0.3004148304462433\n",
      "INFO 2024-12-04 17:20:21 pipeline.py:712] Training Step 13640: Policy loss = 1.5216734409332275, value loss = 0.3277491629123688\n",
      "INFO 2024-12-04 17:20:31 pipeline.py:712] Training Step 13660: Policy loss = 1.6167198419570923, value loss = 0.31566089391708374\n",
      "INFO 2024-12-04 17:20:41 pipeline.py:712] Training Step 13680: Policy loss = 1.5449408292770386, value loss = 0.3037315607070923\n",
      "INFO 2024-12-04 17:20:50 pipeline.py:712] Training Step 13700: Policy loss = 1.6873348951339722, value loss = 0.320456862449646\n",
      "INFO 2024-12-04 17:21:00 pipeline.py:712] Training Step 13720: Policy loss = 1.5679495334625244, value loss = 0.30584174394607544\n",
      "INFO 2024-12-04 17:21:10 pipeline.py:712] Training Step 13740: Policy loss = 1.5592390298843384, value loss = 0.309858500957489\n",
      "INFO 2024-12-04 17:21:19 pipeline.py:712] Training Step 13760: Policy loss = 1.5595123767852783, value loss = 0.27687788009643555\n",
      "INFO 2024-12-04 17:21:29 pipeline.py:712] Training Step 13780: Policy loss = 1.5158050060272217, value loss = 0.3281339704990387\n",
      "INFO 2024-12-04 17:21:39 pipeline.py:712] Training Step 13800: Policy loss = 1.5399659872055054, value loss = 0.32239431142807007\n",
      "INFO 2024-12-04 17:21:48 pipeline.py:712] Training Step 13820: Policy loss = 1.6044049263000488, value loss = 0.3009186089038849\n",
      "INFO 2024-12-04 17:21:58 pipeline.py:712] Training Step 13840: Policy loss = 1.5869083404541016, value loss = 0.30394446849823\n",
      "INFO 2024-12-04 17:22:08 pipeline.py:712] Training Step 13860: Policy loss = 1.6010820865631104, value loss = 0.2973364591598511\n",
      "INFO 2024-12-04 17:22:17 pipeline.py:712] Training Step 13880: Policy loss = 1.627096176147461, value loss = 0.30304932594299316\n",
      "INFO 2024-12-04 17:22:27 pipeline.py:712] Training Step 13900: Policy loss = 1.566470980644226, value loss = 0.2913442850112915\n",
      "INFO 2024-12-04 17:22:36 pipeline.py:712] Training Step 13920: Policy loss = 1.5974557399749756, value loss = 0.31044378876686096\n",
      "INFO 2024-12-04 17:22:46 pipeline.py:712] Training Step 13940: Policy loss = 1.5077221393585205, value loss = 0.3254351019859314\n",
      "INFO 2024-12-04 17:22:56 pipeline.py:712] Training Step 13960: Policy loss = 1.6244831085205078, value loss = 0.2921295166015625\n",
      "INFO 2024-12-04 17:23:05 pipeline.py:712] Training Step 13980: Policy loss = 1.6016649007797241, value loss = 0.2997679114341736\n",
      "INFO 2024-12-04 17:23:15 pipeline.py:712] Training Step 14000: Policy loss = 1.5856096744537354, value loss = 0.2965174913406372\n",
      "INFO 2024-12-04 17:23:25 pipeline.py:712] Training Step 14020: Policy loss = 1.7072839736938477, value loss = 0.31929951906204224\n",
      "INFO 2024-12-04 17:23:50 pipeline.py:738] training_steps 14036: Validation loss: Poliy loss 1.8438212207106293, value_loss 0.45577493261118407\n",
      "INFO 2024-12-04 17:23:52 pipeline.py:712] Training Step 14040: Policy loss = 1.5808368921279907, value loss = 0.2800194025039673\n",
      "INFO 2024-12-04 17:24:02 pipeline.py:712] Training Step 14060: Policy loss = 1.526702642440796, value loss = 0.30155202746391296\n",
      "INFO 2024-12-04 17:24:12 pipeline.py:712] Training Step 14080: Policy loss = 1.515655517578125, value loss = 0.30908602476119995\n",
      "INFO 2024-12-04 17:24:21 pipeline.py:712] Training Step 14100: Policy loss = 1.5898888111114502, value loss = 0.2989931106567383\n",
      "INFO 2024-12-04 17:24:31 pipeline.py:712] Training Step 14120: Policy loss = 1.6143124103546143, value loss = 0.2732640206813812\n",
      "INFO 2024-12-04 17:24:40 pipeline.py:712] Training Step 14140: Policy loss = 1.5644339323043823, value loss = 0.29530203342437744\n",
      "INFO 2024-12-04 17:24:50 pipeline.py:712] Training Step 14160: Policy loss = 1.4985707998275757, value loss = 0.31425291299819946\n",
      "INFO 2024-12-04 17:25:00 pipeline.py:712] Training Step 14180: Policy loss = 1.5401254892349243, value loss = 0.3202279210090637\n",
      "INFO 2024-12-04 17:25:10 pipeline.py:712] Training Step 14200: Policy loss = 1.5418171882629395, value loss = 0.27698349952697754\n",
      "INFO 2024-12-04 17:25:19 pipeline.py:712] Training Step 14220: Policy loss = 1.5771450996398926, value loss = 0.2771626114845276\n",
      "INFO 2024-12-04 17:25:29 pipeline.py:712] Training Step 14240: Policy loss = 1.6164621114730835, value loss = 0.2782035171985626\n",
      "INFO 2024-12-04 17:25:39 pipeline.py:712] Training Step 14260: Policy loss = 1.5838302373886108, value loss = 0.26895108819007874\n",
      "INFO 2024-12-04 17:25:48 pipeline.py:712] Training Step 14280: Policy loss = 1.5817419290542603, value loss = 0.33103257417678833\n",
      "INFO 2024-12-04 17:25:58 pipeline.py:712] Training Step 14300: Policy loss = 1.687239408493042, value loss = 0.283048540353775\n",
      "INFO 2024-12-04 17:26:08 pipeline.py:712] Training Step 14320: Policy loss = 1.4902292490005493, value loss = 0.28665226697921753\n",
      "INFO 2024-12-04 17:26:17 pipeline.py:712] Training Step 14340: Policy loss = 1.6372244358062744, value loss = 0.30032408237457275\n",
      "INFO 2024-12-04 17:26:27 pipeline.py:712] Training Step 14360: Policy loss = 1.5731182098388672, value loss = 0.3193398714065552\n",
      "INFO 2024-12-04 17:26:36 pipeline.py:712] Training Step 14380: Policy loss = 1.6555711030960083, value loss = 0.2916020154953003\n",
      "INFO 2024-12-04 17:26:46 pipeline.py:712] Training Step 14400: Policy loss = 1.574089765548706, value loss = 0.2748503088951111\n",
      "INFO 2024-12-04 17:26:56 pipeline.py:712] Training Step 14420: Policy loss = 1.663681983947754, value loss = 0.3032044768333435\n",
      "INFO 2024-12-04 17:27:05 pipeline.py:712] Training Step 14440: Policy loss = 1.611387014389038, value loss = 0.3329780697822571\n",
      "INFO 2024-12-04 17:27:15 pipeline.py:712] Training Step 14460: Policy loss = 1.6118638515472412, value loss = 0.2829773426055908\n",
      "INFO 2024-12-04 17:27:24 pipeline.py:712] Training Step 14480: Policy loss = 1.674706220626831, value loss = 0.3263291120529175\n",
      "INFO 2024-12-04 17:27:34 pipeline.py:712] Training Step 14500: Policy loss = 1.6184916496276855, value loss = 0.2767264246940613\n",
      "INFO 2024-12-04 17:27:44 pipeline.py:712] Training Step 14520: Policy loss = 1.6770410537719727, value loss = 0.26057344675064087\n",
      "INFO 2024-12-04 17:28:02 pipeline.py:738] training_steps 14520: Validation loss: Poliy loss 1.8445813597225753, value_loss 0.4543356118632145\n",
      "INFO 2024-12-04 17:28:12 pipeline.py:712] Training Step 14540: Policy loss = 1.5604803562164307, value loss = 0.32439279556274414\n",
      "INFO 2024-12-04 17:28:22 pipeline.py:712] Training Step 14560: Policy loss = 1.633662462234497, value loss = 0.283054918050766\n",
      "INFO 2024-12-04 17:28:31 pipeline.py:712] Training Step 14580: Policy loss = 1.6412345170974731, value loss = 0.2963542342185974\n",
      "INFO 2024-12-04 17:28:41 pipeline.py:712] Training Step 14600: Policy loss = 1.6488261222839355, value loss = 0.30000951886177063\n",
      "INFO 2024-12-04 17:28:51 pipeline.py:712] Training Step 14620: Policy loss = 1.5727097988128662, value loss = 0.2747097909450531\n",
      "INFO 2024-12-04 17:29:00 pipeline.py:712] Training Step 14640: Policy loss = 1.596922755241394, value loss = 0.307378888130188\n",
      "INFO 2024-12-04 17:29:10 pipeline.py:712] Training Step 14660: Policy loss = 1.7209186553955078, value loss = 0.3023253083229065\n",
      "INFO 2024-12-04 17:29:20 pipeline.py:712] Training Step 14680: Policy loss = 1.6165190935134888, value loss = 0.26694685220718384\n",
      "INFO 2024-12-04 17:29:29 pipeline.py:712] Training Step 14700: Policy loss = 1.5285017490386963, value loss = 0.25291314721107483\n",
      "INFO 2024-12-04 17:29:39 pipeline.py:712] Training Step 14720: Policy loss = 1.616417646408081, value loss = 0.28863656520843506\n",
      "INFO 2024-12-04 17:29:49 pipeline.py:712] Training Step 14740: Policy loss = 1.5527031421661377, value loss = 0.2684946358203888\n",
      "INFO 2024-12-04 17:29:58 pipeline.py:712] Training Step 14760: Policy loss = 1.512485146522522, value loss = 0.2776961922645569\n",
      "INFO 2024-12-04 17:30:08 pipeline.py:712] Training Step 14780: Policy loss = 1.667374610900879, value loss = 0.2686966061592102\n",
      "INFO 2024-12-04 17:30:18 pipeline.py:712] Training Step 14800: Policy loss = 1.649196743965149, value loss = 0.2760172486305237\n",
      "INFO 2024-12-04 17:30:28 pipeline.py:712] Training Step 14820: Policy loss = 1.5062872171401978, value loss = 0.27576714754104614\n",
      "INFO 2024-12-04 17:30:37 pipeline.py:712] Training Step 14840: Policy loss = 1.592285394668579, value loss = 0.3400161862373352\n",
      "INFO 2024-12-04 17:30:47 pipeline.py:712] Training Step 14860: Policy loss = 1.617114543914795, value loss = 0.2896386981010437\n",
      "INFO 2024-12-04 17:30:57 pipeline.py:712] Training Step 14880: Policy loss = 1.637247920036316, value loss = 0.2886693775653839\n",
      "INFO 2024-12-04 17:31:06 pipeline.py:712] Training Step 14900: Policy loss = 1.5960664749145508, value loss = 0.3141520023345947\n",
      "INFO 2024-12-04 17:31:16 pipeline.py:712] Training Step 14920: Policy loss = 1.6470013856887817, value loss = 0.3161201477050781\n",
      "INFO 2024-12-04 17:31:26 pipeline.py:712] Training Step 14940: Policy loss = 1.5891540050506592, value loss = 0.28791698813438416\n",
      "INFO 2024-12-04 17:31:35 pipeline.py:712] Training Step 14960: Policy loss = 1.5615990161895752, value loss = 0.30752021074295044\n",
      "INFO 2024-12-04 17:31:45 pipeline.py:712] Training Step 14980: Policy loss = 1.5970085859298706, value loss = 0.2983114421367645\n",
      "INFO 2024-12-04 17:31:55 pipeline.py:712] Training Step 15000: Policy loss = 1.6258783340454102, value loss = 0.2859874367713928\n",
      "INFO 2024-12-04 17:32:15 pipeline.py:738] training_steps 15004: Validation loss: Poliy loss 1.8459900725083274, value_loss 0.454782423914456\n",
      "INFO 2024-12-04 17:32:23 pipeline.py:712] Training Step 15020: Policy loss = 1.4971120357513428, value loss = 0.2703881859779358\n",
      "INFO 2024-12-04 17:32:32 pipeline.py:712] Training Step 15040: Policy loss = 1.498650074005127, value loss = 0.3101608455181122\n",
      "INFO 2024-12-04 17:32:42 pipeline.py:712] Training Step 15060: Policy loss = 1.5372931957244873, value loss = 0.27783745527267456\n",
      "INFO 2024-12-04 17:32:51 pipeline.py:712] Training Step 15080: Policy loss = 1.6072328090667725, value loss = 0.3015007972717285\n",
      "INFO 2024-12-04 17:33:01 pipeline.py:712] Training Step 15100: Policy loss = 1.6119359731674194, value loss = 0.2837251126766205\n",
      "INFO 2024-12-04 17:33:11 pipeline.py:712] Training Step 15120: Policy loss = 1.5686135292053223, value loss = 0.3120696246623993\n",
      "INFO 2024-12-04 17:33:21 pipeline.py:712] Training Step 15140: Policy loss = 1.588960886001587, value loss = 0.31960898637771606\n",
      "INFO 2024-12-04 17:33:30 pipeline.py:712] Training Step 15160: Policy loss = 1.599432349205017, value loss = 0.25662022829055786\n",
      "INFO 2024-12-04 17:33:40 pipeline.py:712] Training Step 15180: Policy loss = 1.535759687423706, value loss = 0.2703564167022705\n",
      "INFO 2024-12-04 17:33:50 pipeline.py:712] Training Step 15200: Policy loss = 1.5574946403503418, value loss = 0.29566246271133423\n",
      "INFO 2024-12-04 17:33:59 pipeline.py:712] Training Step 15220: Policy loss = 1.5971908569335938, value loss = 0.2829132676124573\n",
      "INFO 2024-12-04 17:34:09 pipeline.py:712] Training Step 15240: Policy loss = 1.5697003602981567, value loss = 0.2782500386238098\n",
      "INFO 2024-12-04 17:34:19 pipeline.py:712] Training Step 15260: Policy loss = 1.622989535331726, value loss = 0.32029640674591064\n",
      "INFO 2024-12-04 17:34:29 pipeline.py:712] Training Step 15280: Policy loss = 1.4869588613510132, value loss = 0.31033211946487427\n",
      "INFO 2024-12-04 17:34:38 pipeline.py:712] Training Step 15300: Policy loss = 1.6372519731521606, value loss = 0.3133240342140198\n",
      "INFO 2024-12-04 17:34:48 pipeline.py:712] Training Step 15320: Policy loss = 1.559877872467041, value loss = 0.2888793349266052\n",
      "INFO 2024-12-04 17:34:57 pipeline.py:712] Training Step 15340: Policy loss = 1.6133701801300049, value loss = 0.31371864676475525\n",
      "INFO 2024-12-04 17:35:07 pipeline.py:712] Training Step 15360: Policy loss = 1.552929401397705, value loss = 0.2813052535057068\n",
      "INFO 2024-12-04 17:35:17 pipeline.py:712] Training Step 15380: Policy loss = 1.6062195301055908, value loss = 0.291297972202301\n",
      "INFO 2024-12-04 17:35:27 pipeline.py:712] Training Step 15400: Policy loss = 1.5757129192352295, value loss = 0.2373799979686737\n",
      "INFO 2024-12-04 17:35:36 pipeline.py:712] Training Step 15420: Policy loss = 1.6239007711410522, value loss = 0.31507813930511475\n",
      "INFO 2024-12-04 17:35:46 pipeline.py:712] Training Step 15440: Policy loss = 1.5879640579223633, value loss = 0.29480329155921936\n",
      "INFO 2024-12-04 17:35:55 pipeline.py:712] Training Step 15460: Policy loss = 1.6141703128814697, value loss = 0.30980896949768066\n",
      "INFO 2024-12-04 17:36:05 pipeline.py:712] Training Step 15480: Policy loss = 1.5437170267105103, value loss = 0.30428504943847656\n",
      "INFO 2024-12-04 17:36:27 pipeline.py:738] training_steps 15488: Validation loss: Poliy loss 1.8452326303622761, value_loss 0.4534431080349156\n",
      "INFO 2024-12-04 17:36:33 pipeline.py:712] Training Step 15500: Policy loss = 1.5836329460144043, value loss = 0.29128000140190125\n",
      "INFO 2024-12-04 17:36:43 pipeline.py:712] Training Step 15520: Policy loss = 1.6155340671539307, value loss = 0.2610211670398712\n",
      "INFO 2024-12-04 17:36:52 pipeline.py:712] Training Step 15540: Policy loss = 1.610090970993042, value loss = 0.28262418508529663\n",
      "INFO 2024-12-04 17:37:02 pipeline.py:712] Training Step 15560: Policy loss = 1.6085827350616455, value loss = 0.2757360637187958\n",
      "INFO 2024-12-04 17:37:11 pipeline.py:712] Training Step 15580: Policy loss = 1.6204633712768555, value loss = 0.2785080373287201\n",
      "INFO 2024-12-04 17:37:21 pipeline.py:712] Training Step 15600: Policy loss = 1.5723763704299927, value loss = 0.27464956045150757\n",
      "INFO 2024-12-04 17:37:31 pipeline.py:712] Training Step 15620: Policy loss = 1.585923433303833, value loss = 0.2727791666984558\n",
      "INFO 2024-12-04 17:37:41 pipeline.py:712] Training Step 15640: Policy loss = 1.5548564195632935, value loss = 0.286031037569046\n",
      "INFO 2024-12-04 17:37:50 pipeline.py:712] Training Step 15660: Policy loss = 1.556456446647644, value loss = 0.2913624942302704\n",
      "INFO 2024-12-04 17:38:00 pipeline.py:712] Training Step 15680: Policy loss = 1.5625582933425903, value loss = 0.2934423089027405\n",
      "INFO 2024-12-04 17:38:09 pipeline.py:712] Training Step 15700: Policy loss = 1.5530788898468018, value loss = 0.29736340045928955\n",
      "INFO 2024-12-04 17:38:19 pipeline.py:712] Training Step 15720: Policy loss = 1.6377131938934326, value loss = 0.29180455207824707\n",
      "INFO 2024-12-04 17:38:29 pipeline.py:712] Training Step 15740: Policy loss = 1.572261095046997, value loss = 0.2601584792137146\n",
      "INFO 2024-12-04 17:38:39 pipeline.py:712] Training Step 15760: Policy loss = 1.5282948017120361, value loss = 0.29310691356658936\n",
      "INFO 2024-12-04 17:38:48 pipeline.py:712] Training Step 15780: Policy loss = 1.5466376543045044, value loss = 0.2732515335083008\n",
      "INFO 2024-12-04 17:38:58 pipeline.py:712] Training Step 15800: Policy loss = 1.5041491985321045, value loss = 0.28414294123649597\n",
      "INFO 2024-12-04 17:39:07 pipeline.py:712] Training Step 15820: Policy loss = 1.6217706203460693, value loss = 0.3069871962070465\n",
      "INFO 2024-12-04 17:39:17 pipeline.py:712] Training Step 15840: Policy loss = 1.5230768918991089, value loss = 0.2916781008243561\n",
      "INFO 2024-12-04 17:39:27 pipeline.py:712] Training Step 15860: Policy loss = 1.6412909030914307, value loss = 0.2997923493385315\n",
      "INFO 2024-12-04 17:39:36 pipeline.py:712] Training Step 15880: Policy loss = 1.5127973556518555, value loss = 0.28480976819992065\n",
      "INFO 2024-12-04 17:39:46 pipeline.py:712] Training Step 15900: Policy loss = 1.5424647331237793, value loss = 0.27182817459106445\n",
      "INFO 2024-12-04 17:39:56 pipeline.py:712] Training Step 15920: Policy loss = 1.5784193277359009, value loss = 0.26790183782577515\n",
      "INFO 2024-12-04 17:40:05 pipeline.py:712] Training Step 15940: Policy loss = 1.5879735946655273, value loss = 0.28516337275505066\n",
      "INFO 2024-12-04 17:40:15 pipeline.py:712] Training Step 15960: Policy loss = 1.5940632820129395, value loss = 0.2794588804244995\n",
      "INFO 2024-12-04 17:40:38 pipeline.py:738] training_steps 15972: Validation loss: Poliy loss 1.844620003074896, value_loss 0.4516910749380706\n",
      "INFO 2024-12-04 17:40:42 pipeline.py:712] Training Step 15980: Policy loss = 1.631433129310608, value loss = 0.233062744140625\n",
      "INFO 2024-12-04 17:40:52 pipeline.py:712] Training Step 16000: Policy loss = 1.5694074630737305, value loss = 0.2742544114589691\n",
      "INFO 2024-12-04 17:41:02 pipeline.py:712] Training Step 16020: Policy loss = 1.592170238494873, value loss = 0.2759673297405243\n",
      "INFO 2024-12-04 17:41:11 pipeline.py:712] Training Step 16040: Policy loss = 1.585014820098877, value loss = 0.27068811655044556\n",
      "INFO 2024-12-04 17:41:21 pipeline.py:712] Training Step 16060: Policy loss = 1.61257803440094, value loss = 0.26311132311820984\n",
      "INFO 2024-12-04 17:41:30 pipeline.py:712] Training Step 16080: Policy loss = 1.4813233613967896, value loss = 0.2718089818954468\n",
      "INFO 2024-12-04 17:41:40 pipeline.py:712] Training Step 16100: Policy loss = 1.5197787284851074, value loss = 0.29666727781295776\n",
      "INFO 2024-12-04 17:41:50 pipeline.py:712] Training Step 16120: Policy loss = 1.587898850440979, value loss = 0.28580671548843384\n",
      "INFO 2024-12-04 17:41:59 pipeline.py:712] Training Step 16140: Policy loss = 1.5869030952453613, value loss = 0.26419997215270996\n",
      "INFO 2024-12-04 17:42:09 pipeline.py:712] Training Step 16160: Policy loss = 1.5800228118896484, value loss = 0.2642880082130432\n",
      "INFO 2024-12-04 17:42:18 pipeline.py:712] Training Step 16180: Policy loss = 1.5712021589279175, value loss = 0.2809271812438965\n",
      "INFO 2024-12-04 17:42:28 pipeline.py:712] Training Step 16200: Policy loss = 1.5737462043762207, value loss = 0.2613363564014435\n",
      "INFO 2024-12-04 17:42:38 pipeline.py:712] Training Step 16220: Policy loss = 1.6218695640563965, value loss = 0.269181489944458\n",
      "INFO 2024-12-04 17:42:47 pipeline.py:712] Training Step 16240: Policy loss = 1.5736885070800781, value loss = 0.2579309642314911\n",
      "INFO 2024-12-04 17:42:57 pipeline.py:712] Training Step 16260: Policy loss = 1.5896506309509277, value loss = 0.2699785828590393\n",
      "INFO 2024-12-04 17:43:06 pipeline.py:712] Training Step 16280: Policy loss = 1.593963623046875, value loss = 0.26073014736175537\n",
      "INFO 2024-12-04 17:43:16 pipeline.py:712] Training Step 16300: Policy loss = 1.551337718963623, value loss = 0.2713024914264679\n",
      "INFO 2024-12-04 17:43:25 pipeline.py:712] Training Step 16320: Policy loss = 1.6239917278289795, value loss = 0.2839474081993103\n",
      "INFO 2024-12-04 17:43:35 pipeline.py:712] Training Step 16340: Policy loss = 1.5942816734313965, value loss = 0.2562124729156494\n",
      "INFO 2024-12-04 17:43:45 pipeline.py:712] Training Step 16360: Policy loss = 1.4585119485855103, value loss = 0.25609487295150757\n",
      "INFO 2024-12-04 17:43:54 pipeline.py:712] Training Step 16380: Policy loss = 1.525916337966919, value loss = 0.2954469323158264\n",
      "INFO 2024-12-04 17:44:04 pipeline.py:712] Training Step 16400: Policy loss = 1.5549721717834473, value loss = 0.27226021885871887\n",
      "INFO 2024-12-04 17:44:13 pipeline.py:712] Training Step 16420: Policy loss = 1.601459264755249, value loss = 0.2701420485973358\n",
      "INFO 2024-12-04 17:44:23 pipeline.py:712] Training Step 16440: Policy loss = 1.576685905456543, value loss = 0.30018967390060425\n",
      "INFO 2024-12-04 17:44:49 pipeline.py:738] training_steps 16456: Validation loss: Poliy loss 1.849002890899533, value_loss 0.44927550363736074\n",
      "INFO 2024-12-04 17:44:51 pipeline.py:712] Training Step 16460: Policy loss = 1.5716722011566162, value loss = 0.22948911786079407\n",
      "INFO 2024-12-04 17:45:00 pipeline.py:712] Training Step 16480: Policy loss = 1.5123493671417236, value loss = 0.2706088423728943\n",
      "INFO 2024-12-04 17:45:10 pipeline.py:712] Training Step 16500: Policy loss = 1.6223820447921753, value loss = 0.28870704770088196\n",
      "INFO 2024-12-04 17:45:19 pipeline.py:712] Training Step 16520: Policy loss = 1.623563289642334, value loss = 0.2921357750892639\n",
      "INFO 2024-12-04 17:45:29 pipeline.py:712] Training Step 16540: Policy loss = 1.5727005004882812, value loss = 0.24853423237800598\n",
      "INFO 2024-12-04 17:45:39 pipeline.py:712] Training Step 16560: Policy loss = 1.5396193265914917, value loss = 0.26583582162857056\n",
      "INFO 2024-12-04 17:45:48 pipeline.py:712] Training Step 16580: Policy loss = 1.663473129272461, value loss = 0.25289028882980347\n",
      "INFO 2024-12-04 17:45:58 pipeline.py:712] Training Step 16600: Policy loss = 1.5931683778762817, value loss = 0.2773423194885254\n",
      "INFO 2024-12-04 17:46:08 pipeline.py:712] Training Step 16620: Policy loss = 1.5498178005218506, value loss = 0.2798847556114197\n",
      "INFO 2024-12-04 17:46:17 pipeline.py:712] Training Step 16640: Policy loss = 1.5422152280807495, value loss = 0.2552930414676666\n",
      "INFO 2024-12-04 17:46:27 pipeline.py:712] Training Step 16660: Policy loss = 1.6478180885314941, value loss = 0.2751948833465576\n",
      "INFO 2024-12-04 17:46:36 pipeline.py:712] Training Step 16680: Policy loss = 1.5708866119384766, value loss = 0.23643258213996887\n",
      "INFO 2024-12-04 17:46:46 pipeline.py:712] Training Step 16700: Policy loss = 1.572566032409668, value loss = 0.29406681656837463\n",
      "INFO 2024-12-04 17:46:56 pipeline.py:712] Training Step 16720: Policy loss = 1.5297648906707764, value loss = 0.25580358505249023\n",
      "INFO 2024-12-04 17:47:05 pipeline.py:712] Training Step 16740: Policy loss = 1.5601763725280762, value loss = 0.3217903673648834\n",
      "INFO 2024-12-04 17:47:15 pipeline.py:712] Training Step 16760: Policy loss = 1.549072027206421, value loss = 0.303069531917572\n",
      "INFO 2024-12-04 17:47:24 pipeline.py:712] Training Step 16780: Policy loss = 1.5745970010757446, value loss = 0.29425302147865295\n",
      "INFO 2024-12-04 17:47:34 pipeline.py:712] Training Step 16800: Policy loss = 1.5737824440002441, value loss = 0.2409396469593048\n",
      "INFO 2024-12-04 17:47:44 pipeline.py:712] Training Step 16820: Policy loss = 1.5702263116836548, value loss = 0.26991036534309387\n",
      "INFO 2024-12-04 17:47:53 pipeline.py:712] Training Step 16840: Policy loss = 1.5996216535568237, value loss = 0.27246126532554626\n",
      "INFO 2024-12-04 17:48:03 pipeline.py:712] Training Step 16860: Policy loss = 1.5476731061935425, value loss = 0.24541102349758148\n",
      "INFO 2024-12-04 17:48:12 pipeline.py:712] Training Step 16880: Policy loss = 1.5301403999328613, value loss = 0.27776801586151123\n",
      "INFO 2024-12-04 17:48:22 pipeline.py:712] Training Step 16900: Policy loss = 1.5743074417114258, value loss = 0.26836341619491577\n",
      "INFO 2024-12-04 17:48:31 pipeline.py:712] Training Step 16920: Policy loss = 1.5846530199050903, value loss = 0.30172568559646606\n",
      "INFO 2024-12-04 17:48:41 pipeline.py:712] Training Step 16940: Policy loss = 1.5547118186950684, value loss = 0.2879467308521271\n",
      "INFO 2024-12-04 17:48:59 pipeline.py:738] training_steps 16940: Validation loss: Poliy loss 1.8470185975559423, value_loss 0.4482616007816596\n",
      "INFO 2024-12-04 17:49:09 pipeline.py:712] Training Step 16960: Policy loss = 1.5214979648590088, value loss = 0.26990988850593567\n",
      "INFO 2024-12-04 17:49:18 pipeline.py:712] Training Step 16980: Policy loss = 1.4676482677459717, value loss = 0.2933952212333679\n",
      "INFO 2024-12-04 17:49:28 pipeline.py:712] Training Step 17000: Policy loss = 1.5892508029937744, value loss = 0.2737621068954468\n",
      "INFO 2024-12-04 17:49:37 pipeline.py:712] Training Step 17020: Policy loss = 1.4770104885101318, value loss = 0.24861277639865875\n",
      "INFO 2024-12-04 17:49:47 pipeline.py:712] Training Step 17040: Policy loss = 1.5046851634979248, value loss = 0.2728137969970703\n",
      "INFO 2024-12-04 17:49:57 pipeline.py:712] Training Step 17060: Policy loss = 1.524594783782959, value loss = 0.2540653944015503\n",
      "INFO 2024-12-04 17:50:06 pipeline.py:712] Training Step 17080: Policy loss = 1.6740176677703857, value loss = 0.2777101993560791\n",
      "INFO 2024-12-04 17:50:16 pipeline.py:712] Training Step 17100: Policy loss = 1.5593425035476685, value loss = 0.26544320583343506\n",
      "INFO 2024-12-04 17:50:25 pipeline.py:712] Training Step 17120: Policy loss = 1.6897118091583252, value loss = 0.23252007365226746\n",
      "INFO 2024-12-04 17:50:35 pipeline.py:712] Training Step 17140: Policy loss = 1.5549758672714233, value loss = 0.24156178534030914\n",
      "INFO 2024-12-04 17:50:44 pipeline.py:712] Training Step 17160: Policy loss = 1.5710785388946533, value loss = 0.22256498038768768\n",
      "INFO 2024-12-04 17:50:54 pipeline.py:712] Training Step 17180: Policy loss = 1.5541220903396606, value loss = 0.27086758613586426\n",
      "INFO 2024-12-04 17:51:04 pipeline.py:712] Training Step 17200: Policy loss = 1.5557842254638672, value loss = 0.2540343105792999\n",
      "INFO 2024-12-04 17:51:13 pipeline.py:712] Training Step 17220: Policy loss = 1.578697919845581, value loss = 0.2731364667415619\n",
      "INFO 2024-12-04 17:51:23 pipeline.py:712] Training Step 17240: Policy loss = 1.597705602645874, value loss = 0.27570509910583496\n",
      "INFO 2024-12-04 17:51:32 pipeline.py:712] Training Step 17260: Policy loss = 1.4948110580444336, value loss = 0.2910769283771515\n",
      "INFO 2024-12-04 17:51:42 pipeline.py:712] Training Step 17280: Policy loss = 1.5570921897888184, value loss = 0.27271997928619385\n",
      "INFO 2024-12-04 17:51:52 pipeline.py:712] Training Step 17300: Policy loss = 1.5539882183074951, value loss = 0.27291831374168396\n",
      "INFO 2024-12-04 17:52:01 pipeline.py:712] Training Step 17320: Policy loss = 1.6185362339019775, value loss = 0.2831028699874878\n",
      "INFO 2024-12-04 17:52:11 pipeline.py:712] Training Step 17340: Policy loss = 1.535556674003601, value loss = 0.29080086946487427\n",
      "INFO 2024-12-04 17:52:21 pipeline.py:712] Training Step 17360: Policy loss = 1.5882534980773926, value loss = 0.29342982172966003\n",
      "INFO 2024-12-04 17:52:30 pipeline.py:712] Training Step 17380: Policy loss = 1.5559113025665283, value loss = 0.2694680094718933\n",
      "INFO 2024-12-04 17:52:40 pipeline.py:712] Training Step 17400: Policy loss = 1.476710557937622, value loss = 0.2807313799858093\n",
      "INFO 2024-12-04 17:52:49 pipeline.py:712] Training Step 17420: Policy loss = 1.5678446292877197, value loss = 0.27820056676864624\n",
      "INFO 2024-12-04 17:53:09 pipeline.py:738] training_steps 17424: Validation loss: Poliy loss 1.8476472868294012, value_loss 0.449046215805851\n",
      "INFO 2024-12-04 17:53:17 pipeline.py:712] Training Step 17440: Policy loss = 1.4970884323120117, value loss = 0.27638721466064453\n",
      "INFO 2024-12-04 17:53:26 pipeline.py:712] Training Step 17460: Policy loss = 1.5918993949890137, value loss = 0.26549190282821655\n",
      "INFO 2024-12-04 17:53:36 pipeline.py:712] Training Step 17480: Policy loss = 1.5909883975982666, value loss = 0.27941596508026123\n",
      "INFO 2024-12-04 17:53:46 pipeline.py:712] Training Step 17500: Policy loss = 1.6060646772384644, value loss = 0.2828226685523987\n",
      "INFO 2024-12-04 17:53:55 pipeline.py:712] Training Step 17520: Policy loss = 1.5061447620391846, value loss = 0.24420607089996338\n",
      "INFO 2024-12-04 17:54:05 pipeline.py:712] Training Step 17540: Policy loss = 1.5305676460266113, value loss = 0.28502196073532104\n",
      "INFO 2024-12-04 17:54:14 pipeline.py:712] Training Step 17560: Policy loss = 1.5695278644561768, value loss = 0.2985367774963379\n",
      "INFO 2024-12-04 17:54:24 pipeline.py:712] Training Step 17580: Policy loss = 1.5701582431793213, value loss = 0.25617504119873047\n",
      "INFO 2024-12-04 17:54:34 pipeline.py:712] Training Step 17600: Policy loss = 1.5206732749938965, value loss = 0.25340840220451355\n",
      "INFO 2024-12-04 17:54:43 pipeline.py:712] Training Step 17620: Policy loss = 1.6055378913879395, value loss = 0.24961283802986145\n",
      "INFO 2024-12-04 17:54:53 pipeline.py:712] Training Step 17640: Policy loss = 1.5704338550567627, value loss = 0.26190710067749023\n",
      "INFO 2024-12-04 17:55:02 pipeline.py:712] Training Step 17660: Policy loss = 1.5938849449157715, value loss = 0.2603227496147156\n",
      "INFO 2024-12-04 17:55:12 pipeline.py:712] Training Step 17680: Policy loss = 1.5335354804992676, value loss = 0.26542213559150696\n",
      "INFO 2024-12-04 17:55:22 pipeline.py:712] Training Step 17700: Policy loss = 1.5577669143676758, value loss = 0.24746620655059814\n",
      "INFO 2024-12-04 17:55:31 pipeline.py:712] Training Step 17720: Policy loss = 1.617862582206726, value loss = 0.2838655114173889\n",
      "INFO 2024-12-04 17:55:41 pipeline.py:712] Training Step 17740: Policy loss = 1.6302987337112427, value loss = 0.2220935821533203\n",
      "INFO 2024-12-04 17:55:50 pipeline.py:712] Training Step 17760: Policy loss = 1.559279441833496, value loss = 0.25204402208328247\n",
      "INFO 2024-12-04 17:56:00 pipeline.py:712] Training Step 17780: Policy loss = 1.5406246185302734, value loss = 0.2718430757522583\n",
      "INFO 2024-12-04 17:56:10 pipeline.py:712] Training Step 17800: Policy loss = 1.5139391422271729, value loss = 0.2707967162132263\n",
      "INFO 2024-12-04 17:56:19 pipeline.py:712] Training Step 17820: Policy loss = 1.5781277418136597, value loss = 0.25761616230010986\n",
      "INFO 2024-12-04 17:56:29 pipeline.py:712] Training Step 17840: Policy loss = 1.522730827331543, value loss = 0.28646841645240784\n",
      "INFO 2024-12-04 17:56:38 pipeline.py:712] Training Step 17860: Policy loss = 1.492612361907959, value loss = 0.3003295958042145\n",
      "INFO 2024-12-04 17:56:48 pipeline.py:712] Training Step 17880: Policy loss = 1.5561068058013916, value loss = 0.2845694422721863\n",
      "INFO 2024-12-04 17:56:58 pipeline.py:712] Training Step 17900: Policy loss = 1.5993527173995972, value loss = 0.2868192195892334\n",
      "INFO 2024-12-04 17:57:19 pipeline.py:738] training_steps 17908: Validation loss: Poliy loss 1.846288299951397, value_loss 0.4470345414564258\n",
      "INFO 2024-12-04 17:57:25 pipeline.py:712] Training Step 17920: Policy loss = 1.616415023803711, value loss = 0.2467501014471054\n",
      "INFO 2024-12-04 17:57:35 pipeline.py:712] Training Step 17940: Policy loss = 1.533701777458191, value loss = 0.2757735252380371\n",
      "INFO 2024-12-04 17:57:44 pipeline.py:712] Training Step 17960: Policy loss = 1.6254442930221558, value loss = 0.2551689147949219\n",
      "INFO 2024-12-04 17:57:54 pipeline.py:712] Training Step 17980: Policy loss = 1.5740313529968262, value loss = 0.25185054540634155\n",
      "INFO 2024-12-04 17:58:03 pipeline.py:712] Training Step 18000: Policy loss = 1.4962437152862549, value loss = 0.2685333490371704\n",
      "INFO 2024-12-04 17:58:13 pipeline.py:712] Training Step 18020: Policy loss = 1.5120127201080322, value loss = 0.24812477827072144\n",
      "INFO 2024-12-04 17:58:23 pipeline.py:712] Training Step 18040: Policy loss = 1.5375885963439941, value loss = 0.26801735162734985\n",
      "INFO 2024-12-04 17:58:32 pipeline.py:712] Training Step 18060: Policy loss = 1.5306836366653442, value loss = 0.24101099371910095\n",
      "INFO 2024-12-04 17:58:42 pipeline.py:712] Training Step 18080: Policy loss = 1.4884178638458252, value loss = 0.2696671485900879\n",
      "INFO 2024-12-04 17:58:51 pipeline.py:712] Training Step 18100: Policy loss = 1.5822635889053345, value loss = 0.23540334403514862\n",
      "INFO 2024-12-04 17:59:01 pipeline.py:712] Training Step 18120: Policy loss = 1.509953260421753, value loss = 0.2824375033378601\n",
      "INFO 2024-12-04 17:59:11 pipeline.py:712] Training Step 18140: Policy loss = 1.6448314189910889, value loss = 0.277004212141037\n",
      "INFO 2024-12-04 17:59:20 pipeline.py:712] Training Step 18160: Policy loss = 1.5400619506835938, value loss = 0.2487441599369049\n",
      "INFO 2024-12-04 17:59:30 pipeline.py:712] Training Step 18180: Policy loss = 1.5650579929351807, value loss = 0.285236656665802\n",
      "INFO 2024-12-04 17:59:39 pipeline.py:712] Training Step 18200: Policy loss = 1.5663124322891235, value loss = 0.2385740578174591\n",
      "INFO 2024-12-04 17:59:49 pipeline.py:712] Training Step 18220: Policy loss = 1.658118724822998, value loss = 0.2664386034011841\n",
      "INFO 2024-12-04 17:59:59 pipeline.py:712] Training Step 18240: Policy loss = 1.522495985031128, value loss = 0.25600484013557434\n",
      "INFO 2024-12-04 18:00:08 pipeline.py:712] Training Step 18260: Policy loss = 1.5638421773910522, value loss = 0.2842862010002136\n",
      "INFO 2024-12-04 18:00:18 pipeline.py:712] Training Step 18280: Policy loss = 1.5968469381332397, value loss = 0.29180389642715454\n",
      "INFO 2024-12-04 18:00:27 pipeline.py:712] Training Step 18300: Policy loss = 1.5308821201324463, value loss = 0.2677243649959564\n",
      "INFO 2024-12-04 18:00:37 pipeline.py:712] Training Step 18320: Policy loss = 1.494524359703064, value loss = 0.258119136095047\n",
      "INFO 2024-12-04 18:00:47 pipeline.py:712] Training Step 18340: Policy loss = 1.5235553979873657, value loss = 0.2830512821674347\n",
      "INFO 2024-12-04 18:00:56 pipeline.py:712] Training Step 18360: Policy loss = 1.5265514850616455, value loss = 0.24837616086006165\n",
      "INFO 2024-12-04 18:01:06 pipeline.py:712] Training Step 18380: Policy loss = 1.5740561485290527, value loss = 0.23690588772296906\n",
      "INFO 2024-12-04 18:01:30 pipeline.py:738] training_steps 18392: Validation loss: Poliy loss 1.851577877998352, value_loss 0.4487224643836256\n",
      "INFO 2024-12-04 18:01:33 pipeline.py:712] Training Step 18400: Policy loss = 1.5304694175720215, value loss = 0.2583511471748352\n",
      "INFO 2024-12-04 18:01:43 pipeline.py:712] Training Step 18420: Policy loss = 1.5372921228408813, value loss = 0.24930693209171295\n",
      "INFO 2024-12-04 18:01:53 pipeline.py:712] Training Step 18440: Policy loss = 1.5316600799560547, value loss = 0.2677788734436035\n",
      "INFO 2024-12-04 18:02:02 pipeline.py:712] Training Step 18460: Policy loss = 1.5020360946655273, value loss = 0.2449033260345459\n",
      "INFO 2024-12-04 18:02:12 pipeline.py:712] Training Step 18480: Policy loss = 1.5076714754104614, value loss = 0.2520659565925598\n",
      "INFO 2024-12-04 18:02:22 pipeline.py:712] Training Step 18500: Policy loss = 1.5301010608673096, value loss = 0.24569116532802582\n",
      "INFO 2024-12-04 18:02:31 pipeline.py:712] Training Step 18520: Policy loss = 1.6267311573028564, value loss = 0.26003968715667725\n",
      "INFO 2024-12-04 18:02:41 pipeline.py:712] Training Step 18540: Policy loss = 1.5558838844299316, value loss = 0.2422575056552887\n",
      "INFO 2024-12-04 18:02:50 pipeline.py:712] Training Step 18560: Policy loss = 1.5138967037200928, value loss = 0.24319937825202942\n",
      "INFO 2024-12-04 18:03:00 pipeline.py:712] Training Step 18580: Policy loss = 1.516270399093628, value loss = 0.2641800045967102\n",
      "INFO 2024-12-04 18:03:09 pipeline.py:712] Training Step 18600: Policy loss = 1.6207280158996582, value loss = 0.2528873682022095\n",
      "INFO 2024-12-04 18:03:19 pipeline.py:712] Training Step 18620: Policy loss = 1.5790799856185913, value loss = 0.2788999676704407\n",
      "INFO 2024-12-04 18:03:29 pipeline.py:712] Training Step 18640: Policy loss = 1.5672558546066284, value loss = 0.23742470145225525\n",
      "INFO 2024-12-04 18:03:38 pipeline.py:712] Training Step 18660: Policy loss = 1.558321237564087, value loss = 0.26588737964630127\n",
      "INFO 2024-12-04 18:03:48 pipeline.py:712] Training Step 18680: Policy loss = 1.5629162788391113, value loss = 0.24716973304748535\n",
      "INFO 2024-12-04 18:03:57 pipeline.py:712] Training Step 18700: Policy loss = 1.520346999168396, value loss = 0.27709129452705383\n",
      "INFO 2024-12-04 18:04:07 pipeline.py:712] Training Step 18720: Policy loss = 1.523805856704712, value loss = 0.2756396234035492\n",
      "INFO 2024-12-04 18:04:17 pipeline.py:712] Training Step 18740: Policy loss = 1.5337066650390625, value loss = 0.23160076141357422\n",
      "INFO 2024-12-04 18:04:26 pipeline.py:712] Training Step 18760: Policy loss = 1.5771501064300537, value loss = 0.2770426869392395\n",
      "INFO 2024-12-04 18:04:36 pipeline.py:712] Training Step 18780: Policy loss = 1.51278817653656, value loss = 0.2495003491640091\n",
      "INFO 2024-12-04 18:04:46 pipeline.py:712] Training Step 18800: Policy loss = 1.644884467124939, value loss = 0.23350104689598083\n",
      "INFO 2024-12-04 18:04:55 pipeline.py:712] Training Step 18820: Policy loss = 1.607869029045105, value loss = 0.278756707906723\n",
      "INFO 2024-12-04 18:05:05 pipeline.py:712] Training Step 18840: Policy loss = 1.5410031080245972, value loss = 0.2633572816848755\n",
      "INFO 2024-12-04 18:05:14 pipeline.py:712] Training Step 18860: Policy loss = 1.5275371074676514, value loss = 0.2732425928115845\n",
      "INFO 2024-12-04 18:05:40 pipeline.py:738] training_steps 18876: Validation loss: Poliy loss 1.84785344659305, value_loss 0.44695664526986295\n",
      "INFO 2024-12-04 18:05:42 pipeline.py:712] Training Step 18880: Policy loss = 1.5648113489151, value loss = 0.27090978622436523\n",
      "INFO 2024-12-04 18:05:51 pipeline.py:712] Training Step 18900: Policy loss = 1.5836896896362305, value loss = 0.22463291883468628\n",
      "INFO 2024-12-04 18:06:01 pipeline.py:712] Training Step 18920: Policy loss = 1.524043083190918, value loss = 0.22761079668998718\n",
      "INFO 2024-12-04 18:06:11 pipeline.py:712] Training Step 18940: Policy loss = 1.5597259998321533, value loss = 0.2530345618724823\n",
      "INFO 2024-12-04 18:06:20 pipeline.py:712] Training Step 18960: Policy loss = 1.5273807048797607, value loss = 0.22515523433685303\n",
      "INFO 2024-12-04 18:06:30 pipeline.py:712] Training Step 18980: Policy loss = 1.586480975151062, value loss = 0.25071457028388977\n",
      "INFO 2024-12-04 18:06:40 pipeline.py:712] Training Step 19000: Policy loss = 1.53826904296875, value loss = 0.254620760679245\n",
      "INFO 2024-12-04 18:06:49 pipeline.py:712] Training Step 19020: Policy loss = 1.5262665748596191, value loss = 0.2581765651702881\n",
      "INFO 2024-12-04 18:06:59 pipeline.py:712] Training Step 19040: Policy loss = 1.5809471607208252, value loss = 0.2375997006893158\n",
      "INFO 2024-12-04 18:07:08 pipeline.py:712] Training Step 19060: Policy loss = 1.586163878440857, value loss = 0.2695770263671875\n",
      "INFO 2024-12-04 18:07:18 pipeline.py:712] Training Step 19080: Policy loss = 1.560248613357544, value loss = 0.26112547516822815\n",
      "INFO 2024-12-04 18:07:27 pipeline.py:712] Training Step 19100: Policy loss = 1.5818899869918823, value loss = 0.2622934579849243\n",
      "INFO 2024-12-04 18:07:37 pipeline.py:712] Training Step 19120: Policy loss = 1.5472261905670166, value loss = 0.273764044046402\n",
      "INFO 2024-12-04 18:07:47 pipeline.py:712] Training Step 19140: Policy loss = 1.5809134244918823, value loss = 0.24347147345542908\n",
      "INFO 2024-12-04 18:07:56 pipeline.py:712] Training Step 19160: Policy loss = 1.5732688903808594, value loss = 0.26656845211982727\n",
      "INFO 2024-12-04 18:08:06 pipeline.py:712] Training Step 19180: Policy loss = 1.538509726524353, value loss = 0.2313634753227234\n",
      "INFO 2024-12-04 18:08:16 pipeline.py:712] Training Step 19200: Policy loss = 1.5003331899642944, value loss = 0.21180343627929688\n",
      "INFO 2024-12-04 18:08:25 pipeline.py:712] Training Step 19220: Policy loss = 1.5468158721923828, value loss = 0.2459312379360199\n",
      "INFO 2024-12-04 18:08:35 pipeline.py:712] Training Step 19240: Policy loss = 1.5423697233200073, value loss = 0.24739690124988556\n",
      "INFO 2024-12-04 18:08:44 pipeline.py:712] Training Step 19260: Policy loss = 1.5919063091278076, value loss = 0.26094764471054077\n",
      "INFO 2024-12-04 18:08:54 pipeline.py:712] Training Step 19280: Policy loss = 1.5484943389892578, value loss = 0.24673911929130554\n",
      "INFO 2024-12-04 18:09:04 pipeline.py:712] Training Step 19300: Policy loss = 1.5735228061676025, value loss = 0.256712943315506\n",
      "INFO 2024-12-04 18:09:13 pipeline.py:712] Training Step 19320: Policy loss = 1.4827674627304077, value loss = 0.2587287425994873\n",
      "INFO 2024-12-04 18:09:23 pipeline.py:712] Training Step 19340: Policy loss = 1.5802953243255615, value loss = 0.24641263484954834\n",
      "INFO 2024-12-04 18:09:33 pipeline.py:712] Training Step 19360: Policy loss = 1.5366132259368896, value loss = 0.253986656665802\n",
      "INFO 2024-12-04 18:09:50 pipeline.py:738] training_steps 19360: Validation loss: Poliy loss 1.848953589064176, value_loss 0.44987646526977665\n",
      "INFO 2024-12-04 18:10:00 pipeline.py:712] Training Step 19380: Policy loss = 1.5274409055709839, value loss = 0.26808178424835205\n",
      "INFO 2024-12-04 18:10:10 pipeline.py:712] Training Step 19400: Policy loss = 1.537839412689209, value loss = 0.25886014103889465\n",
      "INFO 2024-12-04 18:10:19 pipeline.py:712] Training Step 19420: Policy loss = 1.5838391780853271, value loss = 0.24534420669078827\n",
      "INFO 2024-12-04 18:10:29 pipeline.py:712] Training Step 19440: Policy loss = 1.606917381286621, value loss = 0.23710979521274567\n",
      "INFO 2024-12-04 18:10:38 pipeline.py:712] Training Step 19460: Policy loss = 1.6183520555496216, value loss = 0.2537035346031189\n",
      "INFO 2024-12-04 18:10:48 pipeline.py:712] Training Step 19480: Policy loss = 1.5250061750411987, value loss = 0.27022162079811096\n",
      "INFO 2024-12-04 18:10:58 pipeline.py:712] Training Step 19500: Policy loss = 1.5874974727630615, value loss = 0.23626044392585754\n",
      "INFO 2024-12-04 18:11:07 pipeline.py:712] Training Step 19520: Policy loss = 1.5612218379974365, value loss = 0.26233187317848206\n",
      "INFO 2024-12-04 18:11:17 pipeline.py:712] Training Step 19540: Policy loss = 1.5444177389144897, value loss = 0.25104114413261414\n",
      "INFO 2024-12-04 18:11:26 pipeline.py:712] Training Step 19560: Policy loss = 1.5562468767166138, value loss = 0.2559971213340759\n",
      "INFO 2024-12-04 18:11:36 pipeline.py:712] Training Step 19580: Policy loss = 1.5409915447235107, value loss = 0.2494201809167862\n",
      "INFO 2024-12-04 18:11:46 pipeline.py:712] Training Step 19600: Policy loss = 1.586045265197754, value loss = 0.270190954208374\n",
      "INFO 2024-12-04 18:11:55 pipeline.py:712] Training Step 19620: Policy loss = 1.622183918952942, value loss = 0.2476627230644226\n",
      "INFO 2024-12-04 18:12:05 pipeline.py:712] Training Step 19640: Policy loss = 1.5557687282562256, value loss = 0.20802536606788635\n",
      "INFO 2024-12-04 18:12:15 pipeline.py:712] Training Step 19660: Policy loss = 1.6162996292114258, value loss = 0.2514009475708008\n",
      "INFO 2024-12-04 18:12:24 pipeline.py:712] Training Step 19680: Policy loss = 1.5379232168197632, value loss = 0.2375551164150238\n",
      "INFO 2024-12-04 18:12:34 pipeline.py:712] Training Step 19700: Policy loss = 1.55265474319458, value loss = 0.28959470987319946\n",
      "INFO 2024-12-04 18:12:43 pipeline.py:712] Training Step 19720: Policy loss = 1.5569709539413452, value loss = 0.25576579570770264\n",
      "INFO 2024-12-04 18:12:53 pipeline.py:712] Training Step 19740: Policy loss = 1.52218759059906, value loss = 0.23580199480056763\n",
      "INFO 2024-12-04 18:13:03 pipeline.py:712] Training Step 19760: Policy loss = 1.5414760112762451, value loss = 0.2569127678871155\n",
      "INFO 2024-12-04 18:13:12 pipeline.py:712] Training Step 19780: Policy loss = 1.4925823211669922, value loss = 0.26898297667503357\n",
      "INFO 2024-12-04 18:13:22 pipeline.py:712] Training Step 19800: Policy loss = 1.5313701629638672, value loss = 0.26845914125442505\n",
      "INFO 2024-12-04 18:13:31 pipeline.py:712] Training Step 19820: Policy loss = 1.5272449254989624, value loss = 0.24867798388004303\n",
      "INFO 2024-12-04 18:13:41 pipeline.py:712] Training Step 19840: Policy loss = 1.4191840887069702, value loss = 0.269522100687027\n",
      "INFO 2024-12-04 18:14:01 pipeline.py:738] training_steps 19844: Validation loss: Poliy loss 1.850211479624764, value_loss 0.44562768081172566\n",
      "INFO 2024-12-04 18:14:09 pipeline.py:712] Training Step 19860: Policy loss = 1.4915692806243896, value loss = 0.25445377826690674\n",
      "INFO 2024-12-04 18:14:18 pipeline.py:712] Training Step 19880: Policy loss = 1.5431392192840576, value loss = 0.23548586666584015\n",
      "INFO 2024-12-04 18:14:28 pipeline.py:712] Training Step 19900: Policy loss = 1.6049704551696777, value loss = 0.26157835125923157\n",
      "INFO 2024-12-04 18:14:37 pipeline.py:712] Training Step 19920: Policy loss = 1.5182956457138062, value loss = 0.24298788607120514\n",
      "INFO 2024-12-04 18:14:47 pipeline.py:712] Training Step 19940: Policy loss = 1.6170356273651123, value loss = 0.24206843972206116\n",
      "INFO 2024-12-04 18:14:57 pipeline.py:712] Training Step 19960: Policy loss = 1.5457606315612793, value loss = 0.23075276613235474\n",
      "INFO 2024-12-04 18:15:06 pipeline.py:712] Training Step 19980: Policy loss = 1.485921025276184, value loss = 0.21722140908241272\n",
      "INFO 2024-12-04 18:15:16 pipeline.py:712] Training Step 20000: Policy loss = 1.498953104019165, value loss = 0.24322307109832764\n",
      "INFO 2024-12-04 18:15:25 pipeline.py:712] Training Step 20020: Policy loss = 1.5284236669540405, value loss = 0.21282422542572021\n",
      "INFO 2024-12-04 18:15:35 pipeline.py:712] Training Step 20040: Policy loss = 1.56648588180542, value loss = 0.2541899085044861\n",
      "INFO 2024-12-04 18:15:45 pipeline.py:712] Training Step 20060: Policy loss = 1.5457661151885986, value loss = 0.2601223587989807\n",
      "INFO 2024-12-04 18:15:54 pipeline.py:712] Training Step 20080: Policy loss = 1.6074857711791992, value loss = 0.22002774477005005\n",
      "INFO 2024-12-04 18:16:04 pipeline.py:712] Training Step 20100: Policy loss = 1.4766855239868164, value loss = 0.23831644654273987\n",
      "INFO 2024-12-04 18:16:14 pipeline.py:712] Training Step 20120: Policy loss = 1.4947072267532349, value loss = 0.22191599011421204\n",
      "INFO 2024-12-04 18:16:23 pipeline.py:712] Training Step 20140: Policy loss = 1.5572831630706787, value loss = 0.22638452053070068\n",
      "INFO 2024-12-04 18:16:33 pipeline.py:712] Training Step 20160: Policy loss = 1.4733449220657349, value loss = 0.2657078206539154\n",
      "INFO 2024-12-04 18:16:42 pipeline.py:712] Training Step 20180: Policy loss = 1.4975416660308838, value loss = 0.25578615069389343\n",
      "INFO 2024-12-04 18:16:52 pipeline.py:712] Training Step 20200: Policy loss = 1.5114154815673828, value loss = 0.24631156027317047\n",
      "INFO 2024-12-04 18:17:02 pipeline.py:712] Training Step 20220: Policy loss = 1.5450564622879028, value loss = 0.26260846853256226\n",
      "INFO 2024-12-04 18:17:11 pipeline.py:712] Training Step 20240: Policy loss = 1.4883592128753662, value loss = 0.23515427112579346\n",
      "INFO 2024-12-04 18:17:21 pipeline.py:712] Training Step 20260: Policy loss = 1.4835708141326904, value loss = 0.22423651814460754\n",
      "INFO 2024-12-04 18:17:30 pipeline.py:712] Training Step 20280: Policy loss = 1.6158307790756226, value loss = 0.2315414845943451\n",
      "INFO 2024-12-04 18:17:40 pipeline.py:712] Training Step 20300: Policy loss = 1.4911421537399292, value loss = 0.2283748835325241\n",
      "INFO 2024-12-04 18:17:50 pipeline.py:712] Training Step 20320: Policy loss = 1.5523176193237305, value loss = 0.21579553186893463\n",
      "INFO 2024-12-04 18:18:11 pipeline.py:738] training_steps 20328: Validation loss: Poliy loss 1.846380425281212, value_loss 0.44125755399954125\n",
      "INFO 2024-12-04 18:18:17 pipeline.py:712] Training Step 20340: Policy loss = 1.4445511102676392, value loss = 0.2340792715549469\n",
      "INFO 2024-12-04 18:18:27 pipeline.py:712] Training Step 20360: Policy loss = 1.5105533599853516, value loss = 0.23707301914691925\n",
      "INFO 2024-12-04 18:18:36 pipeline.py:712] Training Step 20380: Policy loss = 1.5614022016525269, value loss = 0.23436105251312256\n",
      "INFO 2024-12-04 18:18:46 pipeline.py:712] Training Step 20400: Policy loss = 1.4815138578414917, value loss = 0.22630509734153748\n",
      "INFO 2024-12-04 18:18:55 pipeline.py:712] Training Step 20420: Policy loss = 1.5595245361328125, value loss = 0.23801428079605103\n",
      "INFO 2024-12-04 18:19:05 pipeline.py:712] Training Step 20440: Policy loss = 1.5150319337844849, value loss = 0.23494867980480194\n",
      "INFO 2024-12-04 18:19:15 pipeline.py:712] Training Step 20460: Policy loss = 1.5076169967651367, value loss = 0.22821299731731415\n",
      "INFO 2024-12-04 18:19:24 pipeline.py:712] Training Step 20480: Policy loss = 1.535503625869751, value loss = 0.23282800614833832\n",
      "INFO 2024-12-04 18:19:34 pipeline.py:712] Training Step 20500: Policy loss = 1.5288680791854858, value loss = 0.20857031643390656\n",
      "INFO 2024-12-04 18:19:44 pipeline.py:712] Training Step 20520: Policy loss = 1.5156182050704956, value loss = 0.22791624069213867\n",
      "INFO 2024-12-04 18:19:53 pipeline.py:712] Training Step 20540: Policy loss = 1.5469809770584106, value loss = 0.21368223428726196\n",
      "INFO 2024-12-04 18:20:03 pipeline.py:712] Training Step 20560: Policy loss = 1.5236129760742188, value loss = 0.2289532721042633\n",
      "INFO 2024-12-04 18:20:13 pipeline.py:712] Training Step 20580: Policy loss = 1.5536845922470093, value loss = 0.2129008024930954\n",
      "INFO 2024-12-04 18:20:22 pipeline.py:712] Training Step 20600: Policy loss = 1.508474588394165, value loss = 0.24420508742332458\n",
      "INFO 2024-12-04 18:20:32 pipeline.py:712] Training Step 20620: Policy loss = 1.5834264755249023, value loss = 0.23283307254314423\n",
      "INFO 2024-12-04 18:20:41 pipeline.py:712] Training Step 20640: Policy loss = 1.5624109506607056, value loss = 0.20598936080932617\n",
      "INFO 2024-12-04 18:20:51 pipeline.py:712] Training Step 20660: Policy loss = 1.5027954578399658, value loss = 0.22235342860221863\n",
      "INFO 2024-12-04 18:21:01 pipeline.py:712] Training Step 20680: Policy loss = 1.4759255647659302, value loss = 0.25013771653175354\n",
      "INFO 2024-12-04 18:21:10 pipeline.py:712] Training Step 20700: Policy loss = 1.5111536979675293, value loss = 0.20706908404827118\n",
      "INFO 2024-12-04 18:21:20 pipeline.py:712] Training Step 20720: Policy loss = 1.4776439666748047, value loss = 0.2489657700061798\n",
      "INFO 2024-12-04 18:21:29 pipeline.py:712] Training Step 20740: Policy loss = 1.4550870656967163, value loss = 0.21530109643936157\n",
      "INFO 2024-12-04 18:21:39 pipeline.py:712] Training Step 20760: Policy loss = 1.5029394626617432, value loss = 0.21438224613666534\n",
      "INFO 2024-12-04 18:21:48 pipeline.py:712] Training Step 20780: Policy loss = 1.5254566669464111, value loss = 0.19445806741714478\n",
      "INFO 2024-12-04 18:21:58 pipeline.py:712] Training Step 20800: Policy loss = 1.5437326431274414, value loss = 0.2548733949661255\n",
      "INFO 2024-12-04 18:22:22 pipeline.py:738] training_steps 20812: Validation loss: Poliy loss 1.8482188015687662, value_loss 0.4424944825348307\n",
      "INFO 2024-12-04 18:22:26 pipeline.py:712] Training Step 20820: Policy loss = 1.6007835865020752, value loss = 0.22842779755592346\n",
      "INFO 2024-12-04 18:22:35 pipeline.py:712] Training Step 20840: Policy loss = 1.4315507411956787, value loss = 0.23603761196136475\n",
      "INFO 2024-12-04 18:22:45 pipeline.py:712] Training Step 20860: Policy loss = 1.563690185546875, value loss = 0.18746882677078247\n",
      "INFO 2024-12-04 18:22:54 pipeline.py:712] Training Step 20880: Policy loss = 1.505471110343933, value loss = 0.20432056486606598\n",
      "INFO 2024-12-04 18:23:04 pipeline.py:712] Training Step 20900: Policy loss = 1.4950146675109863, value loss = 0.24466530978679657\n",
      "INFO 2024-12-04 18:23:14 pipeline.py:712] Training Step 20920: Policy loss = 1.56083345413208, value loss = 0.23048755526542664\n",
      "INFO 2024-12-04 18:23:23 pipeline.py:712] Training Step 20940: Policy loss = 1.5536912679672241, value loss = 0.21691028773784637\n",
      "INFO 2024-12-04 18:23:33 pipeline.py:712] Training Step 20960: Policy loss = 1.5271356105804443, value loss = 0.24191413819789886\n",
      "INFO 2024-12-04 18:23:42 pipeline.py:712] Training Step 20980: Policy loss = 1.5492899417877197, value loss = 0.2481175661087036\n",
      "INFO 2024-12-04 18:23:52 pipeline.py:712] Training Step 21000: Policy loss = 1.4857103824615479, value loss = 0.21271805465221405\n",
      "INFO 2024-12-04 18:24:02 pipeline.py:712] Training Step 21020: Policy loss = 1.5333904027938843, value loss = 0.22923707962036133\n",
      "INFO 2024-12-04 18:24:11 pipeline.py:712] Training Step 21040: Policy loss = 1.5449094772338867, value loss = 0.23442621529102325\n",
      "INFO 2024-12-04 18:24:21 pipeline.py:712] Training Step 21060: Policy loss = 1.514823079109192, value loss = 0.23813720047473907\n",
      "INFO 2024-12-04 18:24:31 pipeline.py:712] Training Step 21080: Policy loss = 1.572538137435913, value loss = 0.21211251616477966\n",
      "INFO 2024-12-04 18:24:40 pipeline.py:712] Training Step 21100: Policy loss = 1.514799952507019, value loss = 0.21647796034812927\n",
      "INFO 2024-12-04 18:24:50 pipeline.py:712] Training Step 21120: Policy loss = 1.6182770729064941, value loss = 0.2402227818965912\n",
      "INFO 2024-12-04 18:24:59 pipeline.py:712] Training Step 21140: Policy loss = 1.418081283569336, value loss = 0.22699901461601257\n",
      "INFO 2024-12-04 18:25:09 pipeline.py:712] Training Step 21160: Policy loss = 1.5495147705078125, value loss = 0.21745799481868744\n",
      "INFO 2024-12-04 18:25:19 pipeline.py:712] Training Step 21180: Policy loss = 1.5004589557647705, value loss = 0.2065315842628479\n",
      "INFO 2024-12-04 18:25:28 pipeline.py:712] Training Step 21200: Policy loss = 1.6180737018585205, value loss = 0.2161329984664917\n",
      "INFO 2024-12-04 18:25:38 pipeline.py:712] Training Step 21220: Policy loss = 1.5407092571258545, value loss = 0.22759434580802917\n",
      "INFO 2024-12-04 18:25:47 pipeline.py:712] Training Step 21240: Policy loss = 1.6281540393829346, value loss = 0.19386595487594604\n",
      "INFO 2024-12-04 18:25:57 pipeline.py:712] Training Step 21260: Policy loss = 1.4736427068710327, value loss = 0.2629775404930115\n",
      "INFO 2024-12-04 18:26:07 pipeline.py:712] Training Step 21280: Policy loss = 1.5735125541687012, value loss = 0.23671986162662506\n",
      "INFO 2024-12-04 18:26:32 pipeline.py:738] training_steps 21296: Validation loss: Poliy loss 1.8480336656335925, value_loss 0.4427579208964207\n",
      "INFO 2024-12-04 18:26:34 pipeline.py:712] Training Step 21300: Policy loss = 1.5074336528778076, value loss = 0.2055038958787918\n",
      "INFO 2024-12-04 18:26:44 pipeline.py:712] Training Step 21320: Policy loss = 1.55897855758667, value loss = 0.21018028259277344\n",
      "INFO 2024-12-04 18:26:53 pipeline.py:712] Training Step 21340: Policy loss = 1.5744731426239014, value loss = 0.20333941280841827\n",
      "INFO 2024-12-04 18:27:03 pipeline.py:712] Training Step 21360: Policy loss = 1.545153021812439, value loss = 0.20437827706336975\n",
      "INFO 2024-12-04 18:27:13 pipeline.py:712] Training Step 21380: Policy loss = 1.5091700553894043, value loss = 0.24649594724178314\n",
      "INFO 2024-12-04 18:27:22 pipeline.py:712] Training Step 21400: Policy loss = 1.6326625347137451, value loss = 0.21220172941684723\n",
      "INFO 2024-12-04 18:27:32 pipeline.py:712] Training Step 21420: Policy loss = 1.5664091110229492, value loss = 0.22829914093017578\n",
      "INFO 2024-12-04 18:27:42 pipeline.py:712] Training Step 21440: Policy loss = 1.5749154090881348, value loss = 0.26330819725990295\n",
      "INFO 2024-12-04 18:27:51 pipeline.py:712] Training Step 21460: Policy loss = 1.621725082397461, value loss = 0.23613864183425903\n",
      "INFO 2024-12-04 18:28:01 pipeline.py:712] Training Step 21480: Policy loss = 1.5625131130218506, value loss = 0.24596524238586426\n",
      "INFO 2024-12-04 18:28:10 pipeline.py:712] Training Step 21500: Policy loss = 1.5771702527999878, value loss = 0.24098122119903564\n",
      "INFO 2024-12-04 18:28:20 pipeline.py:712] Training Step 21520: Policy loss = 1.5015722513198853, value loss = 0.2337610423564911\n",
      "INFO 2024-12-04 18:28:30 pipeline.py:712] Training Step 21540: Policy loss = 1.5412873029708862, value loss = 0.20083260536193848\n",
      "INFO 2024-12-04 18:28:39 pipeline.py:712] Training Step 21560: Policy loss = 1.5301392078399658, value loss = 0.23044714331626892\n",
      "INFO 2024-12-04 18:28:49 pipeline.py:712] Training Step 21580: Policy loss = 1.5748403072357178, value loss = 0.22880448400974274\n",
      "INFO 2024-12-04 18:28:58 pipeline.py:712] Training Step 21600: Policy loss = 1.5847594738006592, value loss = 0.218144029378891\n",
      "INFO 2024-12-04 18:29:08 pipeline.py:712] Training Step 21620: Policy loss = 1.4354783296585083, value loss = 0.23851540684700012\n",
      "INFO 2024-12-04 18:29:18 pipeline.py:712] Training Step 21640: Policy loss = 1.530197024345398, value loss = 0.23904764652252197\n",
      "INFO 2024-12-04 18:29:27 pipeline.py:712] Training Step 21660: Policy loss = 1.5178511142730713, value loss = 0.20661962032318115\n",
      "INFO 2024-12-04 18:29:37 pipeline.py:712] Training Step 21680: Policy loss = 1.5724527835845947, value loss = 0.23792384564876556\n",
      "INFO 2024-12-04 18:29:46 pipeline.py:712] Training Step 21700: Policy loss = 1.6071066856384277, value loss = 0.22717753052711487\n",
      "INFO 2024-12-04 18:29:56 pipeline.py:712] Training Step 21720: Policy loss = 1.5505295991897583, value loss = 0.2184288501739502\n",
      "INFO 2024-12-04 18:30:06 pipeline.py:712] Training Step 21740: Policy loss = 1.545518398284912, value loss = 0.243729829788208\n",
      "INFO 2024-12-04 18:30:15 pipeline.py:712] Training Step 21760: Policy loss = 1.5728402137756348, value loss = 0.22414520382881165\n",
      "INFO 2024-12-04 18:30:25 pipeline.py:712] Training Step 21780: Policy loss = 1.4580715894699097, value loss = 0.22924111783504486\n",
      "INFO 2024-12-04 18:30:43 pipeline.py:738] training_steps 21780: Validation loss: Poliy loss 1.8488376267620774, value_loss 0.4429215415090811\n",
      "INFO 2024-12-04 18:30:52 pipeline.py:712] Training Step 21800: Policy loss = 1.5774959325790405, value loss = 0.21509909629821777\n",
      "INFO 2024-12-04 18:31:02 pipeline.py:712] Training Step 21820: Policy loss = 1.5837886333465576, value loss = 0.21855959296226501\n",
      "INFO 2024-12-04 18:31:12 pipeline.py:712] Training Step 21840: Policy loss = 1.5050920248031616, value loss = 0.21791449189186096\n",
      "INFO 2024-12-04 18:31:21 pipeline.py:712] Training Step 21860: Policy loss = 1.4852511882781982, value loss = 0.2362552434206009\n",
      "INFO 2024-12-04 18:31:31 pipeline.py:712] Training Step 21880: Policy loss = 1.5506855249404907, value loss = 0.22798696160316467\n",
      "INFO 2024-12-04 18:31:41 pipeline.py:712] Training Step 21900: Policy loss = 1.4437780380249023, value loss = 0.2273859679698944\n",
      "INFO 2024-12-04 18:31:50 pipeline.py:712] Training Step 21920: Policy loss = 1.5231702327728271, value loss = 0.20235979557037354\n",
      "INFO 2024-12-04 18:32:00 pipeline.py:712] Training Step 21940: Policy loss = 1.631854772567749, value loss = 0.23866765201091766\n",
      "INFO 2024-12-04 18:32:09 pipeline.py:712] Training Step 21960: Policy loss = 1.5527164936065674, value loss = 0.2538670301437378\n",
      "INFO 2024-12-04 18:32:19 pipeline.py:712] Training Step 21980: Policy loss = 1.5242401361465454, value loss = 0.22217929363250732\n",
      "INFO 2024-12-04 18:32:29 pipeline.py:712] Training Step 22000: Policy loss = 1.500361680984497, value loss = 0.22858020663261414\n",
      "INFO 2024-12-04 18:32:38 pipeline.py:712] Training Step 22020: Policy loss = 1.5523828268051147, value loss = 0.22854483127593994\n",
      "INFO 2024-12-04 18:32:48 pipeline.py:712] Training Step 22040: Policy loss = 1.4921215772628784, value loss = 0.20575614273548126\n",
      "INFO 2024-12-04 18:32:57 pipeline.py:712] Training Step 22060: Policy loss = 1.5039992332458496, value loss = 0.22284138202667236\n",
      "INFO 2024-12-04 18:33:07 pipeline.py:712] Training Step 22080: Policy loss = 1.611298680305481, value loss = 0.20837977528572083\n",
      "INFO 2024-12-04 18:33:17 pipeline.py:712] Training Step 22100: Policy loss = 1.4977152347564697, value loss = 0.2511553168296814\n",
      "INFO 2024-12-04 18:33:26 pipeline.py:712] Training Step 22120: Policy loss = 1.5237051248550415, value loss = 0.27489060163497925\n",
      "INFO 2024-12-04 18:33:36 pipeline.py:712] Training Step 22140: Policy loss = 1.551086187362671, value loss = 0.270018607378006\n",
      "INFO 2024-12-04 18:33:46 pipeline.py:712] Training Step 22160: Policy loss = 1.5169715881347656, value loss = 0.23672504723072052\n",
      "INFO 2024-12-04 18:33:55 pipeline.py:712] Training Step 22180: Policy loss = 1.5502973794937134, value loss = 0.20503276586532593\n",
      "INFO 2024-12-04 18:34:05 pipeline.py:712] Training Step 22200: Policy loss = 1.5037901401519775, value loss = 0.22299766540527344\n",
      "INFO 2024-12-04 18:34:14 pipeline.py:712] Training Step 22220: Policy loss = 1.4584938287734985, value loss = 0.2501809000968933\n",
      "INFO 2024-12-04 18:34:24 pipeline.py:712] Training Step 22240: Policy loss = 1.4816852807998657, value loss = 0.2506885528564453\n",
      "INFO 2024-12-04 18:34:34 pipeline.py:712] Training Step 22260: Policy loss = 1.5362558364868164, value loss = 0.18093577027320862\n",
      "INFO 2024-12-04 18:34:53 pipeline.py:738] training_steps 22264: Validation loss: Poliy loss 1.8484057383459123, value_loss 0.4430273443949027\n",
      "INFO 2024-12-04 18:35:01 pipeline.py:712] Training Step 22280: Policy loss = 1.5977625846862793, value loss = 0.23263448476791382\n",
      "INFO 2024-12-04 18:35:11 pipeline.py:712] Training Step 22300: Policy loss = 1.5806553363800049, value loss = 0.19948340952396393\n",
      "INFO 2024-12-04 18:35:20 pipeline.py:712] Training Step 22320: Policy loss = 1.5455129146575928, value loss = 0.20330765843391418\n",
      "INFO 2024-12-04 18:35:30 pipeline.py:712] Training Step 22340: Policy loss = 1.5281121730804443, value loss = 0.24336975812911987\n",
      "INFO 2024-12-04 18:35:40 pipeline.py:712] Training Step 22360: Policy loss = 1.4876341819763184, value loss = 0.2711884379386902\n",
      "INFO 2024-12-04 18:35:49 pipeline.py:712] Training Step 22380: Policy loss = 1.5327727794647217, value loss = 0.23071855306625366\n",
      "INFO 2024-12-04 18:35:59 pipeline.py:712] Training Step 22400: Policy loss = 1.5508008003234863, value loss = 0.19374896585941315\n",
      "INFO 2024-12-04 18:36:08 pipeline.py:712] Training Step 22420: Policy loss = 1.5178818702697754, value loss = 0.23959346115589142\n",
      "INFO 2024-12-04 18:36:18 pipeline.py:712] Training Step 22440: Policy loss = 1.505965232849121, value loss = 0.21135227382183075\n",
      "INFO 2024-12-04 18:36:28 pipeline.py:712] Training Step 22460: Policy loss = 1.5984387397766113, value loss = 0.21598097681999207\n",
      "INFO 2024-12-04 18:36:37 pipeline.py:712] Training Step 22480: Policy loss = 1.4461015462875366, value loss = 0.21914155781269073\n",
      "INFO 2024-12-04 18:36:47 pipeline.py:712] Training Step 22500: Policy loss = 1.4971593618392944, value loss = 0.2065420150756836\n",
      "INFO 2024-12-04 18:36:56 pipeline.py:712] Training Step 22520: Policy loss = 1.5353535413742065, value loss = 0.23121559619903564\n",
      "INFO 2024-12-04 18:37:06 pipeline.py:712] Training Step 22540: Policy loss = 1.490356206893921, value loss = 0.23627668619155884\n",
      "INFO 2024-12-04 18:37:16 pipeline.py:712] Training Step 22560: Policy loss = 1.5162444114685059, value loss = 0.21221816539764404\n",
      "INFO 2024-12-04 18:37:25 pipeline.py:712] Training Step 22580: Policy loss = 1.501160979270935, value loss = 0.2441292107105255\n",
      "INFO 2024-12-04 18:37:35 pipeline.py:712] Training Step 22600: Policy loss = 1.5159327983856201, value loss = 0.21821147203445435\n",
      "INFO 2024-12-04 18:37:44 pipeline.py:712] Training Step 22620: Policy loss = 1.6934819221496582, value loss = 0.2250325083732605\n",
      "INFO 2024-12-04 18:37:54 pipeline.py:712] Training Step 22640: Policy loss = 1.5314321517944336, value loss = 0.23340383172035217\n",
      "INFO 2024-12-04 18:38:04 pipeline.py:712] Training Step 22660: Policy loss = 1.5179203748703003, value loss = 0.22665706276893616\n",
      "INFO 2024-12-04 18:38:13 pipeline.py:712] Training Step 22680: Policy loss = 1.4500343799591064, value loss = 0.2454579472541809\n",
      "INFO 2024-12-04 18:38:23 pipeline.py:712] Training Step 22700: Policy loss = 1.5859163999557495, value loss = 0.2354646623134613\n",
      "INFO 2024-12-04 18:38:33 pipeline.py:712] Training Step 22720: Policy loss = 1.512778878211975, value loss = 0.2180740237236023\n",
      "INFO 2024-12-04 18:38:42 pipeline.py:712] Training Step 22740: Policy loss = 1.4424221515655518, value loss = 0.2320232391357422\n",
      "INFO 2024-12-04 18:39:04 pipeline.py:738] training_steps 22748: Validation loss: Poliy loss 1.8500956736627172, value_loss 0.44333923840131917\n",
      "INFO 2024-12-04 18:39:10 pipeline.py:712] Training Step 22760: Policy loss = 1.4416391849517822, value loss = 0.21849089860916138\n",
      "INFO 2024-12-04 18:39:19 pipeline.py:712] Training Step 22780: Policy loss = 1.524874210357666, value loss = 0.2076224684715271\n",
      "INFO 2024-12-04 18:39:29 pipeline.py:712] Training Step 22800: Policy loss = 1.4736320972442627, value loss = 0.22973936796188354\n",
      "INFO 2024-12-04 18:39:39 pipeline.py:712] Training Step 22820: Policy loss = 1.49270498752594, value loss = 0.21238973736763\n",
      "INFO 2024-12-04 18:39:49 pipeline.py:712] Training Step 22840: Policy loss = 1.5573294162750244, value loss = 0.23493343591690063\n",
      "INFO 2024-12-04 18:39:58 pipeline.py:712] Training Step 22860: Policy loss = 1.4931275844573975, value loss = 0.22962641716003418\n",
      "INFO 2024-12-04 18:40:08 pipeline.py:712] Training Step 22880: Policy loss = 1.532425880432129, value loss = 0.24392321705818176\n",
      "INFO 2024-12-04 18:40:18 pipeline.py:712] Training Step 22900: Policy loss = 1.5265368223190308, value loss = 0.21697233617305756\n",
      "INFO 2024-12-04 18:40:27 pipeline.py:712] Training Step 22920: Policy loss = 1.5579346418380737, value loss = 0.20367050170898438\n",
      "INFO 2024-12-04 18:40:37 pipeline.py:712] Training Step 22940: Policy loss = 1.4665749073028564, value loss = 0.23695111274719238\n",
      "INFO 2024-12-04 18:40:47 pipeline.py:712] Training Step 22960: Policy loss = 1.5171618461608887, value loss = 0.2134416401386261\n",
      "INFO 2024-12-04 18:40:57 pipeline.py:712] Training Step 22980: Policy loss = 1.5418038368225098, value loss = 0.24284879863262177\n",
      "INFO 2024-12-04 18:41:06 pipeline.py:712] Training Step 23000: Policy loss = 1.5512332916259766, value loss = 0.22763510048389435\n",
      "INFO 2024-12-04 18:41:16 pipeline.py:712] Training Step 23020: Policy loss = 1.6915473937988281, value loss = 0.20204518735408783\n",
      "INFO 2024-12-04 18:41:26 pipeline.py:712] Training Step 23040: Policy loss = 1.505542278289795, value loss = 0.20994332432746887\n",
      "INFO 2024-12-04 18:41:36 pipeline.py:712] Training Step 23060: Policy loss = 1.4753284454345703, value loss = 0.22258004546165466\n",
      "INFO 2024-12-04 18:41:45 pipeline.py:712] Training Step 23080: Policy loss = 1.5292577743530273, value loss = 0.26519984006881714\n",
      "INFO 2024-12-04 18:41:55 pipeline.py:712] Training Step 23100: Policy loss = 1.457535982131958, value loss = 0.22242110967636108\n",
      "INFO 2024-12-04 18:42:05 pipeline.py:712] Training Step 23120: Policy loss = 1.546949863433838, value loss = 0.22908200323581696\n",
      "INFO 2024-12-04 18:42:14 pipeline.py:712] Training Step 23140: Policy loss = 1.4198951721191406, value loss = 0.24231469631195068\n",
      "INFO 2024-12-04 18:42:24 pipeline.py:712] Training Step 23160: Policy loss = 1.574026346206665, value loss = 0.23359280824661255\n",
      "INFO 2024-12-04 18:42:34 pipeline.py:712] Training Step 23180: Policy loss = 1.5139529705047607, value loss = 0.22587867081165314\n",
      "INFO 2024-12-04 18:42:44 pipeline.py:712] Training Step 23200: Policy loss = 1.556272268295288, value loss = 0.19694845378398895\n",
      "INFO 2024-12-04 18:42:53 pipeline.py:712] Training Step 23220: Policy loss = 1.430803656578064, value loss = 0.21861642599105835\n",
      "INFO 2024-12-04 18:43:17 pipeline.py:738] training_steps 23232: Validation loss: Poliy loss 1.849854998901242, value_loss 0.44395242631435394\n",
      "INFO 2024-12-04 18:43:21 pipeline.py:712] Training Step 23240: Policy loss = 1.4322178363800049, value loss = 0.20842282474040985\n",
      "INFO 2024-12-04 18:43:31 pipeline.py:712] Training Step 23260: Policy loss = 1.5867600440979004, value loss = 0.23839470744132996\n",
      "INFO 2024-12-04 18:43:40 pipeline.py:712] Training Step 23280: Policy loss = 1.4996010065078735, value loss = 0.24253743886947632\n",
      "INFO 2024-12-04 18:43:50 pipeline.py:712] Training Step 23300: Policy loss = 1.43513822555542, value loss = 0.2219034731388092\n",
      "INFO 2024-12-04 18:44:00 pipeline.py:712] Training Step 23320: Policy loss = 1.4873507022857666, value loss = 0.24576891958713531\n",
      "INFO 2024-12-04 18:44:10 pipeline.py:712] Training Step 23340: Policy loss = 1.5104303359985352, value loss = 0.25218507647514343\n",
      "INFO 2024-12-04 18:44:19 pipeline.py:712] Training Step 23360: Policy loss = 1.54256010055542, value loss = 0.21187599003314972\n",
      "INFO 2024-12-04 18:44:29 pipeline.py:712] Training Step 23380: Policy loss = 1.5621469020843506, value loss = 0.19653403759002686\n",
      "INFO 2024-12-04 18:44:38 pipeline.py:712] Training Step 23400: Policy loss = 1.5405685901641846, value loss = 0.22611691057682037\n",
      "INFO 2024-12-04 18:44:48 pipeline.py:712] Training Step 23420: Policy loss = 1.5174319744110107, value loss = 0.20200125873088837\n",
      "INFO 2024-12-04 18:44:58 pipeline.py:712] Training Step 23440: Policy loss = 1.5721855163574219, value loss = 0.2155921757221222\n",
      "INFO 2024-12-04 18:45:08 pipeline.py:712] Training Step 23460: Policy loss = 1.5686397552490234, value loss = 0.2219553291797638\n",
      "INFO 2024-12-04 18:45:17 pipeline.py:712] Training Step 23480: Policy loss = 1.5923362970352173, value loss = 0.2194497287273407\n",
      "INFO 2024-12-04 18:45:27 pipeline.py:712] Training Step 23500: Policy loss = 1.4939446449279785, value loss = 0.23597308993339539\n",
      "INFO 2024-12-04 18:45:37 pipeline.py:712] Training Step 23520: Policy loss = 1.497621774673462, value loss = 0.19176214933395386\n",
      "INFO 2024-12-04 18:45:47 pipeline.py:712] Training Step 23540: Policy loss = 1.4970730543136597, value loss = 0.21908476948738098\n",
      "INFO 2024-12-04 18:45:56 pipeline.py:712] Training Step 23560: Policy loss = 1.6014883518218994, value loss = 0.2376519739627838\n",
      "INFO 2024-12-04 18:46:06 pipeline.py:712] Training Step 23580: Policy loss = 1.4684112071990967, value loss = 0.22157607972621918\n",
      "INFO 2024-12-04 18:46:16 pipeline.py:712] Training Step 23600: Policy loss = 1.5805784463882446, value loss = 0.19710445404052734\n",
      "INFO 2024-12-04 18:46:25 pipeline.py:712] Training Step 23620: Policy loss = 1.518333077430725, value loss = 0.21525511145591736\n",
      "INFO 2024-12-04 18:46:35 pipeline.py:712] Training Step 23640: Policy loss = 1.4891914129257202, value loss = 0.23876261711120605\n",
      "INFO 2024-12-04 18:46:45 pipeline.py:712] Training Step 23660: Policy loss = 1.529602289199829, value loss = 0.20220011472702026\n",
      "INFO 2024-12-04 18:46:55 pipeline.py:712] Training Step 23680: Policy loss = 1.4736672639846802, value loss = 0.22832415997982025\n",
      "INFO 2024-12-04 18:47:04 pipeline.py:712] Training Step 23700: Policy loss = 1.5844848155975342, value loss = 0.22918379306793213\n",
      "INFO 2024-12-04 18:47:30 pipeline.py:738] training_steps 23716: Validation loss: Poliy loss 1.850201316544267, value_loss 0.4433759240830531\n",
      "INFO 2024-12-04 18:47:32 pipeline.py:712] Training Step 23720: Policy loss = 1.4725521802902222, value loss = 0.1940779983997345\n",
      "INFO 2024-12-04 18:47:42 pipeline.py:712] Training Step 23740: Policy loss = 1.445479154586792, value loss = 0.2429232895374298\n",
      "INFO 2024-12-04 18:47:51 pipeline.py:712] Training Step 23760: Policy loss = 1.4391497373580933, value loss = 0.225242018699646\n",
      "INFO 2024-12-04 18:48:01 pipeline.py:712] Training Step 23780: Policy loss = 1.4591073989868164, value loss = 0.23718637228012085\n",
      "INFO 2024-12-04 18:48:11 pipeline.py:712] Training Step 23800: Policy loss = 1.4613215923309326, value loss = 0.22293022274971008\n",
      "INFO 2024-12-04 18:48:20 pipeline.py:712] Training Step 23820: Policy loss = 1.5019264221191406, value loss = 0.24153673648834229\n",
      "INFO 2024-12-04 18:48:30 pipeline.py:712] Training Step 23840: Policy loss = 1.5585908889770508, value loss = 0.1829259991645813\n",
      "INFO 2024-12-04 18:48:40 pipeline.py:712] Training Step 23860: Policy loss = 1.5602744817733765, value loss = 0.21108794212341309\n",
      "INFO 2024-12-04 18:48:49 pipeline.py:712] Training Step 23880: Policy loss = 1.5982400178909302, value loss = 0.21060776710510254\n",
      "INFO 2024-12-04 18:48:59 pipeline.py:712] Training Step 23900: Policy loss = 1.5380831956863403, value loss = 0.19973012804985046\n",
      "INFO 2024-12-04 18:49:09 pipeline.py:712] Training Step 23920: Policy loss = 1.4541850090026855, value loss = 0.22358793020248413\n",
      "INFO 2024-12-04 18:49:19 pipeline.py:712] Training Step 23940: Policy loss = 1.5658023357391357, value loss = 0.21483151614665985\n",
      "INFO 2024-12-04 18:49:28 pipeline.py:712] Training Step 23960: Policy loss = 1.5133042335510254, value loss = 0.2521526515483856\n",
      "INFO 2024-12-04 18:49:38 pipeline.py:712] Training Step 23980: Policy loss = 1.5811824798583984, value loss = 0.23091529309749603\n",
      "INFO 2024-12-04 18:49:47 pipeline.py:712] Training Step 24000: Policy loss = 1.5014822483062744, value loss = 0.20641791820526123\n",
      "INFO 2024-12-04 18:49:57 pipeline.py:712] Training Step 24020: Policy loss = 1.446777582168579, value loss = 0.2426445484161377\n",
      "INFO 2024-12-04 18:50:07 pipeline.py:712] Training Step 24040: Policy loss = 1.5673171281814575, value loss = 0.2062368541955948\n",
      "INFO 2024-12-04 18:50:17 pipeline.py:712] Training Step 24060: Policy loss = 1.5591604709625244, value loss = 0.22665980458259583\n",
      "INFO 2024-12-04 18:50:26 pipeline.py:712] Training Step 24080: Policy loss = 1.6176109313964844, value loss = 0.19565990567207336\n",
      "INFO 2024-12-04 18:50:36 pipeline.py:712] Training Step 24100: Policy loss = 1.4933876991271973, value loss = 0.22780153155326843\n",
      "INFO 2024-12-04 18:50:46 pipeline.py:712] Training Step 24120: Policy loss = 1.4888514280319214, value loss = 0.2414504587650299\n",
      "INFO 2024-12-04 18:50:56 pipeline.py:712] Training Step 24140: Policy loss = 1.6518511772155762, value loss = 0.23008793592453003\n",
      "INFO 2024-12-04 18:51:05 pipeline.py:712] Training Step 24160: Policy loss = 1.488100290298462, value loss = 0.22300715744495392\n",
      "INFO 2024-12-04 18:51:15 pipeline.py:712] Training Step 24180: Policy loss = 1.509763479232788, value loss = 0.23712322115898132\n",
      "INFO 2024-12-04 18:51:24 pipeline.py:712] Training Step 24200: Policy loss = 1.476407527923584, value loss = 0.2654893398284912\n",
      "INFO 2024-12-04 18:51:42 pipeline.py:738] training_steps 24200: Validation loss: Poliy loss 1.8508789627278437, value_loss 0.4446391517021617\n",
      "INFO 2024-12-04 18:51:52 pipeline.py:712] Training Step 24220: Policy loss = 1.5543112754821777, value loss = 0.23726525902748108\n",
      "INFO 2024-12-04 18:52:02 pipeline.py:712] Training Step 24240: Policy loss = 1.4925802946090698, value loss = 0.217439204454422\n",
      "INFO 2024-12-04 18:52:12 pipeline.py:712] Training Step 24260: Policy loss = 1.5738461017608643, value loss = 0.2363879382610321\n",
      "INFO 2024-12-04 18:52:21 pipeline.py:712] Training Step 24280: Policy loss = 1.491288185119629, value loss = 0.22057947516441345\n",
      "INFO 2024-12-04 18:52:31 pipeline.py:712] Training Step 24300: Policy loss = 1.506375789642334, value loss = 0.21760183572769165\n",
      "INFO 2024-12-04 18:52:41 pipeline.py:712] Training Step 24320: Policy loss = 1.626701831817627, value loss = 0.22741833329200745\n",
      "INFO 2024-12-04 18:52:50 pipeline.py:712] Training Step 24340: Policy loss = 1.5574009418487549, value loss = 0.21853236854076385\n",
      "INFO 2024-12-04 18:53:00 pipeline.py:712] Training Step 24360: Policy loss = 1.5206366777420044, value loss = 0.22501090168952942\n",
      "INFO 2024-12-04 18:53:10 pipeline.py:712] Training Step 24380: Policy loss = 1.4550539255142212, value loss = 0.24379201233386993\n",
      "INFO 2024-12-04 18:53:19 pipeline.py:712] Training Step 24400: Policy loss = 1.5193159580230713, value loss = 0.1988903284072876\n",
      "INFO 2024-12-04 18:53:29 pipeline.py:712] Training Step 24420: Policy loss = 1.5737268924713135, value loss = 0.2226816862821579\n",
      "INFO 2024-12-04 18:53:39 pipeline.py:712] Training Step 24440: Policy loss = 1.475085973739624, value loss = 0.23731191456317902\n",
      "INFO 2024-12-04 18:53:48 pipeline.py:712] Training Step 24460: Policy loss = 1.4636428356170654, value loss = 0.2191292941570282\n",
      "INFO 2024-12-04 18:53:58 pipeline.py:712] Training Step 24480: Policy loss = 1.4917503595352173, value loss = 0.22577571868896484\n",
      "INFO 2024-12-04 18:54:08 pipeline.py:712] Training Step 24500: Policy loss = 1.5064104795455933, value loss = 0.22764045000076294\n",
      "INFO 2024-12-04 18:54:18 pipeline.py:712] Training Step 24520: Policy loss = 1.599982738494873, value loss = 0.2186480015516281\n",
      "INFO 2024-12-04 18:54:27 pipeline.py:712] Training Step 24540: Policy loss = 1.5243513584136963, value loss = 0.2607666850090027\n",
      "INFO 2024-12-04 18:54:37 pipeline.py:712] Training Step 24560: Policy loss = 1.526495337486267, value loss = 0.23646429181098938\n",
      "INFO 2024-12-04 18:54:47 pipeline.py:712] Training Step 24580: Policy loss = 1.5996325016021729, value loss = 0.21480998396873474\n",
      "INFO 2024-12-04 18:54:56 pipeline.py:712] Training Step 24600: Policy loss = 1.5218784809112549, value loss = 0.19406558573246002\n",
      "INFO 2024-12-04 18:55:06 pipeline.py:712] Training Step 24620: Policy loss = 1.6220152378082275, value loss = 0.2511388659477234\n",
      "INFO 2024-12-04 18:55:16 pipeline.py:712] Training Step 24640: Policy loss = 1.5270130634307861, value loss = 0.23727500438690186\n",
      "INFO 2024-12-04 18:55:26 pipeline.py:712] Training Step 24660: Policy loss = 1.5300177335739136, value loss = 0.2295878827571869\n",
      "INFO 2024-12-04 18:55:35 pipeline.py:712] Training Step 24680: Policy loss = 1.5199472904205322, value loss = 0.18905270099639893\n",
      "INFO 2024-12-04 18:55:55 pipeline.py:738] training_steps 24684: Validation loss: Poliy loss 1.850683566976766, value_loss 0.4440316098635314\n",
      "INFO 2024-12-04 18:56:03 pipeline.py:712] Training Step 24700: Policy loss = 1.4832420349121094, value loss = 0.21738050878047943\n",
      "INFO 2024-12-04 18:56:12 pipeline.py:712] Training Step 24720: Policy loss = 1.5124092102050781, value loss = 0.21494829654693604\n",
      "INFO 2024-12-04 18:56:22 pipeline.py:712] Training Step 24740: Policy loss = 1.522428274154663, value loss = 0.20139119029045105\n",
      "INFO 2024-12-04 18:56:32 pipeline.py:712] Training Step 24760: Policy loss = 1.583482027053833, value loss = 0.22524140775203705\n",
      "INFO 2024-12-04 18:56:42 pipeline.py:712] Training Step 24780: Policy loss = 1.4299612045288086, value loss = 0.23153559863567352\n",
      "INFO 2024-12-04 18:56:51 pipeline.py:712] Training Step 24800: Policy loss = 1.5101323127746582, value loss = 0.2050444334745407\n",
      "INFO 2024-12-04 18:57:01 pipeline.py:712] Training Step 24820: Policy loss = 1.493206262588501, value loss = 0.21025501191616058\n",
      "INFO 2024-12-04 18:57:11 pipeline.py:712] Training Step 24840: Policy loss = 1.5300838947296143, value loss = 0.24475619196891785\n",
      "INFO 2024-12-04 18:57:21 pipeline.py:712] Training Step 24860: Policy loss = 1.502526044845581, value loss = 0.2172066569328308\n",
      "INFO 2024-12-04 18:57:30 pipeline.py:712] Training Step 24880: Policy loss = 1.5558797121047974, value loss = 0.20888930559158325\n",
      "INFO 2024-12-04 18:57:40 pipeline.py:712] Training Step 24900: Policy loss = 1.567704677581787, value loss = 0.26456403732299805\n",
      "INFO 2024-12-04 18:57:50 pipeline.py:712] Training Step 24920: Policy loss = 1.5606740713119507, value loss = 0.2331325113773346\n",
      "INFO 2024-12-04 18:57:59 pipeline.py:712] Training Step 24940: Policy loss = 1.5051690340042114, value loss = 0.24977640807628632\n",
      "INFO 2024-12-04 18:58:09 pipeline.py:712] Training Step 24960: Policy loss = 1.480087399482727, value loss = 0.220490500330925\n",
      "INFO 2024-12-04 18:58:19 pipeline.py:712] Training Step 24980: Policy loss = 1.5506277084350586, value loss = 0.20158171653747559\n",
      "INFO 2024-12-04 18:58:28 pipeline.py:712] Training Step 25000: Policy loss = 1.4874606132507324, value loss = 0.20287169516086578\n",
      "INFO 2024-12-04 18:58:38 pipeline.py:712] Training Step 25020: Policy loss = 1.5022660493850708, value loss = 0.20857740938663483\n",
      "INFO 2024-12-04 18:58:48 pipeline.py:712] Training Step 25040: Policy loss = 1.6239662170410156, value loss = 0.22310329973697662\n",
      "INFO 2024-12-04 18:58:57 pipeline.py:712] Training Step 25060: Policy loss = 1.4897148609161377, value loss = 0.2171487957239151\n",
      "INFO 2024-12-04 18:59:07 pipeline.py:712] Training Step 25080: Policy loss = 1.5827720165252686, value loss = 0.22336724400520325\n",
      "INFO 2024-12-04 18:59:17 pipeline.py:712] Training Step 25100: Policy loss = 1.5215885639190674, value loss = 0.22704371809959412\n",
      "INFO 2024-12-04 18:59:27 pipeline.py:712] Training Step 25120: Policy loss = 1.4556989669799805, value loss = 0.24152642488479614\n",
      "INFO 2024-12-04 18:59:36 pipeline.py:712] Training Step 25140: Policy loss = 1.497330904006958, value loss = 0.2246798723936081\n",
      "INFO 2024-12-04 18:59:46 pipeline.py:712] Training Step 25160: Policy loss = 1.564586877822876, value loss = 0.22831889986991882\n",
      "INFO 2024-12-04 19:00:08 pipeline.py:738] training_steps 25168: Validation loss: Poliy loss 1.8507341019442825, value_loss 0.44494657755875194\n",
      "INFO 2024-12-04 19:00:14 pipeline.py:712] Training Step 25180: Policy loss = 1.5686976909637451, value loss = 0.1773025393486023\n",
      "INFO 2024-12-04 19:00:23 pipeline.py:712] Training Step 25200: Policy loss = 1.498007893562317, value loss = 0.26102232933044434\n",
      "INFO 2024-12-04 19:00:33 pipeline.py:712] Training Step 25220: Policy loss = 1.5248398780822754, value loss = 0.21966411173343658\n",
      "INFO 2024-12-04 19:00:43 pipeline.py:712] Training Step 25240: Policy loss = 1.5442076921463013, value loss = 0.2245049625635147\n",
      "INFO 2024-12-04 19:00:52 pipeline.py:712] Training Step 25260: Policy loss = 1.5169190168380737, value loss = 0.21853885054588318\n",
      "INFO 2024-12-04 19:01:02 pipeline.py:712] Training Step 25280: Policy loss = 1.483081340789795, value loss = 0.20258474349975586\n",
      "INFO 2024-12-04 19:01:12 pipeline.py:712] Training Step 25300: Policy loss = 1.5270178318023682, value loss = 0.23231810331344604\n",
      "INFO 2024-12-04 19:01:21 pipeline.py:712] Training Step 25320: Policy loss = 1.5113698244094849, value loss = 0.2011079490184784\n",
      "INFO 2024-12-04 19:01:31 pipeline.py:712] Training Step 25340: Policy loss = 1.583652138710022, value loss = 0.22679436206817627\n",
      "INFO 2024-12-04 19:01:41 pipeline.py:712] Training Step 25360: Policy loss = 1.4840166568756104, value loss = 0.24556145071983337\n",
      "INFO 2024-12-04 19:01:51 pipeline.py:712] Training Step 25380: Policy loss = 1.5882874727249146, value loss = 0.2141995131969452\n",
      "INFO 2024-12-04 19:02:00 pipeline.py:712] Training Step 25400: Policy loss = 1.4322059154510498, value loss = 0.22650322318077087\n",
      "INFO 2024-12-04 19:02:10 pipeline.py:712] Training Step 25420: Policy loss = 1.5291986465454102, value loss = 0.23855765163898468\n",
      "INFO 2024-12-04 19:02:19 pipeline.py:712] Training Step 25440: Policy loss = 1.5412554740905762, value loss = 0.24194754660129547\n",
      "INFO 2024-12-04 19:02:29 pipeline.py:712] Training Step 25460: Policy loss = 1.494998574256897, value loss = 0.21215367317199707\n",
      "INFO 2024-12-04 19:02:39 pipeline.py:712] Training Step 25480: Policy loss = 1.5538194179534912, value loss = 0.21565739810466766\n",
      "INFO 2024-12-04 19:02:49 pipeline.py:712] Training Step 25500: Policy loss = 1.4733359813690186, value loss = 0.22206726670265198\n",
      "INFO 2024-12-04 19:02:58 pipeline.py:712] Training Step 25520: Policy loss = 1.5972365140914917, value loss = 0.21982747316360474\n",
      "INFO 2024-12-04 19:03:08 pipeline.py:712] Training Step 25540: Policy loss = 1.5457967519760132, value loss = 0.19849339127540588\n",
      "INFO 2024-12-04 19:03:18 pipeline.py:712] Training Step 25560: Policy loss = 1.5407780408859253, value loss = 0.23096224665641785\n",
      "INFO 2024-12-04 19:03:28 pipeline.py:712] Training Step 25580: Policy loss = 1.5634732246398926, value loss = 0.22511188685894012\n",
      "INFO 2024-12-04 19:03:37 pipeline.py:712] Training Step 25600: Policy loss = 1.5032711029052734, value loss = 0.22256377339363098\n",
      "INFO 2024-12-04 19:03:47 pipeline.py:712] Training Step 25620: Policy loss = 1.610201120376587, value loss = 0.2372959703207016\n",
      "INFO 2024-12-04 19:03:57 pipeline.py:712] Training Step 25640: Policy loss = 1.492081642150879, value loss = 0.19348087906837463\n",
      "INFO 2024-12-04 19:04:21 pipeline.py:738] training_steps 25652: Validation loss: Poliy loss 1.8511605165043816, value_loss 0.44519769656853597\n",
      "INFO 2024-12-04 19:04:25 pipeline.py:712] Training Step 25660: Policy loss = 1.5661386251449585, value loss = 0.23466181755065918\n",
      "INFO 2024-12-04 19:04:34 pipeline.py:712] Training Step 25680: Policy loss = 1.601452112197876, value loss = 0.24363481998443604\n",
      "INFO 2024-12-04 19:04:44 pipeline.py:712] Training Step 25700: Policy loss = 1.5857317447662354, value loss = 0.23142287135124207\n",
      "INFO 2024-12-04 19:04:54 pipeline.py:712] Training Step 25720: Policy loss = 1.5296070575714111, value loss = 0.22849540412425995\n",
      "INFO 2024-12-04 19:05:03 pipeline.py:712] Training Step 25740: Policy loss = 1.4500659704208374, value loss = 0.23742906749248505\n",
      "INFO 2024-12-04 19:05:13 pipeline.py:712] Training Step 25760: Policy loss = 1.5510149002075195, value loss = 0.22358916699886322\n",
      "INFO 2024-12-04 19:05:23 pipeline.py:712] Training Step 25780: Policy loss = 1.5360647439956665, value loss = 0.22347208857536316\n",
      "INFO 2024-12-04 19:05:32 pipeline.py:712] Training Step 25800: Policy loss = 1.4903271198272705, value loss = 0.23468148708343506\n",
      "INFO 2024-12-04 19:05:42 pipeline.py:712] Training Step 25820: Policy loss = 1.5639219284057617, value loss = 0.21743927896022797\n",
      "INFO 2024-12-04 19:05:52 pipeline.py:712] Training Step 25840: Policy loss = 1.4898924827575684, value loss = 0.20267151296138763\n",
      "INFO 2024-12-04 19:06:02 pipeline.py:712] Training Step 25860: Policy loss = 1.5543773174285889, value loss = 0.18654930591583252\n",
      "INFO 2024-12-04 19:06:11 pipeline.py:712] Training Step 25880: Policy loss = 1.6347284317016602, value loss = 0.2316734939813614\n",
      "INFO 2024-12-04 19:06:21 pipeline.py:712] Training Step 25900: Policy loss = 1.5046892166137695, value loss = 0.23586001992225647\n",
      "INFO 2024-12-04 19:06:31 pipeline.py:712] Training Step 25920: Policy loss = 1.5206938982009888, value loss = 0.24771398305892944\n",
      "INFO 2024-12-04 19:06:41 pipeline.py:712] Training Step 25940: Policy loss = 1.5158145427703857, value loss = 0.2393835484981537\n",
      "INFO 2024-12-04 19:06:50 pipeline.py:712] Training Step 25960: Policy loss = 1.4860801696777344, value loss = 0.2186969667673111\n",
      "INFO 2024-12-04 19:07:00 pipeline.py:712] Training Step 25980: Policy loss = 1.4854333400726318, value loss = 0.20306642353534698\n",
      "INFO 2024-12-04 19:07:10 pipeline.py:712] Training Step 26000: Policy loss = 1.5029079914093018, value loss = 0.22773827612400055\n",
      "INFO 2024-12-04 19:07:19 pipeline.py:712] Training Step 26020: Policy loss = 1.5348747968673706, value loss = 0.20940232276916504\n",
      "INFO 2024-12-04 19:07:29 pipeline.py:712] Training Step 26040: Policy loss = 1.5055644512176514, value loss = 0.21586094796657562\n",
      "INFO 2024-12-04 19:07:39 pipeline.py:712] Training Step 26060: Policy loss = 1.5627760887145996, value loss = 0.218852236866951\n",
      "INFO 2024-12-04 19:07:49 pipeline.py:712] Training Step 26080: Policy loss = 1.4795820713043213, value loss = 0.23101262748241425\n",
      "INFO 2024-12-04 19:07:58 pipeline.py:712] Training Step 26100: Policy loss = 1.5557222366333008, value loss = 0.22525516152381897\n",
      "INFO 2024-12-04 19:08:08 pipeline.py:712] Training Step 26120: Policy loss = 1.5948208570480347, value loss = 0.22192835807800293\n",
      "INFO 2024-12-04 19:08:34 pipeline.py:738] training_steps 26136: Validation loss: Poliy loss 1.8516652036885746, value_loss 0.44531373484212844\n",
      "INFO 2024-12-04 19:08:35 pipeline.py:712] Training Step 26140: Policy loss = 1.5670803785324097, value loss = 0.23595045506954193\n",
      "INFO 2024-12-04 19:08:45 pipeline.py:712] Training Step 26160: Policy loss = 1.5747413635253906, value loss = 0.2056131660938263\n",
      "INFO 2024-12-04 19:08:55 pipeline.py:712] Training Step 26180: Policy loss = 1.5166099071502686, value loss = 0.21349915862083435\n",
      "INFO 2024-12-04 19:09:05 pipeline.py:712] Training Step 26200: Policy loss = 1.519455909729004, value loss = 0.20872992277145386\n",
      "INFO 2024-12-04 19:09:14 pipeline.py:712] Training Step 26220: Policy loss = 1.442722201347351, value loss = 0.2086365520954132\n",
      "INFO 2024-12-04 19:09:24 pipeline.py:712] Training Step 26240: Policy loss = 1.5530519485473633, value loss = 0.22973372042179108\n",
      "INFO 2024-12-04 19:09:34 pipeline.py:712] Training Step 26260: Policy loss = 1.5020561218261719, value loss = 0.2299727201461792\n",
      "INFO 2024-12-04 19:09:43 pipeline.py:712] Training Step 26280: Policy loss = 1.5455641746520996, value loss = 0.24191702902317047\n",
      "INFO 2024-12-04 19:09:53 pipeline.py:712] Training Step 26300: Policy loss = 1.5181219577789307, value loss = 0.21832643449306488\n",
      "INFO 2024-12-04 19:10:03 pipeline.py:712] Training Step 26320: Policy loss = 1.5326968431472778, value loss = 0.23392091691493988\n",
      "INFO 2024-12-04 19:10:12 pipeline.py:712] Training Step 26340: Policy loss = 1.4329347610473633, value loss = 0.24616552889347076\n",
      "INFO 2024-12-04 19:10:22 pipeline.py:712] Training Step 26360: Policy loss = 1.6114388704299927, value loss = 0.22480016946792603\n",
      "INFO 2024-12-04 19:10:32 pipeline.py:712] Training Step 26380: Policy loss = 1.4870498180389404, value loss = 0.22592413425445557\n",
      "INFO 2024-12-04 19:10:41 pipeline.py:712] Training Step 26400: Policy loss = 1.5204877853393555, value loss = 0.2010767012834549\n",
      "INFO 2024-12-04 19:10:51 pipeline.py:712] Training Step 26420: Policy loss = 1.563513994216919, value loss = 0.2446354627609253\n",
      "INFO 2024-12-04 19:11:01 pipeline.py:712] Training Step 26440: Policy loss = 1.5162009000778198, value loss = 0.2048514485359192\n",
      "INFO 2024-12-04 19:11:11 pipeline.py:712] Training Step 26460: Policy loss = 1.5041468143463135, value loss = 0.2306867241859436\n",
      "INFO 2024-12-04 19:11:20 pipeline.py:712] Training Step 26480: Policy loss = 1.4546172618865967, value loss = 0.19964298605918884\n",
      "INFO 2024-12-04 19:11:30 pipeline.py:712] Training Step 26500: Policy loss = 1.5769524574279785, value loss = 0.23128151893615723\n",
      "INFO 2024-12-04 19:11:40 pipeline.py:712] Training Step 26520: Policy loss = 1.532485842704773, value loss = 0.20259547233581543\n",
      "INFO 2024-12-04 19:11:49 pipeline.py:712] Training Step 26540: Policy loss = 1.5466194152832031, value loss = 0.21697670221328735\n",
      "INFO 2024-12-04 19:11:59 pipeline.py:712] Training Step 26560: Policy loss = 1.5358233451843262, value loss = 0.20109151303768158\n",
      "INFO 2024-12-04 19:12:09 pipeline.py:712] Training Step 26580: Policy loss = 1.511554479598999, value loss = 0.2178059220314026\n",
      "INFO 2024-12-04 19:12:18 pipeline.py:712] Training Step 26600: Policy loss = 1.5590460300445557, value loss = 0.21742315590381622\n",
      "INFO 2024-12-04 19:12:28 pipeline.py:712] Training Step 26620: Policy loss = 1.625428557395935, value loss = 0.2014727145433426\n",
      "INFO 2024-12-04 19:12:46 pipeline.py:738] training_steps 26620: Validation loss: Poliy loss 1.8509242358754894, value_loss 0.44548646152996624\n",
      "INFO 2024-12-04 19:12:56 pipeline.py:712] Training Step 26640: Policy loss = 1.4843311309814453, value loss = 0.23360586166381836\n",
      "INFO 2024-12-04 19:13:06 pipeline.py:712] Training Step 26660: Policy loss = 1.4737014770507812, value loss = 0.21954773366451263\n",
      "INFO 2024-12-04 19:13:15 pipeline.py:712] Training Step 26680: Policy loss = 1.6273322105407715, value loss = 0.2074802815914154\n",
      "INFO 2024-12-04 19:13:25 pipeline.py:712] Training Step 26700: Policy loss = 1.5675833225250244, value loss = 0.22347936034202576\n",
      "INFO 2024-12-04 19:13:35 pipeline.py:712] Training Step 26720: Policy loss = 1.5780705213546753, value loss = 0.21782943606376648\n",
      "INFO 2024-12-04 19:13:44 pipeline.py:712] Training Step 26740: Policy loss = 1.5436214208602905, value loss = 0.22842353582382202\n",
      "INFO 2024-12-04 19:13:54 pipeline.py:712] Training Step 26760: Policy loss = 1.517026662826538, value loss = 0.22085076570510864\n",
      "INFO 2024-12-04 19:14:04 pipeline.py:712] Training Step 26780: Policy loss = 1.5431890487670898, value loss = 0.23349782824516296\n",
      "INFO 2024-12-04 19:14:14 pipeline.py:712] Training Step 26800: Policy loss = 1.4940214157104492, value loss = 0.19594338536262512\n",
      "INFO 2024-12-04 19:14:23 pipeline.py:712] Training Step 26820: Policy loss = 1.5291483402252197, value loss = 0.2390349954366684\n",
      "INFO 2024-12-04 19:14:33 pipeline.py:712] Training Step 26840: Policy loss = 1.5867570638656616, value loss = 0.2184683233499527\n",
      "INFO 2024-12-04 19:14:42 pipeline.py:712] Training Step 26860: Policy loss = 1.5815775394439697, value loss = 0.22587692737579346\n",
      "INFO 2024-12-04 19:14:52 pipeline.py:712] Training Step 26880: Policy loss = 1.4954630136489868, value loss = 0.19873367249965668\n",
      "INFO 2024-12-04 19:15:02 pipeline.py:712] Training Step 26900: Policy loss = 1.5964257717132568, value loss = 0.21870726346969604\n",
      "INFO 2024-12-04 19:15:12 pipeline.py:712] Training Step 26920: Policy loss = 1.546964406967163, value loss = 0.21042723953723907\n",
      "INFO 2024-12-04 19:15:21 pipeline.py:712] Training Step 26940: Policy loss = 1.5258358716964722, value loss = 0.2238973081111908\n",
      "INFO 2024-12-04 19:15:31 pipeline.py:712] Training Step 26960: Policy loss = 1.5692856311798096, value loss = 0.23489068448543549\n",
      "INFO 2024-12-04 19:15:41 pipeline.py:712] Training Step 26980: Policy loss = 1.5065712928771973, value loss = 0.1897328943014145\n",
      "INFO 2024-12-04 19:15:50 pipeline.py:712] Training Step 27000: Policy loss = 1.4956470727920532, value loss = 0.23206371068954468\n",
      "INFO 2024-12-04 19:16:00 pipeline.py:712] Training Step 27020: Policy loss = 1.5145606994628906, value loss = 0.21722286939620972\n",
      "INFO 2024-12-04 19:16:10 pipeline.py:712] Training Step 27040: Policy loss = 1.4934245347976685, value loss = 0.21728754043579102\n",
      "INFO 2024-12-04 19:16:19 pipeline.py:712] Training Step 27060: Policy loss = 1.5904507637023926, value loss = 0.20545251667499542\n",
      "INFO 2024-12-04 19:16:29 pipeline.py:712] Training Step 27080: Policy loss = 1.5138407945632935, value loss = 0.2102278172969818\n",
      "INFO 2024-12-04 19:16:39 pipeline.py:712] Training Step 27100: Policy loss = 1.5324110984802246, value loss = 0.2191513180732727\n",
      "INFO 2024-12-04 19:16:59 pipeline.py:738] training_steps 27104: Validation loss: Poliy loss 1.8514606610673372, value_loss 0.44594020066691226\n",
      "INFO 2024-12-04 19:17:06 pipeline.py:712] Training Step 27120: Policy loss = 1.5630817413330078, value loss = 0.20495036244392395\n",
      "INFO 2024-12-04 19:17:16 pipeline.py:712] Training Step 27140: Policy loss = 1.546074390411377, value loss = 0.20674069225788116\n",
      "INFO 2024-12-04 19:17:26 pipeline.py:712] Training Step 27160: Policy loss = 1.490436315536499, value loss = 0.22192518413066864\n",
      "INFO 2024-12-04 19:17:36 pipeline.py:712] Training Step 27180: Policy loss = 1.5006605386734009, value loss = 0.19410304725170135\n",
      "INFO 2024-12-04 19:17:45 pipeline.py:712] Training Step 27200: Policy loss = 1.5267410278320312, value loss = 0.19659744203090668\n",
      "INFO 2024-12-04 19:17:55 pipeline.py:712] Training Step 27220: Policy loss = 1.4357240200042725, value loss = 0.19036592543125153\n",
      "INFO 2024-12-04 19:18:05 pipeline.py:712] Training Step 27240: Policy loss = 1.485508680343628, value loss = 0.2198532074689865\n",
      "INFO 2024-12-04 19:18:14 pipeline.py:712] Training Step 27260: Policy loss = 1.5421037673950195, value loss = 0.228585347533226\n",
      "INFO 2024-12-04 19:18:24 pipeline.py:712] Training Step 27280: Policy loss = 1.4666574001312256, value loss = 0.21110260486602783\n",
      "INFO 2024-12-04 19:18:34 pipeline.py:712] Training Step 27300: Policy loss = 1.5068552494049072, value loss = 0.20830902457237244\n",
      "INFO 2024-12-04 19:18:43 pipeline.py:712] Training Step 27320: Policy loss = 1.4526761770248413, value loss = 0.21255019307136536\n",
      "INFO 2024-12-04 19:18:53 pipeline.py:712] Training Step 27340: Policy loss = 1.4807573556900024, value loss = 0.22912059724330902\n",
      "INFO 2024-12-04 19:19:03 pipeline.py:712] Training Step 27360: Policy loss = 1.4842884540557861, value loss = 0.23201435804367065\n",
      "INFO 2024-12-04 19:19:13 pipeline.py:712] Training Step 27380: Policy loss = 1.5178158283233643, value loss = 0.19399020075798035\n",
      "INFO 2024-12-04 19:19:22 pipeline.py:712] Training Step 27400: Policy loss = 1.5792710781097412, value loss = 0.1918930858373642\n",
      "INFO 2024-12-04 19:19:32 pipeline.py:712] Training Step 27420: Policy loss = 1.5034325122833252, value loss = 0.21131795644760132\n",
      "INFO 2024-12-04 19:19:42 pipeline.py:712] Training Step 27440: Policy loss = 1.5388942956924438, value loss = 0.21958759427070618\n",
      "INFO 2024-12-04 19:19:51 pipeline.py:712] Training Step 27460: Policy loss = 1.566777229309082, value loss = 0.24440997838974\n",
      "INFO 2024-12-04 19:20:01 pipeline.py:712] Training Step 27480: Policy loss = 1.4954155683517456, value loss = 0.21644362807273865\n",
      "INFO 2024-12-04 19:20:11 pipeline.py:712] Training Step 27500: Policy loss = 1.4573678970336914, value loss = 0.24596039950847626\n",
      "INFO 2024-12-04 19:20:21 pipeline.py:712] Training Step 27520: Policy loss = 1.5746748447418213, value loss = 0.19828438758850098\n",
      "INFO 2024-12-04 19:20:30 pipeline.py:712] Training Step 27540: Policy loss = 1.5456461906433105, value loss = 0.1997237503528595\n",
      "INFO 2024-12-04 19:20:40 pipeline.py:712] Training Step 27560: Policy loss = 1.473907470703125, value loss = 0.256318598985672\n",
      "INFO 2024-12-04 19:20:50 pipeline.py:712] Training Step 27580: Policy loss = 1.4688111543655396, value loss = 0.2477637529373169\n",
      "INFO 2024-12-04 19:21:12 pipeline.py:738] training_steps 27588: Validation loss: Poliy loss 1.8513729855662486, value_loss 0.44597078273530866\n",
      "INFO 2024-12-04 19:21:17 pipeline.py:712] Training Step 27600: Policy loss = 1.5186233520507812, value loss = 0.2425227016210556\n",
      "INFO 2024-12-04 19:21:27 pipeline.py:712] Training Step 27620: Policy loss = 1.5696977376937866, value loss = 0.21338480710983276\n",
      "INFO 2024-12-04 19:21:37 pipeline.py:712] Training Step 27640: Policy loss = 1.4965336322784424, value loss = 0.22325219213962555\n",
      "INFO 2024-12-04 19:21:47 pipeline.py:712] Training Step 27660: Policy loss = 1.5472981929779053, value loss = 0.1964525282382965\n",
      "INFO 2024-12-04 19:21:56 pipeline.py:712] Training Step 27680: Policy loss = 1.4641780853271484, value loss = 0.21254730224609375\n",
      "INFO 2024-12-04 19:22:06 pipeline.py:712] Training Step 27700: Policy loss = 1.5029611587524414, value loss = 0.21334512531757355\n",
      "INFO 2024-12-04 19:22:16 pipeline.py:712] Training Step 27720: Policy loss = 1.5944316387176514, value loss = 0.17091995477676392\n",
      "INFO 2024-12-04 19:22:25 pipeline.py:712] Training Step 27740: Policy loss = 1.5488351583480835, value loss = 0.21830445528030396\n",
      "INFO 2024-12-04 19:22:35 pipeline.py:712] Training Step 27760: Policy loss = 1.5384085178375244, value loss = 0.22988927364349365\n",
      "INFO 2024-12-04 19:22:45 pipeline.py:712] Training Step 27780: Policy loss = 1.5344915390014648, value loss = 0.21879461407661438\n",
      "INFO 2024-12-04 19:22:54 pipeline.py:712] Training Step 27800: Policy loss = 1.4370977878570557, value loss = 0.22191008925437927\n",
      "INFO 2024-12-04 19:23:04 pipeline.py:712] Training Step 27820: Policy loss = 1.426830768585205, value loss = 0.22466930747032166\n",
      "INFO 2024-12-04 19:23:14 pipeline.py:712] Training Step 27840: Policy loss = 1.52756667137146, value loss = 0.212001770734787\n",
      "INFO 2024-12-04 19:23:24 pipeline.py:712] Training Step 27860: Policy loss = 1.5312061309814453, value loss = 0.21074895560741425\n",
      "INFO 2024-12-04 19:23:33 pipeline.py:712] Training Step 27880: Policy loss = 1.4695544242858887, value loss = 0.24863475561141968\n",
      "INFO 2024-12-04 19:23:43 pipeline.py:712] Training Step 27900: Policy loss = 1.527944803237915, value loss = 0.22603222727775574\n",
      "INFO 2024-12-04 19:23:53 pipeline.py:712] Training Step 27920: Policy loss = 1.5724684000015259, value loss = 0.21411418914794922\n",
      "INFO 2024-12-04 19:24:02 pipeline.py:712] Training Step 27940: Policy loss = 1.6468358039855957, value loss = 0.26548856496810913\n",
      "INFO 2024-12-04 19:24:12 pipeline.py:712] Training Step 27960: Policy loss = 1.5005191564559937, value loss = 0.21576479077339172\n",
      "INFO 2024-12-04 19:24:22 pipeline.py:712] Training Step 27980: Policy loss = 1.608331561088562, value loss = 0.23125337064266205\n",
      "INFO 2024-12-04 19:24:31 pipeline.py:712] Training Step 28000: Policy loss = 1.5804650783538818, value loss = 0.2188161313533783\n",
      "INFO 2024-12-04 19:24:41 pipeline.py:712] Training Step 28020: Policy loss = 1.5545668601989746, value loss = 0.2251792848110199\n",
      "INFO 2024-12-04 19:24:51 pipeline.py:712] Training Step 28040: Policy loss = 1.551135778427124, value loss = 0.20633478462696075\n",
      "INFO 2024-12-04 19:25:00 pipeline.py:712] Training Step 28060: Policy loss = 1.5551220178604126, value loss = 0.20384764671325684\n",
      "INFO 2024-12-04 19:25:24 pipeline.py:738] training_steps 28072: Validation loss: Poliy loss 1.8519336024268729, value_loss 0.4453693889692181\n",
      "INFO 2024-12-04 19:25:28 pipeline.py:712] Training Step 28080: Policy loss = 1.5501712560653687, value loss = 0.1887437254190445\n",
      "INFO 2024-12-04 19:25:38 pipeline.py:712] Training Step 28100: Policy loss = 1.466849446296692, value loss = 0.19346663355827332\n",
      "INFO 2024-12-04 19:25:48 pipeline.py:712] Training Step 28120: Policy loss = 1.4458913803100586, value loss = 0.2033688873052597\n",
      "INFO 2024-12-04 19:25:57 pipeline.py:712] Training Step 28140: Policy loss = 1.51198148727417, value loss = 0.21227017045021057\n",
      "INFO 2024-12-04 19:26:07 pipeline.py:712] Training Step 28160: Policy loss = 1.4990490674972534, value loss = 0.20296138525009155\n",
      "INFO 2024-12-04 19:26:16 pipeline.py:712] Training Step 28180: Policy loss = 1.5370328426361084, value loss = 0.21834778785705566\n",
      "INFO 2024-12-04 19:26:26 pipeline.py:712] Training Step 28200: Policy loss = 1.5599355697631836, value loss = 0.20514091849327087\n",
      "INFO 2024-12-04 19:26:36 pipeline.py:712] Training Step 28220: Policy loss = 1.5144569873809814, value loss = 0.2212737798690796\n",
      "INFO 2024-12-04 19:26:46 pipeline.py:712] Training Step 28240: Policy loss = 1.6233958005905151, value loss = 0.2328498661518097\n",
      "INFO 2024-12-04 19:26:55 pipeline.py:712] Training Step 28260: Policy loss = 1.5112255811691284, value loss = 0.2296643853187561\n",
      "INFO 2024-12-04 19:27:05 pipeline.py:712] Training Step 28280: Policy loss = 1.4499754905700684, value loss = 0.2432614266872406\n",
      "INFO 2024-12-04 19:27:15 pipeline.py:712] Training Step 28300: Policy loss = 1.479416847229004, value loss = 0.24258145689964294\n",
      "INFO 2024-12-04 19:27:24 pipeline.py:712] Training Step 28320: Policy loss = 1.5688376426696777, value loss = 0.2115735113620758\n",
      "INFO 2024-12-04 19:27:34 pipeline.py:712] Training Step 28340: Policy loss = 1.4864633083343506, value loss = 0.2217312753200531\n",
      "INFO 2024-12-04 19:27:44 pipeline.py:712] Training Step 28360: Policy loss = 1.5584238767623901, value loss = 0.19239121675491333\n",
      "INFO 2024-12-04 19:27:53 pipeline.py:712] Training Step 28380: Policy loss = 1.5163445472717285, value loss = 0.1737198531627655\n",
      "INFO 2024-12-04 19:28:03 pipeline.py:712] Training Step 28400: Policy loss = 1.5535262823104858, value loss = 0.21689151227474213\n",
      "INFO 2024-12-04 19:28:13 pipeline.py:712] Training Step 28420: Policy loss = 1.5615164041519165, value loss = 0.2202659547328949\n",
      "INFO 2024-12-04 19:28:22 pipeline.py:712] Training Step 28440: Policy loss = 1.5684146881103516, value loss = 0.2118779420852661\n",
      "INFO 2024-12-04 19:28:32 pipeline.py:712] Training Step 28460: Policy loss = 1.5624037981033325, value loss = 0.21477703750133514\n",
      "INFO 2024-12-04 19:28:42 pipeline.py:712] Training Step 28480: Policy loss = 1.4701380729675293, value loss = 0.2084345519542694\n",
      "INFO 2024-12-04 19:28:51 pipeline.py:712] Training Step 28500: Policy loss = 1.5243185758590698, value loss = 0.22814612090587616\n",
      "INFO 2024-12-04 19:29:01 pipeline.py:712] Training Step 28520: Policy loss = 1.5338993072509766, value loss = 0.22385528683662415\n",
      "INFO 2024-12-04 19:29:11 pipeline.py:712] Training Step 28540: Policy loss = 1.4990065097808838, value loss = 0.21645165979862213\n",
      "INFO 2024-12-04 19:29:37 pipeline.py:738] training_steps 28556: Validation loss: Poliy loss 1.8525761629714341, value_loss 0.44616012714925357\n",
      "INFO 2024-12-04 19:29:38 pipeline.py:712] Training Step 28560: Policy loss = 1.5267009735107422, value loss = 0.22252504527568817\n",
      "INFO 2024-12-04 19:29:48 pipeline.py:712] Training Step 28580: Policy loss = 1.5892874002456665, value loss = 0.21495245397090912\n",
      "INFO 2024-12-04 19:29:58 pipeline.py:712] Training Step 28600: Policy loss = 1.561586856842041, value loss = 0.2037239968776703\n",
      "INFO 2024-12-04 19:30:08 pipeline.py:712] Training Step 28620: Policy loss = 1.461166501045227, value loss = 0.2232125997543335\n",
      "INFO 2024-12-04 19:30:17 pipeline.py:712] Training Step 28640: Policy loss = 1.4733253717422485, value loss = 0.2223430573940277\n",
      "INFO 2024-12-04 19:30:27 pipeline.py:712] Training Step 28660: Policy loss = 1.661470651626587, value loss = 0.17844852805137634\n",
      "INFO 2024-12-04 19:30:37 pipeline.py:712] Training Step 28680: Policy loss = 1.5031630992889404, value loss = 0.19114094972610474\n",
      "INFO 2024-12-04 19:30:47 pipeline.py:712] Training Step 28700: Policy loss = 1.5586442947387695, value loss = 0.19936519861221313\n",
      "INFO 2024-12-04 19:30:56 pipeline.py:712] Training Step 28720: Policy loss = 1.4791871309280396, value loss = 0.2322477251291275\n",
      "INFO 2024-12-04 19:31:06 pipeline.py:712] Training Step 28740: Policy loss = 1.6111615896224976, value loss = 0.23561854660511017\n",
      "INFO 2024-12-04 19:31:16 pipeline.py:712] Training Step 28760: Policy loss = 1.5468504428863525, value loss = 0.23190060257911682\n",
      "INFO 2024-12-04 19:31:25 pipeline.py:712] Training Step 28780: Policy loss = 1.495452642440796, value loss = 0.21957102417945862\n",
      "INFO 2024-12-04 19:31:35 pipeline.py:712] Training Step 28800: Policy loss = 1.552327275276184, value loss = 0.21528664231300354\n",
      "INFO 2024-12-04 19:31:45 pipeline.py:712] Training Step 28820: Policy loss = 1.54603910446167, value loss = 0.1989077627658844\n",
      "INFO 2024-12-04 19:31:55 pipeline.py:712] Training Step 28840: Policy loss = 1.5785157680511475, value loss = 0.24249619245529175\n",
      "INFO 2024-12-04 19:32:04 pipeline.py:712] Training Step 28860: Policy loss = 1.524760365486145, value loss = 0.27615779638290405\n",
      "INFO 2024-12-04 19:32:14 pipeline.py:712] Training Step 28880: Policy loss = 1.5606253147125244, value loss = 0.20472609996795654\n",
      "INFO 2024-12-04 19:32:23 pipeline.py:712] Training Step 28900: Policy loss = 1.493485450744629, value loss = 0.21499764919281006\n",
      "INFO 2024-12-04 19:32:33 pipeline.py:712] Training Step 28920: Policy loss = 1.5696359872817993, value loss = 0.1989230215549469\n",
      "INFO 2024-12-04 19:32:43 pipeline.py:712] Training Step 28940: Policy loss = 1.490341067314148, value loss = 0.23765379190444946\n",
      "INFO 2024-12-04 19:32:53 pipeline.py:712] Training Step 28960: Policy loss = 1.5404353141784668, value loss = 0.2210613340139389\n",
      "INFO 2024-12-04 19:33:02 pipeline.py:712] Training Step 28980: Policy loss = 1.4675490856170654, value loss = 0.20907682180404663\n",
      "INFO 2024-12-04 19:33:12 pipeline.py:712] Training Step 29000: Policy loss = 1.5310702323913574, value loss = 0.2252521514892578\n",
      "INFO 2024-12-04 19:33:22 pipeline.py:712] Training Step 29020: Policy loss = 1.5437500476837158, value loss = 0.22473232448101044\n",
      "INFO 2024-12-04 19:33:31 pipeline.py:712] Training Step 29040: Policy loss = 1.4846621751785278, value loss = 0.22715970873832703\n",
      "INFO 2024-12-04 19:33:49 pipeline.py:738] training_steps 29040: Validation loss: Poliy loss 1.852016896498008, value_loss 0.4463150848130711\n",
      "INFO 2024-12-04 19:33:59 pipeline.py:712] Training Step 29060: Policy loss = 1.456134557723999, value loss = 0.21025224030017853\n",
      "INFO 2024-12-04 19:34:09 pipeline.py:712] Training Step 29080: Policy loss = 1.5275812149047852, value loss = 0.20954254269599915\n",
      "INFO 2024-12-04 19:34:19 pipeline.py:712] Training Step 29100: Policy loss = 1.5229721069335938, value loss = 0.21416136622428894\n",
      "INFO 2024-12-04 19:34:28 pipeline.py:712] Training Step 29120: Policy loss = 1.4692728519439697, value loss = 0.21415990591049194\n",
      "INFO 2024-12-04 19:34:38 pipeline.py:712] Training Step 29140: Policy loss = 1.4021921157836914, value loss = 0.23110297322273254\n",
      "INFO 2024-12-04 19:34:48 pipeline.py:712] Training Step 29160: Policy loss = 1.4372708797454834, value loss = 0.2038765847682953\n",
      "INFO 2024-12-04 19:34:57 pipeline.py:712] Training Step 29180: Policy loss = 1.605721354484558, value loss = 0.2105257511138916\n",
      "INFO 2024-12-04 19:35:07 pipeline.py:712] Training Step 29200: Policy loss = 1.4979712963104248, value loss = 0.25034642219543457\n",
      "INFO 2024-12-04 19:35:17 pipeline.py:712] Training Step 29220: Policy loss = 1.498518943786621, value loss = 0.21119193732738495\n",
      "INFO 2024-12-04 19:35:26 pipeline.py:712] Training Step 29240: Policy loss = 1.5871243476867676, value loss = 0.25223270058631897\n",
      "INFO 2024-12-04 19:35:36 pipeline.py:712] Training Step 29260: Policy loss = 1.5398147106170654, value loss = 0.2068037986755371\n",
      "INFO 2024-12-04 19:35:46 pipeline.py:712] Training Step 29280: Policy loss = 1.5414729118347168, value loss = 0.19188551604747772\n",
      "INFO 2024-12-04 19:35:56 pipeline.py:712] Training Step 29300: Policy loss = 1.5928616523742676, value loss = 0.21980223059654236\n",
      "INFO 2024-12-04 19:36:05 pipeline.py:712] Training Step 29320: Policy loss = 1.5211666822433472, value loss = 0.22569164633750916\n",
      "INFO 2024-12-04 19:36:15 pipeline.py:712] Training Step 29340: Policy loss = 1.450535774230957, value loss = 0.24695922434329987\n",
      "INFO 2024-12-04 19:36:25 pipeline.py:712] Training Step 29360: Policy loss = 1.491078495979309, value loss = 0.22162507474422455\n",
      "INFO 2024-12-04 19:36:34 pipeline.py:712] Training Step 29380: Policy loss = 1.5683326721191406, value loss = 0.21344056725502014\n",
      "INFO 2024-12-04 19:36:44 pipeline.py:712] Training Step 29400: Policy loss = 1.5974156856536865, value loss = 0.22613967955112457\n",
      "INFO 2024-12-04 19:36:54 pipeline.py:712] Training Step 29420: Policy loss = 1.4455339908599854, value loss = 0.20294161140918732\n",
      "INFO 2024-12-04 19:37:03 pipeline.py:712] Training Step 29440: Policy loss = 1.5414589643478394, value loss = 0.2024521678686142\n",
      "INFO 2024-12-04 19:37:13 pipeline.py:712] Training Step 29460: Policy loss = 1.4660649299621582, value loss = 0.22623032331466675\n",
      "INFO 2024-12-04 19:37:23 pipeline.py:712] Training Step 29480: Policy loss = 1.5431923866271973, value loss = 0.2269517481327057\n",
      "INFO 2024-12-04 19:37:32 pipeline.py:712] Training Step 29500: Policy loss = 1.4848620891571045, value loss = 0.2244163453578949\n",
      "INFO 2024-12-04 19:37:42 pipeline.py:712] Training Step 29520: Policy loss = 1.620270848274231, value loss = 0.20958146452903748\n",
      "INFO 2024-12-04 19:38:02 pipeline.py:738] training_steps 29524: Validation loss: Poliy loss 1.852172073770742, value_loss 0.4470034700925233\n",
      "INFO 2024-12-04 19:38:10 pipeline.py:712] Training Step 29540: Policy loss = 1.5153038501739502, value loss = 0.22082044184207916\n",
      "INFO 2024-12-04 19:38:20 pipeline.py:712] Training Step 29560: Policy loss = 1.4773751497268677, value loss = 0.21569202840328217\n",
      "INFO 2024-12-04 19:38:29 pipeline.py:712] Training Step 29580: Policy loss = 1.485173225402832, value loss = 0.230123370885849\n",
      "INFO 2024-12-04 19:38:39 pipeline.py:712] Training Step 29600: Policy loss = 1.478379249572754, value loss = 0.22168630361557007\n",
      "INFO 2024-12-04 19:38:49 pipeline.py:712] Training Step 29620: Policy loss = 1.4995802640914917, value loss = 0.2446916550397873\n",
      "INFO 2024-12-04 19:38:58 pipeline.py:712] Training Step 29640: Policy loss = 1.5126121044158936, value loss = 0.22316128015518188\n",
      "INFO 2024-12-04 19:39:08 pipeline.py:712] Training Step 29660: Policy loss = 1.4305920600891113, value loss = 0.23238691687583923\n",
      "INFO 2024-12-04 19:39:18 pipeline.py:712] Training Step 29680: Policy loss = 1.5357980728149414, value loss = 0.20688703656196594\n",
      "INFO 2024-12-04 19:39:27 pipeline.py:712] Training Step 29700: Policy loss = 1.5264626741409302, value loss = 0.21442461013793945\n",
      "INFO 2024-12-04 19:39:37 pipeline.py:712] Training Step 29720: Policy loss = 1.4949309825897217, value loss = 0.18042171001434326\n",
      "INFO 2024-12-04 19:39:47 pipeline.py:712] Training Step 29740: Policy loss = 1.554288387298584, value loss = 0.21863986551761627\n",
      "INFO 2024-12-04 19:39:56 pipeline.py:712] Training Step 29760: Policy loss = 1.524893045425415, value loss = 0.20349161326885223\n",
      "INFO 2024-12-04 19:40:06 pipeline.py:712] Training Step 29780: Policy loss = 1.4852313995361328, value loss = 0.2315831333398819\n",
      "INFO 2024-12-04 19:40:16 pipeline.py:712] Training Step 29800: Policy loss = 1.446527123451233, value loss = 0.19709832966327667\n",
      "INFO 2024-12-04 19:40:26 pipeline.py:712] Training Step 29820: Policy loss = 1.5011749267578125, value loss = 0.20275349915027618\n",
      "INFO 2024-12-04 19:40:35 pipeline.py:712] Training Step 29840: Policy loss = 1.5924478769302368, value loss = 0.20221436023712158\n",
      "INFO 2024-12-04 19:40:45 pipeline.py:712] Training Step 29860: Policy loss = 1.5179933309555054, value loss = 0.19657105207443237\n",
      "INFO 2024-12-04 19:40:55 pipeline.py:712] Training Step 29880: Policy loss = 1.5832300186157227, value loss = 0.22835668921470642\n",
      "INFO 2024-12-04 19:41:05 pipeline.py:712] Training Step 29900: Policy loss = 1.5431370735168457, value loss = 0.23336704075336456\n",
      "INFO 2024-12-04 19:41:14 pipeline.py:712] Training Step 29920: Policy loss = 1.4656643867492676, value loss = 0.22218239307403564\n",
      "INFO 2024-12-04 19:41:24 pipeline.py:712] Training Step 29940: Policy loss = 1.5315086841583252, value loss = 0.20664028823375702\n",
      "INFO 2024-12-04 19:41:33 pipeline.py:712] Training Step 29960: Policy loss = 1.5696160793304443, value loss = 0.22269131243228912\n",
      "INFO 2024-12-04 19:41:43 pipeline.py:712] Training Step 29980: Policy loss = 1.439863920211792, value loss = 0.21184542775154114\n",
      "INFO 2024-12-04 19:41:53 pipeline.py:712] Training Step 30000: Policy loss = 1.457779884338379, value loss = 0.2232683300971985\n",
      "INFO 2024-12-04 19:42:15 pipeline.py:738] training_steps 30008: Validation loss: Poliy loss 1.8523272412722227, value_loss 0.44700672391985286\n",
      "INFO 2024-12-04 19:42:21 pipeline.py:712] Training Step 30020: Policy loss = 1.51194167137146, value loss = 0.23258906602859497\n",
      "INFO 2024-12-04 19:42:30 pipeline.py:712] Training Step 30040: Policy loss = 1.5452214479446411, value loss = 0.1906866431236267\n",
      "INFO 2024-12-04 19:42:40 pipeline.py:712] Training Step 30060: Policy loss = 1.496659278869629, value loss = 0.2170131504535675\n",
      "INFO 2024-12-04 19:42:50 pipeline.py:712] Training Step 30080: Policy loss = 1.5107312202453613, value loss = 0.20032627880573273\n",
      "INFO 2024-12-04 19:42:59 pipeline.py:712] Training Step 30100: Policy loss = 1.5042577981948853, value loss = 0.2402484118938446\n",
      "INFO 2024-12-04 19:43:09 pipeline.py:712] Training Step 30120: Policy loss = 1.4276677370071411, value loss = 0.23704999685287476\n",
      "INFO 2024-12-04 19:43:19 pipeline.py:712] Training Step 30140: Policy loss = 1.4843932390213013, value loss = 0.22011229395866394\n",
      "INFO 2024-12-04 19:43:28 pipeline.py:712] Training Step 30160: Policy loss = 1.4630014896392822, value loss = 0.22800254821777344\n",
      "INFO 2024-12-04 19:43:38 pipeline.py:712] Training Step 30180: Policy loss = 1.4782167673110962, value loss = 0.22282075881958008\n",
      "INFO 2024-12-04 19:43:48 pipeline.py:712] Training Step 30200: Policy loss = 1.499022126197815, value loss = 0.2376326620578766\n",
      "INFO 2024-12-04 19:43:57 pipeline.py:712] Training Step 30220: Policy loss = 1.5865693092346191, value loss = 0.22122788429260254\n",
      "INFO 2024-12-04 19:44:07 pipeline.py:712] Training Step 30240: Policy loss = 1.472291111946106, value loss = 0.2106648087501526\n",
      "INFO 2024-12-04 19:44:17 pipeline.py:712] Training Step 30260: Policy loss = 1.532963514328003, value loss = 0.17436887323856354\n",
      "INFO 2024-12-04 19:44:27 pipeline.py:712] Training Step 30280: Policy loss = 1.4496359825134277, value loss = 0.20464985072612762\n",
      "INFO 2024-12-04 19:44:36 pipeline.py:712] Training Step 30300: Policy loss = 1.52490234375, value loss = 0.19193397462368011\n",
      "INFO 2024-12-04 19:44:46 pipeline.py:712] Training Step 30320: Policy loss = 1.5908548831939697, value loss = 0.1999363899230957\n",
      "INFO 2024-12-04 19:44:56 pipeline.py:712] Training Step 30340: Policy loss = 1.5194530487060547, value loss = 0.2106676697731018\n",
      "INFO 2024-12-04 19:45:05 pipeline.py:712] Training Step 30360: Policy loss = 1.4845093488693237, value loss = 0.2272339165210724\n",
      "INFO 2024-12-04 19:45:15 pipeline.py:712] Training Step 30380: Policy loss = 1.3867404460906982, value loss = 0.21683061122894287\n",
      "INFO 2024-12-04 19:45:25 pipeline.py:712] Training Step 30400: Policy loss = 1.5901517868041992, value loss = 0.20098377764225006\n",
      "INFO 2024-12-04 19:45:34 pipeline.py:712] Training Step 30420: Policy loss = 1.523038625717163, value loss = 0.21339373290538788\n",
      "INFO 2024-12-04 19:45:44 pipeline.py:712] Training Step 30440: Policy loss = 1.5643315315246582, value loss = 0.25286853313446045\n",
      "INFO 2024-12-04 19:45:54 pipeline.py:712] Training Step 30460: Policy loss = 1.6101906299591064, value loss = 0.20480045676231384\n",
      "INFO 2024-12-04 19:46:03 pipeline.py:712] Training Step 30480: Policy loss = 1.5374037027359009, value loss = 0.2223694920539856\n",
      "INFO 2024-12-04 19:46:27 pipeline.py:738] training_steps 30492: Validation loss: Poliy loss 1.8524434713066602, value_loss 0.44723795036800573\n",
      "INFO 2024-12-04 19:46:31 pipeline.py:712] Training Step 30500: Policy loss = 1.599961519241333, value loss = 0.2285955250263214\n",
      "INFO 2024-12-04 19:46:41 pipeline.py:712] Training Step 30520: Policy loss = 1.5360504388809204, value loss = 0.20543880760669708\n",
      "INFO 2024-12-04 19:46:51 pipeline.py:712] Training Step 30540: Policy loss = 1.5054324865341187, value loss = 0.19693243503570557\n",
      "INFO 2024-12-04 19:47:00 pipeline.py:712] Training Step 30560: Policy loss = 1.4606122970581055, value loss = 0.237081378698349\n",
      "INFO 2024-12-04 19:47:10 pipeline.py:712] Training Step 30580: Policy loss = 1.549631953239441, value loss = 0.19443373382091522\n",
      "INFO 2024-12-04 19:47:20 pipeline.py:712] Training Step 30600: Policy loss = 1.5800329446792603, value loss = 0.19906967878341675\n",
      "INFO 2024-12-04 19:47:30 pipeline.py:712] Training Step 30620: Policy loss = 1.518995761871338, value loss = 0.23233889043331146\n",
      "INFO 2024-12-04 19:47:39 pipeline.py:712] Training Step 30640: Policy loss = 1.5511808395385742, value loss = 0.22792084515094757\n",
      "INFO 2024-12-04 19:47:49 pipeline.py:712] Training Step 30660: Policy loss = 1.454188346862793, value loss = 0.20201322436332703\n",
      "INFO 2024-12-04 19:47:59 pipeline.py:712] Training Step 30680: Policy loss = 1.5789560079574585, value loss = 0.22823312878608704\n",
      "INFO 2024-12-04 19:48:08 pipeline.py:712] Training Step 30700: Policy loss = 1.4937266111373901, value loss = 0.22595897316932678\n",
      "INFO 2024-12-04 19:48:18 pipeline.py:712] Training Step 30720: Policy loss = 1.5668138265609741, value loss = 0.2500319480895996\n",
      "INFO 2024-12-04 19:48:28 pipeline.py:712] Training Step 30740: Policy loss = 1.504244327545166, value loss = 0.20660792291164398\n",
      "INFO 2024-12-04 19:48:37 pipeline.py:712] Training Step 30760: Policy loss = 1.5070204734802246, value loss = 0.21649278700351715\n",
      "INFO 2024-12-04 19:48:47 pipeline.py:712] Training Step 30780: Policy loss = 1.458038091659546, value loss = 0.24156275391578674\n",
      "INFO 2024-12-04 19:48:57 pipeline.py:712] Training Step 30800: Policy loss = 1.5177549123764038, value loss = 0.21337935328483582\n",
      "INFO 2024-12-04 19:49:06 pipeline.py:712] Training Step 30820: Policy loss = 1.576094627380371, value loss = 0.22799453139305115\n",
      "INFO 2024-12-04 19:49:16 pipeline.py:712] Training Step 30840: Policy loss = 1.5855695009231567, value loss = 0.2386566549539566\n",
      "INFO 2024-12-04 19:49:26 pipeline.py:712] Training Step 30860: Policy loss = 1.4888863563537598, value loss = 0.22288087010383606\n",
      "INFO 2024-12-04 19:49:35 pipeline.py:712] Training Step 30880: Policy loss = 1.5804078578948975, value loss = 0.22095581889152527\n",
      "INFO 2024-12-04 19:49:45 pipeline.py:712] Training Step 30900: Policy loss = 1.4116042852401733, value loss = 0.20687489211559296\n",
      "INFO 2024-12-04 19:49:55 pipeline.py:712] Training Step 30920: Policy loss = 1.461212396621704, value loss = 0.18960174918174744\n",
      "INFO 2024-12-04 19:50:04 pipeline.py:712] Training Step 30940: Policy loss = 1.516988754272461, value loss = 0.19578921794891357\n",
      "INFO 2024-12-04 19:50:14 pipeline.py:712] Training Step 30960: Policy loss = 1.5125770568847656, value loss = 0.21527642011642456\n",
      "INFO 2024-12-04 19:50:40 pipeline.py:738] training_steps 30976: Validation loss: Poliy loss 1.8534928970649593, value_loss 0.44762747966852345\n",
      "INFO 2024-12-04 19:50:42 pipeline.py:712] Training Step 30980: Policy loss = 1.613134741783142, value loss = 0.2394385039806366\n",
      "INFO 2024-12-04 19:50:52 pipeline.py:712] Training Step 31000: Policy loss = 1.4681267738342285, value loss = 0.2283492535352707\n",
      "INFO 2024-12-04 19:51:01 pipeline.py:712] Training Step 31020: Policy loss = 1.4893286228179932, value loss = 0.20748430490493774\n",
      "INFO 2024-12-04 19:51:11 pipeline.py:712] Training Step 31040: Policy loss = 1.5788700580596924, value loss = 0.2216542661190033\n",
      "INFO 2024-12-04 19:51:20 pipeline.py:712] Training Step 31060: Policy loss = 1.5739641189575195, value loss = 0.21394655108451843\n",
      "INFO 2024-12-04 19:51:29 pipeline.py:712] Training Step 31080: Policy loss = 1.520176887512207, value loss = 0.19962167739868164\n",
      "INFO 2024-12-04 19:51:38 pipeline.py:712] Training Step 31100: Policy loss = 1.5133707523345947, value loss = 0.20687362551689148\n",
      "INFO 2024-12-04 19:51:47 pipeline.py:712] Training Step 31120: Policy loss = 1.4436964988708496, value loss = 0.22516760230064392\n",
      "INFO 2024-12-04 19:51:56 pipeline.py:712] Training Step 31140: Policy loss = 1.4637471437454224, value loss = 0.22981292009353638\n",
      "INFO 2024-12-04 19:52:05 pipeline.py:712] Training Step 31160: Policy loss = 1.563731074333191, value loss = 0.21152427792549133\n",
      "INFO 2024-12-04 19:52:14 pipeline.py:712] Training Step 31180: Policy loss = 1.552009105682373, value loss = 0.19782483577728271\n",
      "INFO 2024-12-04 19:52:23 pipeline.py:712] Training Step 31200: Policy loss = 1.4584763050079346, value loss = 0.21230915188789368\n",
      "INFO 2024-12-04 19:52:33 pipeline.py:712] Training Step 31220: Policy loss = 1.537776231765747, value loss = 0.22402645647525787\n",
      "INFO 2024-12-04 19:52:42 pipeline.py:712] Training Step 31240: Policy loss = 1.5282104015350342, value loss = 0.2448955476284027\n",
      "INFO 2024-12-04 19:52:52 pipeline.py:712] Training Step 31260: Policy loss = 1.4940179586410522, value loss = 0.20938223600387573\n",
      "INFO 2024-12-04 19:53:02 pipeline.py:712] Training Step 31280: Policy loss = 1.4382150173187256, value loss = 0.21889841556549072\n",
      "INFO 2024-12-04 19:53:12 pipeline.py:712] Training Step 31300: Policy loss = 1.5720983743667603, value loss = 0.2228071689605713\n",
      "INFO 2024-12-04 19:53:21 pipeline.py:712] Training Step 31320: Policy loss = 1.4939615726470947, value loss = 0.20069101452827454\n",
      "INFO 2024-12-04 19:53:31 pipeline.py:712] Training Step 31340: Policy loss = 1.5124753713607788, value loss = 0.22869664430618286\n",
      "INFO 2024-12-04 19:53:41 pipeline.py:712] Training Step 31360: Policy loss = 1.5440386533737183, value loss = 0.2297321856021881\n",
      "INFO 2024-12-04 19:53:50 pipeline.py:712] Training Step 31380: Policy loss = 1.5899689197540283, value loss = 0.22646573185920715\n",
      "INFO 2024-12-04 19:54:00 pipeline.py:712] Training Step 31400: Policy loss = 1.54853093624115, value loss = 0.19851385056972504\n",
      "INFO 2024-12-04 19:54:10 pipeline.py:712] Training Step 31420: Policy loss = 1.5356473922729492, value loss = 0.21047742664813995\n",
      "INFO 2024-12-04 19:54:19 pipeline.py:712] Training Step 31440: Policy loss = 1.5236057043075562, value loss = 0.24421672523021698\n",
      "INFO 2024-12-04 19:54:29 pipeline.py:712] Training Step 31460: Policy loss = 1.5172775983810425, value loss = 0.21980588138103485\n",
      "INFO 2024-12-04 19:54:47 pipeline.py:738] training_steps 31460: Validation loss: Poliy loss 1.8530082262930323, value_loss 0.44777377780343663\n",
      "INFO 2024-12-04 19:54:57 pipeline.py:712] Training Step 31480: Policy loss = 1.4664289951324463, value loss = 0.1976737529039383\n",
      "INFO 2024-12-04 19:55:07 pipeline.py:712] Training Step 31500: Policy loss = 1.5916755199432373, value loss = 0.1947845220565796\n",
      "INFO 2024-12-04 19:55:16 pipeline.py:712] Training Step 31520: Policy loss = 1.5333385467529297, value loss = 0.18417957425117493\n",
      "INFO 2024-12-04 19:55:26 pipeline.py:712] Training Step 31540: Policy loss = 1.5187861919403076, value loss = 0.2147599160671234\n",
      "INFO 2024-12-04 19:55:36 pipeline.py:712] Training Step 31560: Policy loss = 1.4594237804412842, value loss = 0.20636451244354248\n",
      "INFO 2024-12-04 19:55:46 pipeline.py:712] Training Step 31580: Policy loss = 1.5074145793914795, value loss = 0.23268309235572815\n",
      "INFO 2024-12-04 19:55:55 pipeline.py:712] Training Step 31600: Policy loss = 1.532195806503296, value loss = 0.21069949865341187\n",
      "INFO 2024-12-04 19:56:05 pipeline.py:712] Training Step 31620: Policy loss = 1.5523567199707031, value loss = 0.2263832986354828\n",
      "INFO 2024-12-04 19:56:14 pipeline.py:712] Training Step 31640: Policy loss = 1.519898533821106, value loss = 0.23381595313549042\n",
      "INFO 2024-12-04 19:56:24 pipeline.py:712] Training Step 31660: Policy loss = 1.4684028625488281, value loss = 0.19518440961837769\n",
      "INFO 2024-12-04 19:56:34 pipeline.py:712] Training Step 31680: Policy loss = 1.456892728805542, value loss = 0.19708320498466492\n",
      "INFO 2024-12-04 19:56:44 pipeline.py:712] Training Step 31700: Policy loss = 1.5688998699188232, value loss = 0.21194416284561157\n",
      "INFO 2024-12-04 19:56:53 pipeline.py:712] Training Step 31720: Policy loss = 1.568000078201294, value loss = 0.22437192499637604\n",
      "INFO 2024-12-04 19:57:03 pipeline.py:712] Training Step 31740: Policy loss = 1.576691746711731, value loss = 0.22961674630641937\n",
      "INFO 2024-12-04 19:57:13 pipeline.py:712] Training Step 31760: Policy loss = 1.506284236907959, value loss = 0.2194289118051529\n",
      "INFO 2024-12-04 19:57:22 pipeline.py:712] Training Step 31780: Policy loss = 1.5558089017868042, value loss = 0.2080415040254593\n",
      "INFO 2024-12-04 19:57:32 pipeline.py:712] Training Step 31800: Policy loss = 1.4694064855575562, value loss = 0.2023988664150238\n",
      "INFO 2024-12-04 19:57:42 pipeline.py:712] Training Step 31820: Policy loss = 1.5998363494873047, value loss = 0.20189395546913147\n",
      "INFO 2024-12-04 19:57:52 pipeline.py:712] Training Step 31840: Policy loss = 1.5159313678741455, value loss = 0.23904773592948914\n",
      "INFO 2024-12-04 19:58:01 pipeline.py:712] Training Step 31860: Policy loss = 1.4878780841827393, value loss = 0.21322819590568542\n",
      "INFO 2024-12-04 19:58:11 pipeline.py:712] Training Step 31880: Policy loss = 1.5346193313598633, value loss = 0.22677645087242126\n",
      "INFO 2024-12-04 19:58:20 pipeline.py:712] Training Step 31900: Policy loss = 1.5035390853881836, value loss = 0.21365158259868622\n",
      "INFO 2024-12-04 19:58:30 pipeline.py:712] Training Step 31920: Policy loss = 1.6119446754455566, value loss = 0.21382726728916168\n",
      "INFO 2024-12-04 19:58:40 pipeline.py:712] Training Step 31940: Policy loss = 1.436282753944397, value loss = 0.2176196277141571\n",
      "INFO 2024-12-04 19:59:00 pipeline.py:738] training_steps 31944: Validation loss: Poliy loss 1.8525279985099543, value_loss 0.4476432172489948\n",
      "INFO 2024-12-04 19:59:08 pipeline.py:712] Training Step 31960: Policy loss = 1.577134132385254, value loss = 0.21724560856819153\n",
      "INFO 2024-12-04 19:59:17 pipeline.py:712] Training Step 31980: Policy loss = 1.5459541082382202, value loss = 0.21724504232406616\n",
      "INFO 2024-12-04 19:59:27 pipeline.py:712] Training Step 32000: Policy loss = 1.5866799354553223, value loss = 0.2316111922264099\n",
      "INFO 2024-12-04 19:59:37 pipeline.py:712] Training Step 32020: Policy loss = 1.4896948337554932, value loss = 0.18396688997745514\n",
      "INFO 2024-12-04 19:59:46 pipeline.py:712] Training Step 32040: Policy loss = 1.4579973220825195, value loss = 0.253342866897583\n",
      "INFO 2024-12-04 19:59:56 pipeline.py:712] Training Step 32060: Policy loss = 1.4457569122314453, value loss = 0.23758098483085632\n",
      "INFO 2024-12-04 20:00:06 pipeline.py:712] Training Step 32080: Policy loss = 1.5020314455032349, value loss = 0.2039799839258194\n",
      "INFO 2024-12-04 20:00:16 pipeline.py:712] Training Step 32100: Policy loss = 1.5539612770080566, value loss = 0.20279936492443085\n",
      "INFO 2024-12-04 20:00:25 pipeline.py:712] Training Step 32120: Policy loss = 1.471222162246704, value loss = 0.2293137013912201\n",
      "INFO 2024-12-04 20:00:35 pipeline.py:712] Training Step 32140: Policy loss = 1.5033094882965088, value loss = 0.19074547290802002\n",
      "INFO 2024-12-04 20:00:44 pipeline.py:712] Training Step 32160: Policy loss = 1.504409909248352, value loss = 0.19113874435424805\n",
      "INFO 2024-12-04 20:00:54 pipeline.py:712] Training Step 32180: Policy loss = 1.4196323156356812, value loss = 0.23783542215824127\n",
      "INFO 2024-12-04 20:01:04 pipeline.py:712] Training Step 32200: Policy loss = 1.5151890516281128, value loss = 0.1979702115058899\n",
      "INFO 2024-12-04 20:01:14 pipeline.py:712] Training Step 32220: Policy loss = 1.572989583015442, value loss = 0.18493247032165527\n",
      "INFO 2024-12-04 20:01:23 pipeline.py:712] Training Step 32240: Policy loss = 1.4750032424926758, value loss = 0.1773912012577057\n",
      "INFO 2024-12-04 20:01:33 pipeline.py:712] Training Step 32260: Policy loss = 1.5043081045150757, value loss = 0.22433783113956451\n",
      "INFO 2024-12-04 20:01:43 pipeline.py:712] Training Step 32280: Policy loss = 1.4523276090621948, value loss = 0.20199164748191833\n",
      "INFO 2024-12-04 20:01:53 pipeline.py:712] Training Step 32300: Policy loss = 1.5117526054382324, value loss = 0.22634392976760864\n",
      "INFO 2024-12-04 20:02:02 pipeline.py:712] Training Step 32320: Policy loss = 1.5408165454864502, value loss = 0.20301707088947296\n",
      "INFO 2024-12-04 20:02:12 pipeline.py:712] Training Step 32340: Policy loss = 1.585357427597046, value loss = 0.24294628202915192\n",
      "INFO 2024-12-04 20:02:22 pipeline.py:712] Training Step 32360: Policy loss = 1.4064092636108398, value loss = 0.23946624994277954\n",
      "INFO 2024-12-04 20:02:31 pipeline.py:712] Training Step 32380: Policy loss = 1.501456618309021, value loss = 0.21502381563186646\n",
      "INFO 2024-12-04 20:02:41 pipeline.py:712] Training Step 32400: Policy loss = 1.4583204984664917, value loss = 0.23081791400909424\n",
      "INFO 2024-12-04 20:02:51 pipeline.py:712] Training Step 32420: Policy loss = 1.5556526184082031, value loss = 0.24329572916030884\n",
      "INFO 2024-12-04 20:03:13 pipeline.py:738] training_steps 32428: Validation loss: Poliy loss 1.8526929724411887, value_loss 0.44791852328620974\n",
      "INFO 2024-12-04 20:03:18 pipeline.py:712] Training Step 32440: Policy loss = 1.5214593410491943, value loss = 0.231149822473526\n",
      "INFO 2024-12-04 20:03:28 pipeline.py:712] Training Step 32460: Policy loss = 1.526005506515503, value loss = 0.21627557277679443\n",
      "INFO 2024-12-04 20:03:38 pipeline.py:712] Training Step 32480: Policy loss = 1.5540497303009033, value loss = 0.20526833832263947\n",
      "INFO 2024-12-04 20:03:47 pipeline.py:712] Training Step 32500: Policy loss = 1.4949214458465576, value loss = 0.19128648936748505\n",
      "INFO 2024-12-04 20:03:57 pipeline.py:712] Training Step 32520: Policy loss = 1.5967144966125488, value loss = 0.2279193103313446\n",
      "INFO 2024-12-04 20:04:07 pipeline.py:712] Training Step 32540: Policy loss = 1.568213701248169, value loss = 0.2103501260280609\n",
      "INFO 2024-12-04 20:04:17 pipeline.py:712] Training Step 32560: Policy loss = 1.5184383392333984, value loss = 0.21726882457733154\n",
      "INFO 2024-12-04 20:04:26 pipeline.py:712] Training Step 32580: Policy loss = 1.4154531955718994, value loss = 0.1821669340133667\n",
      "INFO 2024-12-04 20:04:36 pipeline.py:712] Training Step 32600: Policy loss = 1.5979431867599487, value loss = 0.18446633219718933\n",
      "INFO 2024-12-04 20:04:46 pipeline.py:712] Training Step 32620: Policy loss = 1.4353140592575073, value loss = 0.20518533885478973\n",
      "INFO 2024-12-04 20:04:55 pipeline.py:712] Training Step 32640: Policy loss = 1.4684886932373047, value loss = 0.24969390034675598\n",
      "INFO 2024-12-04 20:05:05 pipeline.py:712] Training Step 32660: Policy loss = 1.5022823810577393, value loss = 0.22429420053958893\n",
      "INFO 2024-12-04 20:05:15 pipeline.py:712] Training Step 32680: Policy loss = 1.5280952453613281, value loss = 0.21128742396831512\n",
      "INFO 2024-12-04 20:05:25 pipeline.py:712] Training Step 32700: Policy loss = 1.5868256092071533, value loss = 0.20199467241764069\n",
      "INFO 2024-12-04 20:05:34 pipeline.py:712] Training Step 32720: Policy loss = 1.4920856952667236, value loss = 0.23766016960144043\n",
      "INFO 2024-12-04 20:05:44 pipeline.py:712] Training Step 32740: Policy loss = 1.5597559213638306, value loss = 0.21877238154411316\n",
      "INFO 2024-12-04 20:05:54 pipeline.py:712] Training Step 32760: Policy loss = 1.5504835844039917, value loss = 0.22692149877548218\n",
      "INFO 2024-12-04 20:06:03 pipeline.py:712] Training Step 32780: Policy loss = 1.5339646339416504, value loss = 0.20379558205604553\n",
      "INFO 2024-12-04 20:06:13 pipeline.py:712] Training Step 32800: Policy loss = 1.586937665939331, value loss = 0.2187415063381195\n",
      "INFO 2024-12-04 20:06:23 pipeline.py:712] Training Step 32820: Policy loss = 1.5602866411209106, value loss = 0.2339397519826889\n",
      "INFO 2024-12-04 20:06:32 pipeline.py:712] Training Step 32840: Policy loss = 1.5917420387268066, value loss = 0.22429248690605164\n",
      "INFO 2024-12-04 20:06:42 pipeline.py:712] Training Step 32860: Policy loss = 1.4682683944702148, value loss = 0.21055461466312408\n",
      "INFO 2024-12-04 20:06:52 pipeline.py:712] Training Step 32880: Policy loss = 1.5691845417022705, value loss = 0.18563413619995117\n",
      "INFO 2024-12-04 20:07:02 pipeline.py:712] Training Step 32900: Policy loss = 1.5196236371994019, value loss = 0.20724698901176453\n",
      "INFO 2024-12-04 20:07:26 pipeline.py:738] training_steps 32912: Validation loss: Poliy loss 1.8530275831457044, value_loss 0.44789187610149384\n",
      "INFO 2024-12-04 20:07:29 pipeline.py:712] Training Step 32920: Policy loss = 1.483717679977417, value loss = 0.19636207818984985\n",
      "INFO 2024-12-04 20:07:39 pipeline.py:712] Training Step 32940: Policy loss = 1.5157009363174438, value loss = 0.22613395750522614\n",
      "INFO 2024-12-04 20:07:49 pipeline.py:712] Training Step 32960: Policy loss = 1.4288947582244873, value loss = 0.20144987106323242\n",
      "INFO 2024-12-04 20:07:58 pipeline.py:712] Training Step 32980: Policy loss = 1.50823974609375, value loss = 0.22430580854415894\n",
      "INFO 2024-12-04 20:08:08 pipeline.py:712] Training Step 33000: Policy loss = 1.583153486251831, value loss = 0.20231780409812927\n",
      "INFO 2024-12-04 20:08:18 pipeline.py:712] Training Step 33020: Policy loss = 1.580451250076294, value loss = 0.24051065742969513\n",
      "INFO 2024-12-04 20:08:28 pipeline.py:712] Training Step 33040: Policy loss = 1.5568097829818726, value loss = 0.19819806516170502\n",
      "INFO 2024-12-04 20:08:37 pipeline.py:712] Training Step 33060: Policy loss = 1.5202786922454834, value loss = 0.20060144364833832\n",
      "INFO 2024-12-04 20:08:47 pipeline.py:712] Training Step 33080: Policy loss = 1.4872361421585083, value loss = 0.18464165925979614\n",
      "INFO 2024-12-04 20:08:57 pipeline.py:712] Training Step 33100: Policy loss = 1.560248613357544, value loss = 0.23342137038707733\n",
      "INFO 2024-12-04 20:09:06 pipeline.py:712] Training Step 33120: Policy loss = 1.523626685142517, value loss = 0.1995960772037506\n",
      "INFO 2024-12-04 20:09:16 pipeline.py:712] Training Step 33140: Policy loss = 1.5582976341247559, value loss = 0.18959444761276245\n",
      "INFO 2024-12-04 20:09:26 pipeline.py:712] Training Step 33160: Policy loss = 1.5644181966781616, value loss = 0.2310236245393753\n",
      "INFO 2024-12-04 20:09:35 pipeline.py:712] Training Step 33180: Policy loss = 1.4956302642822266, value loss = 0.24123524129390717\n",
      "INFO 2024-12-04 20:09:45 pipeline.py:712] Training Step 33200: Policy loss = 1.5833324193954468, value loss = 0.22285196185112\n",
      "INFO 2024-12-04 20:09:55 pipeline.py:712] Training Step 33220: Policy loss = 1.5269246101379395, value loss = 0.20193937420845032\n",
      "INFO 2024-12-04 20:10:04 pipeline.py:712] Training Step 33240: Policy loss = 1.5388484001159668, value loss = 0.24220120906829834\n",
      "INFO 2024-12-04 20:10:14 pipeline.py:712] Training Step 33260: Policy loss = 1.545396327972412, value loss = 0.21437318623065948\n",
      "INFO 2024-12-04 20:10:24 pipeline.py:712] Training Step 33280: Policy loss = 1.5290231704711914, value loss = 0.22345522046089172\n",
      "INFO 2024-12-04 20:10:34 pipeline.py:712] Training Step 33300: Policy loss = 1.5158474445343018, value loss = 0.1981455385684967\n",
      "INFO 2024-12-04 20:10:43 pipeline.py:712] Training Step 33320: Policy loss = 1.4655647277832031, value loss = 0.19945800304412842\n",
      "INFO 2024-12-04 20:10:53 pipeline.py:712] Training Step 33340: Policy loss = 1.5294992923736572, value loss = 0.20703355967998505\n",
      "INFO 2024-12-04 20:11:03 pipeline.py:712] Training Step 33360: Policy loss = 1.4713475704193115, value loss = 0.22256162762641907\n",
      "INFO 2024-12-04 20:11:13 pipeline.py:712] Training Step 33380: Policy loss = 1.5313630104064941, value loss = 0.2489038109779358\n",
      "INFO 2024-12-04 20:11:38 pipeline.py:738] training_steps 33396: Validation loss: Poliy loss 1.8533119324777947, value_loss 0.4483234076226344\n",
      "INFO 2024-12-04 20:11:40 pipeline.py:712] Training Step 33400: Policy loss = 1.4396075010299683, value loss = 0.18471351265907288\n",
      "INFO 2024-12-04 20:11:50 pipeline.py:712] Training Step 33420: Policy loss = 1.5805021524429321, value loss = 0.1908387541770935\n",
      "INFO 2024-12-04 20:12:00 pipeline.py:712] Training Step 33440: Policy loss = 1.4551894664764404, value loss = 0.20741130411624908\n",
      "INFO 2024-12-04 20:12:09 pipeline.py:712] Training Step 33460: Policy loss = 1.46555495262146, value loss = 0.24438948929309845\n",
      "INFO 2024-12-04 20:12:19 pipeline.py:712] Training Step 33480: Policy loss = 1.5518722534179688, value loss = 0.20350193977355957\n",
      "INFO 2024-12-04 20:12:29 pipeline.py:712] Training Step 33500: Policy loss = 1.5161159038543701, value loss = 0.1908349096775055\n",
      "INFO 2024-12-04 20:12:39 pipeline.py:712] Training Step 33520: Policy loss = 1.537872314453125, value loss = 0.1997915655374527\n",
      "INFO 2024-12-04 20:12:48 pipeline.py:712] Training Step 33540: Policy loss = 1.552206039428711, value loss = 0.20363497734069824\n",
      "INFO 2024-12-04 20:12:58 pipeline.py:712] Training Step 33560: Policy loss = 1.562546968460083, value loss = 0.2171393632888794\n",
      "INFO 2024-12-04 20:13:08 pipeline.py:712] Training Step 33580: Policy loss = 1.4440622329711914, value loss = 0.20315119624137878\n",
      "INFO 2024-12-04 20:13:17 pipeline.py:712] Training Step 33600: Policy loss = 1.4014304876327515, value loss = 0.21983860433101654\n",
      "INFO 2024-12-04 20:13:27 pipeline.py:712] Training Step 33620: Policy loss = 1.5153144598007202, value loss = 0.19658881425857544\n",
      "INFO 2024-12-04 20:13:37 pipeline.py:712] Training Step 33640: Policy loss = 1.51259183883667, value loss = 0.2151201069355011\n",
      "INFO 2024-12-04 20:13:46 pipeline.py:712] Training Step 33660: Policy loss = 1.567739486694336, value loss = 0.2081407904624939\n",
      "INFO 2024-12-04 20:13:56 pipeline.py:712] Training Step 33680: Policy loss = 1.5063849687576294, value loss = 0.23789717257022858\n",
      "INFO 2024-12-04 20:14:06 pipeline.py:712] Training Step 33700: Policy loss = 1.5188663005828857, value loss = 0.22790184617042542\n",
      "INFO 2024-12-04 20:14:15 pipeline.py:712] Training Step 33720: Policy loss = 1.5427722930908203, value loss = 0.20912855863571167\n",
      "INFO 2024-12-04 20:14:25 pipeline.py:712] Training Step 33740: Policy loss = 1.4934139251708984, value loss = 0.19426220655441284\n",
      "INFO 2024-12-04 20:14:35 pipeline.py:712] Training Step 33760: Policy loss = 1.598908543586731, value loss = 0.19505400955677032\n",
      "INFO 2024-12-04 20:14:44 pipeline.py:712] Training Step 33780: Policy loss = 1.516378402709961, value loss = 0.22193163633346558\n",
      "INFO 2024-12-04 20:14:54 pipeline.py:712] Training Step 33800: Policy loss = 1.6173382997512817, value loss = 0.1942310929298401\n",
      "INFO 2024-12-04 20:15:04 pipeline.py:712] Training Step 33820: Policy loss = 1.5823876857757568, value loss = 0.22513510286808014\n",
      "INFO 2024-12-04 20:15:13 pipeline.py:712] Training Step 33840: Policy loss = 1.4973348379135132, value loss = 0.22383883595466614\n",
      "INFO 2024-12-04 20:15:23 pipeline.py:712] Training Step 33860: Policy loss = 1.5557609796524048, value loss = 0.1975862681865692\n",
      "INFO 2024-12-04 20:15:33 pipeline.py:712] Training Step 33880: Policy loss = 1.5996780395507812, value loss = 0.19570598006248474\n",
      "INFO 2024-12-04 20:15:52 pipeline.py:738] training_steps 33880: Validation loss: Poliy loss 1.8538743511575166, value_loss 0.447966426122384\n",
      "INFO 2024-12-04 20:16:02 pipeline.py:712] Training Step 33900: Policy loss = 1.5517330169677734, value loss = 0.19504877924919128\n",
      "INFO 2024-12-04 20:16:12 pipeline.py:712] Training Step 33920: Policy loss = 1.5369291305541992, value loss = 0.23253214359283447\n",
      "INFO 2024-12-04 20:16:21 pipeline.py:712] Training Step 33940: Policy loss = 1.46217679977417, value loss = 0.2032715529203415\n",
      "INFO 2024-12-04 20:16:31 pipeline.py:712] Training Step 33960: Policy loss = 1.4685416221618652, value loss = 0.18429487943649292\n",
      "INFO 2024-12-04 20:16:41 pipeline.py:712] Training Step 33980: Policy loss = 1.5153888463974, value loss = 0.22759319841861725\n",
      "INFO 2024-12-04 20:16:50 pipeline.py:712] Training Step 34000: Policy loss = 1.5064404010772705, value loss = 0.21659016609191895\n",
      "INFO 2024-12-04 20:17:00 pipeline.py:712] Training Step 34020: Policy loss = 1.5347858667373657, value loss = 0.21872982382774353\n",
      "INFO 2024-12-04 20:17:10 pipeline.py:712] Training Step 34040: Policy loss = 1.5097103118896484, value loss = 0.20437021553516388\n",
      "INFO 2024-12-04 20:17:20 pipeline.py:712] Training Step 34060: Policy loss = 1.5008825063705444, value loss = 0.20464269816875458\n",
      "INFO 2024-12-04 20:17:30 pipeline.py:712] Training Step 34080: Policy loss = 1.5525801181793213, value loss = 0.23967120051383972\n",
      "INFO 2024-12-04 20:17:40 pipeline.py:712] Training Step 34100: Policy loss = 1.4768316745758057, value loss = 0.21928945183753967\n",
      "INFO 2024-12-04 20:17:49 pipeline.py:712] Training Step 34120: Policy loss = 1.4938757419586182, value loss = 0.18970987200737\n",
      "INFO 2024-12-04 20:17:59 pipeline.py:712] Training Step 34140: Policy loss = 1.4513914585113525, value loss = 0.22055059671401978\n",
      "INFO 2024-12-04 20:18:08 pipeline.py:712] Training Step 34160: Policy loss = 1.520745873451233, value loss = 0.2139834761619568\n",
      "INFO 2024-12-04 20:18:18 pipeline.py:712] Training Step 34180: Policy loss = 1.561821699142456, value loss = 0.20834055542945862\n",
      "INFO 2024-12-04 20:18:28 pipeline.py:712] Training Step 34200: Policy loss = 1.5020544528961182, value loss = 0.2571782171726227\n",
      "INFO 2024-12-04 20:18:38 pipeline.py:712] Training Step 34220: Policy loss = 1.5136903524398804, value loss = 0.2122986614704132\n",
      "INFO 2024-12-04 20:18:47 pipeline.py:712] Training Step 34240: Policy loss = 1.487877368927002, value loss = 0.2239151895046234\n",
      "INFO 2024-12-04 20:18:57 pipeline.py:712] Training Step 34260: Policy loss = 1.6574199199676514, value loss = 0.22387254238128662\n",
      "INFO 2024-12-04 20:19:06 pipeline.py:712] Training Step 34280: Policy loss = 1.4520500898361206, value loss = 0.2371216118335724\n",
      "INFO 2024-12-04 20:19:16 pipeline.py:712] Training Step 34300: Policy loss = 1.5173368453979492, value loss = 0.1882065087556839\n",
      "INFO 2024-12-04 20:19:26 pipeline.py:712] Training Step 34320: Policy loss = 1.5485856533050537, value loss = 0.2347327023744583\n",
      "INFO 2024-12-04 20:19:36 pipeline.py:712] Training Step 34340: Policy loss = 1.4259250164031982, value loss = 0.24292221665382385\n",
      "INFO 2024-12-04 20:19:46 pipeline.py:712] Training Step 34360: Policy loss = 1.439605712890625, value loss = 0.2528711259365082\n",
      "INFO 2024-12-04 20:20:06 pipeline.py:738] training_steps 34364: Validation loss: Poliy loss 1.8534851934089036, value_loss 0.44861862600826824\n",
      "INFO 2024-12-04 20:20:14 pipeline.py:712] Training Step 34380: Policy loss = 1.5308680534362793, value loss = 0.2000383883714676\n",
      "INFO 2024-12-04 20:20:24 pipeline.py:712] Training Step 34400: Policy loss = 1.5491220951080322, value loss = 0.20903295278549194\n",
      "INFO 2024-12-04 20:20:33 pipeline.py:712] Training Step 34420: Policy loss = 1.5537467002868652, value loss = 0.20241796970367432\n",
      "INFO 2024-12-04 20:20:43 pipeline.py:712] Training Step 34440: Policy loss = 1.5427281856536865, value loss = 0.1907045543193817\n",
      "INFO 2024-12-04 20:20:53 pipeline.py:712] Training Step 34460: Policy loss = 1.5076220035552979, value loss = 0.2045111358165741\n",
      "INFO 2024-12-04 20:21:03 pipeline.py:712] Training Step 34480: Policy loss = 1.592984676361084, value loss = 0.2085314691066742\n",
      "INFO 2024-12-04 20:21:12 pipeline.py:712] Training Step 34500: Policy loss = 1.4496853351593018, value loss = 0.22878435254096985\n",
      "INFO 2024-12-04 20:21:22 pipeline.py:712] Training Step 34520: Policy loss = 1.5665825605392456, value loss = 0.22232119739055634\n",
      "INFO 2024-12-04 20:21:31 pipeline.py:712] Training Step 34540: Policy loss = 1.5420304536819458, value loss = 0.2188010811805725\n",
      "INFO 2024-12-04 20:21:41 pipeline.py:712] Training Step 34560: Policy loss = 1.4703311920166016, value loss = 0.19175554811954498\n",
      "INFO 2024-12-04 20:21:51 pipeline.py:712] Training Step 34580: Policy loss = 1.5320422649383545, value loss = 0.23137351870536804\n",
      "INFO 2024-12-04 20:22:00 pipeline.py:712] Training Step 34600: Policy loss = 1.5619393587112427, value loss = 0.21655775606632233\n",
      "INFO 2024-12-04 20:22:10 pipeline.py:712] Training Step 34620: Policy loss = 1.4709547758102417, value loss = 0.22219443321228027\n",
      "INFO 2024-12-04 20:22:20 pipeline.py:712] Training Step 34640: Policy loss = 1.5200172662734985, value loss = 0.20710334181785583\n",
      "INFO 2024-12-04 20:22:29 pipeline.py:712] Training Step 34660: Policy loss = 1.5144121646881104, value loss = 0.1920967698097229\n",
      "INFO 2024-12-04 20:22:39 pipeline.py:712] Training Step 34680: Policy loss = 1.5702260732650757, value loss = 0.2245369851589203\n",
      "INFO 2024-12-04 20:22:49 pipeline.py:712] Training Step 34700: Policy loss = 1.5117418766021729, value loss = 0.2392721027135849\n",
      "INFO 2024-12-04 20:22:58 pipeline.py:712] Training Step 34720: Policy loss = 1.4936652183532715, value loss = 0.2160007655620575\n",
      "INFO 2024-12-04 20:23:08 pipeline.py:712] Training Step 34740: Policy loss = 1.486429214477539, value loss = 0.21854937076568604\n",
      "INFO 2024-12-04 20:23:18 pipeline.py:712] Training Step 34760: Policy loss = 1.5461288690567017, value loss = 0.17250767350196838\n",
      "INFO 2024-12-04 20:23:27 pipeline.py:712] Training Step 34780: Policy loss = 1.4802837371826172, value loss = 0.1975686103105545\n",
      "INFO 2024-12-04 20:23:37 pipeline.py:712] Training Step 34800: Policy loss = 1.5017502307891846, value loss = 0.2210201919078827\n",
      "INFO 2024-12-04 20:23:47 pipeline.py:712] Training Step 34820: Policy loss = 1.6046903133392334, value loss = 0.19889375567436218\n",
      "INFO 2024-12-04 20:23:57 pipeline.py:712] Training Step 34840: Policy loss = 1.5386208295822144, value loss = 0.20838609337806702\n",
      "INFO 2024-12-04 20:24:18 pipeline.py:738] training_steps 34848: Validation loss: Poliy loss 1.8540982721281833, value_loss 0.4487844896121103\n",
      "INFO 2024-12-04 20:24:24 pipeline.py:712] Training Step 34860: Policy loss = 1.5173628330230713, value loss = 0.200601726770401\n",
      "INFO 2024-12-04 20:24:34 pipeline.py:712] Training Step 34880: Policy loss = 1.4814083576202393, value loss = 0.2096628099679947\n",
      "INFO 2024-12-04 20:24:43 pipeline.py:712] Training Step 34900: Policy loss = 1.5645413398742676, value loss = 0.2149323970079422\n",
      "INFO 2024-12-04 20:24:53 pipeline.py:712] Training Step 34920: Policy loss = 1.5611002445220947, value loss = 0.19070006906986237\n",
      "INFO 2024-12-04 20:25:03 pipeline.py:712] Training Step 34940: Policy loss = 1.6014314889907837, value loss = 0.20228436589241028\n",
      "INFO 2024-12-04 20:25:13 pipeline.py:712] Training Step 34960: Policy loss = 1.4909414052963257, value loss = 0.20354239642620087\n",
      "INFO 2024-12-04 20:25:22 pipeline.py:712] Training Step 34980: Policy loss = 1.5194272994995117, value loss = 0.2419775426387787\n",
      "INFO 2024-12-04 20:25:32 pipeline.py:712] Training Step 35000: Policy loss = 1.5256619453430176, value loss = 0.19477972388267517\n",
      "INFO 2024-12-04 20:25:42 pipeline.py:712] Training Step 35020: Policy loss = 1.5226848125457764, value loss = 0.20003268122673035\n",
      "INFO 2024-12-04 20:25:51 pipeline.py:712] Training Step 35040: Policy loss = 1.4496238231658936, value loss = 0.18781998753547668\n",
      "INFO 2024-12-04 20:26:01 pipeline.py:712] Training Step 35060: Policy loss = 1.541306972503662, value loss = 0.22157153487205505\n",
      "INFO 2024-12-04 20:26:11 pipeline.py:712] Training Step 35080: Policy loss = 1.4964141845703125, value loss = 0.23183003067970276\n",
      "INFO 2024-12-04 20:26:21 pipeline.py:712] Training Step 35100: Policy loss = 1.5102779865264893, value loss = 0.1942460685968399\n",
      "INFO 2024-12-04 20:26:31 pipeline.py:712] Training Step 35120: Policy loss = 1.4428153038024902, value loss = 0.24973735213279724\n",
      "INFO 2024-12-04 20:26:41 pipeline.py:712] Training Step 35140: Policy loss = 1.5724653005599976, value loss = 0.22665688395500183\n",
      "INFO 2024-12-04 20:26:50 pipeline.py:712] Training Step 35160: Policy loss = 1.4522404670715332, value loss = 0.23689627647399902\n",
      "INFO 2024-12-04 20:27:00 pipeline.py:712] Training Step 35180: Policy loss = 1.5135047435760498, value loss = 0.19925406575202942\n",
      "INFO 2024-12-04 20:27:10 pipeline.py:712] Training Step 35200: Policy loss = 1.5264263153076172, value loss = 0.20576676726341248\n",
      "INFO 2024-12-04 20:27:19 pipeline.py:712] Training Step 35220: Policy loss = 1.5398881435394287, value loss = 0.19863909482955933\n",
      "INFO 2024-12-04 20:27:29 pipeline.py:712] Training Step 35240: Policy loss = 1.4525065422058105, value loss = 0.189378023147583\n",
      "INFO 2024-12-04 20:27:39 pipeline.py:712] Training Step 35260: Policy loss = 1.4652353525161743, value loss = 0.2390907257795334\n",
      "INFO 2024-12-04 20:27:48 pipeline.py:712] Training Step 35280: Policy loss = 1.5556998252868652, value loss = 0.24292272329330444\n",
      "INFO 2024-12-04 20:27:58 pipeline.py:712] Training Step 35300: Policy loss = 1.4972238540649414, value loss = 0.22943802177906036\n",
      "INFO 2024-12-04 20:28:08 pipeline.py:712] Training Step 35320: Policy loss = 1.5138447284698486, value loss = 0.21374911069869995\n",
      "INFO 2024-12-04 20:28:31 pipeline.py:738] training_steps 35332: Validation loss: Poliy loss 1.8536754778174103, value_loss 0.44877583057176873\n",
      "INFO 2024-12-04 20:28:35 pipeline.py:712] Training Step 35340: Policy loss = 1.5410648584365845, value loss = 0.19986243546009064\n",
      "INFO 2024-12-04 20:28:45 pipeline.py:712] Training Step 35360: Policy loss = 1.5137691497802734, value loss = 0.21372148394584656\n",
      "INFO 2024-12-04 20:28:54 pipeline.py:712] Training Step 35380: Policy loss = 1.5032062530517578, value loss = 0.222603440284729\n",
      "INFO 2024-12-04 20:29:04 pipeline.py:712] Training Step 35400: Policy loss = 1.5230557918548584, value loss = 0.2061636745929718\n",
      "INFO 2024-12-04 20:29:14 pipeline.py:712] Training Step 35420: Policy loss = 1.5281851291656494, value loss = 0.1864059567451477\n",
      "INFO 2024-12-04 20:29:23 pipeline.py:712] Training Step 35440: Policy loss = 1.5255846977233887, value loss = 0.23612099885940552\n",
      "INFO 2024-12-04 20:29:33 pipeline.py:712] Training Step 35460: Policy loss = 1.5088574886322021, value loss = 0.21810835599899292\n",
      "INFO 2024-12-04 20:29:43 pipeline.py:712] Training Step 35480: Policy loss = 1.564051628112793, value loss = 0.22278034687042236\n",
      "INFO 2024-12-04 20:29:52 pipeline.py:712] Training Step 35500: Policy loss = 1.5599204301834106, value loss = 0.21027356386184692\n",
      "INFO 2024-12-04 20:30:02 pipeline.py:712] Training Step 35520: Policy loss = 1.5342411994934082, value loss = 0.1848759949207306\n",
      "INFO 2024-12-04 20:30:12 pipeline.py:712] Training Step 35540: Policy loss = 1.5469019412994385, value loss = 0.2052597552537918\n",
      "INFO 2024-12-04 20:30:21 pipeline.py:712] Training Step 35560: Policy loss = 1.5076634883880615, value loss = 0.18491928279399872\n",
      "INFO 2024-12-04 20:30:31 pipeline.py:712] Training Step 35580: Policy loss = 1.5507527589797974, value loss = 0.18045130372047424\n",
      "INFO 2024-12-04 20:30:40 pipeline.py:712] Training Step 35600: Policy loss = 1.5334265232086182, value loss = 0.2360430508852005\n",
      "INFO 2024-12-04 20:30:50 pipeline.py:712] Training Step 35620: Policy loss = 1.6125959157943726, value loss = 0.19105809926986694\n",
      "INFO 2024-12-04 20:31:00 pipeline.py:712] Training Step 35640: Policy loss = 1.5035476684570312, value loss = 0.2100968360900879\n",
      "INFO 2024-12-04 20:31:09 pipeline.py:712] Training Step 35660: Policy loss = 1.524705410003662, value loss = 0.2244207262992859\n",
      "INFO 2024-12-04 20:31:19 pipeline.py:712] Training Step 35680: Policy loss = 1.5459537506103516, value loss = 0.21966341137886047\n",
      "INFO 2024-12-04 20:31:29 pipeline.py:712] Training Step 35700: Policy loss = 1.5500342845916748, value loss = 0.19380880892276764\n",
      "INFO 2024-12-04 20:31:38 pipeline.py:712] Training Step 35720: Policy loss = 1.514630675315857, value loss = 0.20805072784423828\n",
      "INFO 2024-12-04 20:31:48 pipeline.py:712] Training Step 35740: Policy loss = 1.473585844039917, value loss = 0.2205989509820938\n",
      "INFO 2024-12-04 20:31:57 pipeline.py:712] Training Step 35760: Policy loss = 1.4485106468200684, value loss = 0.20508252084255219\n",
      "INFO 2024-12-04 20:32:07 pipeline.py:712] Training Step 35780: Policy loss = 1.5265438556671143, value loss = 0.21901777386665344\n",
      "INFO 2024-12-04 20:32:17 pipeline.py:712] Training Step 35800: Policy loss = 1.5074818134307861, value loss = 0.22325022518634796\n",
      "INFO 2024-12-04 20:32:42 pipeline.py:738] training_steps 35816: Validation loss: Poliy loss 1.8542970428701306, value_loss 0.44941479602798085\n",
      "INFO 2024-12-04 20:32:44 pipeline.py:712] Training Step 35820: Policy loss = 1.5107566118240356, value loss = 0.20475386083126068\n",
      "INFO 2024-12-04 20:32:54 pipeline.py:712] Training Step 35840: Policy loss = 1.4875893592834473, value loss = 0.21270042657852173\n",
      "INFO 2024-12-04 20:33:03 pipeline.py:712] Training Step 35860: Policy loss = 1.4595367908477783, value loss = 0.20334646105766296\n",
      "INFO 2024-12-04 20:33:13 pipeline.py:712] Training Step 35880: Policy loss = 1.4657132625579834, value loss = 0.19054394960403442\n",
      "INFO 2024-12-04 20:33:23 pipeline.py:712] Training Step 35900: Policy loss = 1.5152382850646973, value loss = 0.21306201815605164\n",
      "INFO 2024-12-04 20:33:32 pipeline.py:712] Training Step 35920: Policy loss = 1.5028613805770874, value loss = 0.22129732370376587\n",
      "INFO 2024-12-04 20:33:42 pipeline.py:712] Training Step 35940: Policy loss = 1.5446608066558838, value loss = 0.25786706805229187\n",
      "INFO 2024-12-04 20:33:52 pipeline.py:712] Training Step 35960: Policy loss = 1.4979848861694336, value loss = 0.20733657479286194\n",
      "INFO 2024-12-04 20:34:01 pipeline.py:712] Training Step 35980: Policy loss = 1.4756944179534912, value loss = 0.24299810826778412\n",
      "INFO 2024-12-04 20:34:11 pipeline.py:712] Training Step 36000: Policy loss = 1.4491369724273682, value loss = 0.20127630233764648\n",
      "INFO 2024-12-04 20:34:21 pipeline.py:712] Training Step 36020: Policy loss = 1.495193362236023, value loss = 0.18887275457382202\n",
      "INFO 2024-12-04 20:34:30 pipeline.py:712] Training Step 36040: Policy loss = 1.500195026397705, value loss = 0.21989576518535614\n",
      "INFO 2024-12-04 20:34:40 pipeline.py:712] Training Step 36060: Policy loss = 1.4830172061920166, value loss = 0.20114955306053162\n",
      "INFO 2024-12-04 20:34:49 pipeline.py:712] Training Step 36080: Policy loss = 1.4544501304626465, value loss = 0.2202310860157013\n",
      "INFO 2024-12-04 20:34:59 pipeline.py:712] Training Step 36100: Policy loss = 1.5045359134674072, value loss = 0.23148439824581146\n",
      "INFO 2024-12-04 20:35:09 pipeline.py:712] Training Step 36120: Policy loss = 1.5526022911071777, value loss = 0.21822023391723633\n",
      "INFO 2024-12-04 20:35:18 pipeline.py:712] Training Step 36140: Policy loss = 1.5083751678466797, value loss = 0.22844642400741577\n",
      "INFO 2024-12-04 20:35:28 pipeline.py:712] Training Step 36160: Policy loss = 1.4693069458007812, value loss = 0.21685796976089478\n",
      "INFO 2024-12-04 20:35:37 pipeline.py:712] Training Step 36180: Policy loss = 1.4731189012527466, value loss = 0.23904570937156677\n",
      "INFO 2024-12-04 20:35:47 pipeline.py:712] Training Step 36200: Policy loss = 1.5126070976257324, value loss = 0.2311202436685562\n",
      "INFO 2024-12-04 20:35:57 pipeline.py:712] Training Step 36220: Policy loss = 1.430257797241211, value loss = 0.24797165393829346\n",
      "INFO 2024-12-04 20:36:06 pipeline.py:712] Training Step 36240: Policy loss = 1.5328775644302368, value loss = 0.22047151625156403\n",
      "INFO 2024-12-04 20:36:16 pipeline.py:712] Training Step 36260: Policy loss = 1.5496996641159058, value loss = 0.23323404788970947\n",
      "INFO 2024-12-04 20:36:25 pipeline.py:712] Training Step 36280: Policy loss = 1.5133110284805298, value loss = 0.17764157056808472\n",
      "INFO 2024-12-04 20:36:35 pipeline.py:712] Training Step 36300: Policy loss = 1.4931247234344482, value loss = 0.18957281112670898\n",
      "INFO 2024-12-04 20:36:53 pipeline.py:738] training_steps 36300: Validation loss: Poliy loss 1.8542333851095105, value_loss 0.4496931392149847\n",
      "INFO 2024-12-04 20:37:02 pipeline.py:712] Training Step 36320: Policy loss = 1.4479988813400269, value loss = 0.22450628876686096\n",
      "INFO 2024-12-04 20:37:12 pipeline.py:712] Training Step 36340: Policy loss = 1.4796119928359985, value loss = 0.21782901883125305\n",
      "INFO 2024-12-04 20:37:22 pipeline.py:712] Training Step 36360: Policy loss = 1.5144504308700562, value loss = 0.20920366048812866\n",
      "INFO 2024-12-04 20:37:31 pipeline.py:712] Training Step 36380: Policy loss = 1.5315757989883423, value loss = 0.21442893147468567\n",
      "INFO 2024-12-04 20:37:41 pipeline.py:712] Training Step 36400: Policy loss = 1.5071512460708618, value loss = 0.21596774458885193\n",
      "INFO 2024-12-04 20:37:51 pipeline.py:712] Training Step 36420: Policy loss = 1.4056934118270874, value loss = 0.20315420627593994\n",
      "INFO 2024-12-04 20:38:00 pipeline.py:712] Training Step 36440: Policy loss = 1.4509855508804321, value loss = 0.21550682187080383\n",
      "INFO 2024-12-04 20:38:10 pipeline.py:712] Training Step 36460: Policy loss = 1.421879529953003, value loss = 0.19755704700946808\n",
      "INFO 2024-12-04 20:38:19 pipeline.py:712] Training Step 36480: Policy loss = 1.5595347881317139, value loss = 0.19572125375270844\n",
      "INFO 2024-12-04 20:38:29 pipeline.py:712] Training Step 36500: Policy loss = 1.5208313465118408, value loss = 0.2130160629749298\n",
      "INFO 2024-12-04 20:38:39 pipeline.py:712] Training Step 36520: Policy loss = 1.4561598300933838, value loss = 0.19599081575870514\n",
      "INFO 2024-12-04 20:38:48 pipeline.py:712] Training Step 36540: Policy loss = 1.503275752067566, value loss = 0.22480015456676483\n",
      "INFO 2024-12-04 20:38:58 pipeline.py:712] Training Step 36560: Policy loss = 1.5114587545394897, value loss = 0.21201542019844055\n",
      "INFO 2024-12-04 20:39:07 pipeline.py:712] Training Step 36580: Policy loss = 1.527125358581543, value loss = 0.1977819949388504\n",
      "INFO 2024-12-04 20:39:17 pipeline.py:712] Training Step 36600: Policy loss = 1.4338703155517578, value loss = 0.21831560134887695\n",
      "INFO 2024-12-04 20:39:27 pipeline.py:712] Training Step 36620: Policy loss = 1.5339467525482178, value loss = 0.2213301956653595\n",
      "INFO 2024-12-04 20:39:36 pipeline.py:712] Training Step 36640: Policy loss = 1.4866523742675781, value loss = 0.20270134508609772\n",
      "INFO 2024-12-04 20:39:46 pipeline.py:712] Training Step 36660: Policy loss = 1.5754950046539307, value loss = 0.21444205939769745\n",
      "INFO 2024-12-04 20:39:55 pipeline.py:712] Training Step 36680: Policy loss = 1.4448387622833252, value loss = 0.2112204134464264\n",
      "INFO 2024-12-04 20:40:05 pipeline.py:712] Training Step 36700: Policy loss = 1.530877709388733, value loss = 0.20429250597953796\n",
      "INFO 2024-12-04 20:40:14 pipeline.py:712] Training Step 36720: Policy loss = 1.5392706394195557, value loss = 0.18904314935207367\n",
      "INFO 2024-12-04 20:40:24 pipeline.py:712] Training Step 36740: Policy loss = 1.5753896236419678, value loss = 0.22098040580749512\n",
      "INFO 2024-12-04 20:40:34 pipeline.py:712] Training Step 36760: Policy loss = 1.540157675743103, value loss = 0.2179548144340515\n",
      "INFO 2024-12-04 20:40:43 pipeline.py:712] Training Step 36780: Policy loss = 1.509645700454712, value loss = 0.21701809763908386\n",
      "INFO 2024-12-04 20:41:03 pipeline.py:738] training_steps 36784: Validation loss: Poliy loss 1.8540272663851254, value_loss 0.4494496180874402\n",
      "INFO 2024-12-04 20:41:11 pipeline.py:712] Training Step 36800: Policy loss = 1.500089406967163, value loss = 0.22094544768333435\n",
      "INFO 2024-12-04 20:41:20 pipeline.py:712] Training Step 36820: Policy loss = 1.5405806303024292, value loss = 0.20158927142620087\n",
      "INFO 2024-12-04 20:41:30 pipeline.py:712] Training Step 36840: Policy loss = 1.4924896955490112, value loss = 0.2180890142917633\n",
      "INFO 2024-12-04 20:41:40 pipeline.py:712] Training Step 36860: Policy loss = 1.5003819465637207, value loss = 0.2170943319797516\n",
      "INFO 2024-12-04 20:41:49 pipeline.py:712] Training Step 36880: Policy loss = 1.554339051246643, value loss = 0.20884467661380768\n",
      "INFO 2024-12-04 20:41:59 pipeline.py:712] Training Step 36900: Policy loss = 1.5150878429412842, value loss = 0.20961114764213562\n",
      "INFO 2024-12-04 20:42:08 pipeline.py:712] Training Step 36920: Policy loss = 1.523575782775879, value loss = 0.2318987250328064\n",
      "INFO 2024-12-04 20:42:18 pipeline.py:712] Training Step 36940: Policy loss = 1.4635915756225586, value loss = 0.2320292443037033\n",
      "INFO 2024-12-04 20:42:28 pipeline.py:712] Training Step 36960: Policy loss = 1.5167865753173828, value loss = 0.22231629490852356\n",
      "INFO 2024-12-04 20:42:37 pipeline.py:712] Training Step 36980: Policy loss = 1.4956015348434448, value loss = 0.19141195714473724\n",
      "INFO 2024-12-04 20:42:47 pipeline.py:712] Training Step 37000: Policy loss = 1.535824179649353, value loss = 0.2084302455186844\n",
      "INFO 2024-12-04 20:42:56 pipeline.py:712] Training Step 37020: Policy loss = 1.5977308750152588, value loss = 0.19302505254745483\n",
      "INFO 2024-12-04 20:43:06 pipeline.py:712] Training Step 37040: Policy loss = 1.5615781545639038, value loss = 0.23152266442775726\n",
      "INFO 2024-12-04 20:43:16 pipeline.py:712] Training Step 37060: Policy loss = 1.4274982213974, value loss = 0.24726206064224243\n",
      "INFO 2024-12-04 20:43:25 pipeline.py:712] Training Step 37080: Policy loss = 1.5061981678009033, value loss = 0.23274943232536316\n",
      "INFO 2024-12-04 20:43:35 pipeline.py:712] Training Step 37100: Policy loss = 1.544373869895935, value loss = 0.22429800033569336\n",
      "INFO 2024-12-04 20:43:44 pipeline.py:712] Training Step 37120: Policy loss = 1.4989620447158813, value loss = 0.19835913181304932\n",
      "INFO 2024-12-04 20:43:54 pipeline.py:712] Training Step 37140: Policy loss = 1.510327935218811, value loss = 0.26992160081863403\n",
      "INFO 2024-12-04 20:44:04 pipeline.py:712] Training Step 37160: Policy loss = 1.5378435850143433, value loss = 0.21099701523780823\n",
      "INFO 2024-12-04 20:44:13 pipeline.py:712] Training Step 37180: Policy loss = 1.5113039016723633, value loss = 0.23896296322345734\n",
      "INFO 2024-12-04 20:44:23 pipeline.py:712] Training Step 37200: Policy loss = 1.5019583702087402, value loss = 0.21595823764801025\n",
      "INFO 2024-12-04 20:44:33 pipeline.py:712] Training Step 37220: Policy loss = 1.4976942539215088, value loss = 0.23870551586151123\n",
      "INFO 2024-12-04 20:44:42 pipeline.py:712] Training Step 37240: Policy loss = 1.4922151565551758, value loss = 0.18714308738708496\n",
      "INFO 2024-12-04 20:44:52 pipeline.py:712] Training Step 37260: Policy loss = 1.4620091915130615, value loss = 0.23528863489627838\n",
      "INFO 2024-12-04 20:45:13 pipeline.py:738] training_steps 37268: Validation loss: Poliy loss 1.8550008466986359, value_loss 0.4500329020570536\n",
      "INFO 2024-12-04 20:45:19 pipeline.py:712] Training Step 37280: Policy loss = 1.5923970937728882, value loss = 0.2076314091682434\n",
      "INFO 2024-12-04 20:45:29 pipeline.py:712] Training Step 37300: Policy loss = 1.574783205986023, value loss = 0.23102283477783203\n",
      "INFO 2024-12-04 20:45:38 pipeline.py:712] Training Step 37320: Policy loss = 1.505277156829834, value loss = 0.18970277905464172\n",
      "INFO 2024-12-04 20:45:48 pipeline.py:712] Training Step 37340: Policy loss = 1.4971072673797607, value loss = 0.24085897207260132\n",
      "INFO 2024-12-04 20:45:58 pipeline.py:712] Training Step 37360: Policy loss = 1.4794037342071533, value loss = 0.22311434149742126\n",
      "INFO 2024-12-04 20:46:07 pipeline.py:712] Training Step 37380: Policy loss = 1.5809247493743896, value loss = 0.20633406937122345\n",
      "INFO 2024-12-04 20:46:17 pipeline.py:712] Training Step 37400: Policy loss = 1.5757331848144531, value loss = 0.1871129870414734\n",
      "INFO 2024-12-04 20:46:26 pipeline.py:712] Training Step 37420: Policy loss = 1.5857481956481934, value loss = 0.21815350651741028\n",
      "INFO 2024-12-04 20:46:36 pipeline.py:712] Training Step 37440: Policy loss = 1.5002250671386719, value loss = 0.21573224663734436\n",
      "INFO 2024-12-04 20:46:46 pipeline.py:712] Training Step 37460: Policy loss = 1.4954086542129517, value loss = 0.23166118562221527\n",
      "INFO 2024-12-04 20:46:55 pipeline.py:712] Training Step 37480: Policy loss = 1.4986752271652222, value loss = 0.20097967982292175\n",
      "INFO 2024-12-04 20:47:05 pipeline.py:712] Training Step 37500: Policy loss = 1.537050485610962, value loss = 0.23284344375133514\n",
      "INFO 2024-12-04 20:47:14 pipeline.py:712] Training Step 37520: Policy loss = 1.4865633249282837, value loss = 0.20806929469108582\n",
      "INFO 2024-12-04 20:47:24 pipeline.py:712] Training Step 37540: Policy loss = 1.527791976928711, value loss = 0.2087002396583557\n",
      "INFO 2024-12-04 20:47:33 pipeline.py:712] Training Step 37560: Policy loss = 1.5113825798034668, value loss = 0.2154540717601776\n",
      "INFO 2024-12-04 20:47:43 pipeline.py:712] Training Step 37580: Policy loss = 1.4528815746307373, value loss = 0.22205550968647003\n",
      "INFO 2024-12-04 20:47:53 pipeline.py:712] Training Step 37600: Policy loss = 1.5340495109558105, value loss = 0.1946767270565033\n",
      "INFO 2024-12-04 20:48:03 pipeline.py:712] Training Step 37620: Policy loss = 1.5236120223999023, value loss = 0.20075461268424988\n",
      "INFO 2024-12-04 20:48:12 pipeline.py:712] Training Step 37640: Policy loss = 1.445676326751709, value loss = 0.2126346081495285\n",
      "INFO 2024-12-04 20:48:22 pipeline.py:712] Training Step 37660: Policy loss = 1.4590232372283936, value loss = 0.22719427943229675\n",
      "INFO 2024-12-04 20:48:31 pipeline.py:712] Training Step 37680: Policy loss = 1.4376003742218018, value loss = 0.201006680727005\n",
      "INFO 2024-12-04 20:48:41 pipeline.py:712] Training Step 37700: Policy loss = 1.492274522781372, value loss = 0.2095656394958496\n",
      "INFO 2024-12-04 20:48:51 pipeline.py:712] Training Step 37720: Policy loss = 1.53218674659729, value loss = 0.2178179919719696\n",
      "INFO 2024-12-04 20:49:00 pipeline.py:712] Training Step 37740: Policy loss = 1.4414700269699097, value loss = 0.20488208532333374\n",
      "INFO 2024-12-04 20:49:24 pipeline.py:738] training_steps 37752: Validation loss: Poliy loss 1.8542164573903943, value_loss 0.4502264571483018\n",
      "INFO 2024-12-04 20:49:27 pipeline.py:712] Training Step 37760: Policy loss = 1.51945161819458, value loss = 0.22316236793994904\n",
      "INFO 2024-12-04 20:49:37 pipeline.py:712] Training Step 37780: Policy loss = 1.5286247730255127, value loss = 0.17323239147663116\n",
      "INFO 2024-12-04 20:49:46 pipeline.py:712] Training Step 37800: Policy loss = 1.522867202758789, value loss = 0.1987682431936264\n",
      "INFO 2024-12-04 20:49:56 pipeline.py:712] Training Step 37820: Policy loss = 1.4829574823379517, value loss = 0.21075907349586487\n",
      "INFO 2024-12-04 20:50:06 pipeline.py:712] Training Step 37840: Policy loss = 1.46633780002594, value loss = 0.20343199372291565\n",
      "INFO 2024-12-04 20:50:15 pipeline.py:712] Training Step 37860: Policy loss = 1.5392227172851562, value loss = 0.2030160129070282\n",
      "INFO 2024-12-04 20:50:25 pipeline.py:712] Training Step 37880: Policy loss = 1.4729171991348267, value loss = 0.19554653763771057\n",
      "INFO 2024-12-04 20:50:34 pipeline.py:712] Training Step 37900: Policy loss = 1.6129199266433716, value loss = 0.21664705872535706\n",
      "INFO 2024-12-04 20:50:44 pipeline.py:712] Training Step 37920: Policy loss = 1.499427080154419, value loss = 0.20363765954971313\n",
      "INFO 2024-12-04 20:50:54 pipeline.py:712] Training Step 37940: Policy loss = 1.4226858615875244, value loss = 0.18985186517238617\n",
      "INFO 2024-12-04 20:51:03 pipeline.py:712] Training Step 37960: Policy loss = 1.5039703845977783, value loss = 0.20598724484443665\n",
      "INFO 2024-12-04 20:51:13 pipeline.py:712] Training Step 37980: Policy loss = 1.4811753034591675, value loss = 0.20391759276390076\n",
      "INFO 2024-12-04 20:51:22 pipeline.py:712] Training Step 38000: Policy loss = 1.4534525871276855, value loss = 0.22458967566490173\n",
      "INFO 2024-12-04 20:51:32 pipeline.py:712] Training Step 38020: Policy loss = 1.5415159463882446, value loss = 0.23079374432563782\n",
      "INFO 2024-12-04 20:51:41 pipeline.py:712] Training Step 38040: Policy loss = 1.5175573825836182, value loss = 0.18514424562454224\n",
      "INFO 2024-12-04 20:51:51 pipeline.py:712] Training Step 38060: Policy loss = 1.5584475994110107, value loss = 0.21079802513122559\n",
      "INFO 2024-12-04 20:52:01 pipeline.py:712] Training Step 38080: Policy loss = 1.5072226524353027, value loss = 0.20639261603355408\n",
      "INFO 2024-12-04 20:52:10 pipeline.py:712] Training Step 38100: Policy loss = 1.520472526550293, value loss = 0.19967560470104218\n",
      "INFO 2024-12-04 20:52:20 pipeline.py:712] Training Step 38120: Policy loss = 1.5891189575195312, value loss = 0.2167074978351593\n",
      "INFO 2024-12-04 20:52:29 pipeline.py:712] Training Step 38140: Policy loss = 1.506744623184204, value loss = 0.22689157724380493\n",
      "INFO 2024-12-04 20:52:39 pipeline.py:712] Training Step 38160: Policy loss = 1.506291151046753, value loss = 0.21176087856292725\n",
      "INFO 2024-12-04 20:52:49 pipeline.py:712] Training Step 38180: Policy loss = 1.5816045999526978, value loss = 0.18620404601097107\n",
      "INFO 2024-12-04 20:52:58 pipeline.py:712] Training Step 38200: Policy loss = 1.5447790622711182, value loss = 0.19290465116500854\n",
      "INFO 2024-12-04 20:53:08 pipeline.py:712] Training Step 38220: Policy loss = 1.5082321166992188, value loss = 0.19656026363372803\n",
      "INFO 2024-12-04 20:53:33 pipeline.py:738] training_steps 38236: Validation loss: Poliy loss 1.8539291375973186, value_loss 0.449932655594388\n",
      "INFO 2024-12-04 20:53:35 pipeline.py:712] Training Step 38240: Policy loss = 1.5407955646514893, value loss = 0.18504585325717926\n",
      "INFO 2024-12-04 20:53:44 pipeline.py:712] Training Step 38260: Policy loss = 1.5331218242645264, value loss = 0.19841726124286652\n",
      "INFO 2024-12-04 20:53:54 pipeline.py:712] Training Step 38280: Policy loss = 1.542797565460205, value loss = 0.23376259207725525\n",
      "INFO 2024-12-04 20:54:04 pipeline.py:712] Training Step 38300: Policy loss = 1.5175185203552246, value loss = 0.20731399953365326\n",
      "INFO 2024-12-04 20:54:13 pipeline.py:712] Training Step 38320: Policy loss = 1.4886727333068848, value loss = 0.19565671682357788\n",
      "INFO 2024-12-04 20:54:23 pipeline.py:712] Training Step 38340: Policy loss = 1.5568294525146484, value loss = 0.22566774487495422\n",
      "INFO 2024-12-04 20:54:32 pipeline.py:712] Training Step 38360: Policy loss = 1.5422043800354004, value loss = 0.22125759720802307\n",
      "INFO 2024-12-04 20:54:42 pipeline.py:712] Training Step 38380: Policy loss = 1.5214099884033203, value loss = 0.2031501680612564\n",
      "INFO 2024-12-04 20:54:51 pipeline.py:712] Training Step 38400: Policy loss = 1.4703437089920044, value loss = 0.22074991464614868\n",
      "INFO 2024-12-04 20:55:01 pipeline.py:712] Training Step 38420: Policy loss = 1.5298147201538086, value loss = 0.20859840512275696\n",
      "INFO 2024-12-04 20:55:11 pipeline.py:712] Training Step 38440: Policy loss = 1.448535680770874, value loss = 0.20336976647377014\n",
      "INFO 2024-12-04 20:55:20 pipeline.py:712] Training Step 38460: Policy loss = 1.52642023563385, value loss = 0.2573484778404236\n",
      "INFO 2024-12-04 20:55:30 pipeline.py:712] Training Step 38480: Policy loss = 1.4833476543426514, value loss = 0.2079603672027588\n",
      "INFO 2024-12-04 20:55:39 pipeline.py:712] Training Step 38500: Policy loss = 1.4407124519348145, value loss = 0.22132739424705505\n",
      "INFO 2024-12-04 20:55:49 pipeline.py:712] Training Step 38520: Policy loss = 1.471205711364746, value loss = 0.19484290480613708\n",
      "INFO 2024-12-04 20:55:59 pipeline.py:712] Training Step 38540: Policy loss = 1.3928020000457764, value loss = 0.19967742264270782\n",
      "INFO 2024-12-04 20:56:08 pipeline.py:712] Training Step 38560: Policy loss = 1.5000059604644775, value loss = 0.23135124146938324\n",
      "INFO 2024-12-04 20:56:18 pipeline.py:712] Training Step 38580: Policy loss = 1.495548129081726, value loss = 0.2016328126192093\n",
      "INFO 2024-12-04 20:56:27 pipeline.py:712] Training Step 38600: Policy loss = 1.510443091392517, value loss = 0.1815893054008484\n",
      "INFO 2024-12-04 20:56:37 pipeline.py:712] Training Step 38620: Policy loss = 1.600678563117981, value loss = 0.23435550928115845\n",
      "INFO 2024-12-04 20:56:46 pipeline.py:712] Training Step 38640: Policy loss = 1.4539120197296143, value loss = 0.22548601031303406\n",
      "INFO 2024-12-04 20:56:56 pipeline.py:712] Training Step 38660: Policy loss = 1.4665374755859375, value loss = 0.21857038140296936\n",
      "INFO 2024-12-04 20:57:06 pipeline.py:712] Training Step 38680: Policy loss = 1.5520668029785156, value loss = 0.1966443657875061\n",
      "INFO 2024-12-04 20:57:15 pipeline.py:712] Training Step 38700: Policy loss = 1.5498358011245728, value loss = 0.20320814847946167\n",
      "INFO 2024-12-04 20:57:25 pipeline.py:712] Training Step 38720: Policy loss = 1.5679657459259033, value loss = 0.20948809385299683\n",
      "INFO 2024-12-04 20:57:43 pipeline.py:738] training_steps 38720: Validation loss: Poliy loss 1.8548021658522185, value_loss 0.45091926172131397\n",
      "INFO 2024-12-04 20:57:52 pipeline.py:712] Training Step 38740: Policy loss = 1.4601123332977295, value loss = 0.2031550258398056\n",
      "INFO 2024-12-04 20:58:02 pipeline.py:712] Training Step 38760: Policy loss = 1.410170555114746, value loss = 0.24465890228748322\n",
      "INFO 2024-12-04 20:58:12 pipeline.py:712] Training Step 38780: Policy loss = 1.5220260620117188, value loss = 0.18722659349441528\n",
      "INFO 2024-12-04 20:58:21 pipeline.py:712] Training Step 38800: Policy loss = 1.4825191497802734, value loss = 0.220787912607193\n",
      "INFO 2024-12-04 20:58:31 pipeline.py:712] Training Step 38820: Policy loss = 1.527166485786438, value loss = 0.20696061849594116\n",
      "INFO 2024-12-04 20:58:40 pipeline.py:712] Training Step 38840: Policy loss = 1.4260811805725098, value loss = 0.21367397904396057\n",
      "INFO 2024-12-04 20:58:50 pipeline.py:712] Training Step 38860: Policy loss = 1.5143530368804932, value loss = 0.2216804027557373\n",
      "INFO 2024-12-04 20:58:59 pipeline.py:712] Training Step 38880: Policy loss = 1.5226857662200928, value loss = 0.18099482357501984\n",
      "INFO 2024-12-04 20:59:09 pipeline.py:712] Training Step 38900: Policy loss = 1.4631850719451904, value loss = 0.2333059012889862\n",
      "INFO 2024-12-04 20:59:19 pipeline.py:712] Training Step 38920: Policy loss = 1.5538074970245361, value loss = 0.1982012689113617\n",
      "INFO 2024-12-04 20:59:28 pipeline.py:712] Training Step 38940: Policy loss = 1.4769859313964844, value loss = 0.1959843933582306\n",
      "INFO 2024-12-04 20:59:38 pipeline.py:712] Training Step 38960: Policy loss = 1.503741979598999, value loss = 0.18142752349376678\n",
      "INFO 2024-12-04 20:59:47 pipeline.py:712] Training Step 38980: Policy loss = 1.532729148864746, value loss = 0.2241508811712265\n",
      "INFO 2024-12-04 20:59:57 pipeline.py:712] Training Step 39000: Policy loss = 1.5506609678268433, value loss = 0.22848033905029297\n",
      "INFO 2024-12-04 21:00:06 pipeline.py:712] Training Step 39020: Policy loss = 1.4972267150878906, value loss = 0.19361793994903564\n",
      "INFO 2024-12-04 21:00:16 pipeline.py:712] Training Step 39040: Policy loss = 1.4186404943466187, value loss = 0.2277340441942215\n",
      "INFO 2024-12-04 21:00:26 pipeline.py:712] Training Step 39060: Policy loss = 1.5079991817474365, value loss = 0.19932076334953308\n",
      "INFO 2024-12-04 21:00:35 pipeline.py:712] Training Step 39080: Policy loss = 1.5197415351867676, value loss = 0.22614780068397522\n",
      "INFO 2024-12-04 21:00:45 pipeline.py:712] Training Step 39100: Policy loss = 1.5455121994018555, value loss = 0.22992607951164246\n",
      "INFO 2024-12-04 21:00:54 pipeline.py:712] Training Step 39120: Policy loss = 1.5471596717834473, value loss = 0.22588442265987396\n",
      "INFO 2024-12-04 21:01:04 pipeline.py:712] Training Step 39140: Policy loss = 1.5534842014312744, value loss = 0.2178477644920349\n",
      "INFO 2024-12-04 21:01:13 pipeline.py:712] Training Step 39160: Policy loss = 1.5241338014602661, value loss = 0.2002016007900238\n",
      "INFO 2024-12-04 21:01:23 pipeline.py:712] Training Step 39180: Policy loss = 1.5346513986587524, value loss = 0.21789947152137756\n",
      "INFO 2024-12-04 21:01:32 pipeline.py:712] Training Step 39200: Policy loss = 1.4637452363967896, value loss = 0.19055964052677155\n",
      "INFO 2024-12-04 21:01:52 pipeline.py:738] training_steps 39204: Validation loss: Poliy loss 1.8548588293497679, value_loss 0.4503844443891869\n",
      "INFO 2024-12-04 21:02:00 pipeline.py:712] Training Step 39220: Policy loss = 1.5449249744415283, value loss = 0.21841108798980713\n",
      "INFO 2024-12-04 21:02:09 pipeline.py:712] Training Step 39240: Policy loss = 1.5796409845352173, value loss = 0.19558262825012207\n",
      "INFO 2024-12-04 21:02:19 pipeline.py:712] Training Step 39260: Policy loss = 1.51763117313385, value loss = 0.21812328696250916\n",
      "INFO 2024-12-04 21:02:29 pipeline.py:712] Training Step 39280: Policy loss = 1.4879363775253296, value loss = 0.19719630479812622\n",
      "INFO 2024-12-04 21:02:38 pipeline.py:712] Training Step 39300: Policy loss = 1.5125489234924316, value loss = 0.24057358503341675\n",
      "INFO 2024-12-04 21:02:48 pipeline.py:712] Training Step 39320: Policy loss = 1.5059512853622437, value loss = 0.2286992073059082\n",
      "INFO 2024-12-04 21:02:57 pipeline.py:712] Training Step 39340: Policy loss = 1.4988330602645874, value loss = 0.23835279047489166\n",
      "INFO 2024-12-04 21:03:07 pipeline.py:712] Training Step 39360: Policy loss = 1.4450321197509766, value loss = 0.21718809008598328\n",
      "INFO 2024-12-04 21:03:17 pipeline.py:712] Training Step 39380: Policy loss = 1.4302451610565186, value loss = 0.22010043263435364\n",
      "INFO 2024-12-04 21:03:26 pipeline.py:712] Training Step 39400: Policy loss = 1.4648194313049316, value loss = 0.1950872391462326\n",
      "INFO 2024-12-04 21:03:36 pipeline.py:712] Training Step 39420: Policy loss = 1.5242081880569458, value loss = 0.21905353665351868\n",
      "INFO 2024-12-04 21:03:45 pipeline.py:712] Training Step 39440: Policy loss = 1.470005750656128, value loss = 0.22078154981136322\n",
      "INFO 2024-12-04 21:03:55 pipeline.py:712] Training Step 39460: Policy loss = 1.5923115015029907, value loss = 0.21013590693473816\n",
      "INFO 2024-12-04 21:04:04 pipeline.py:712] Training Step 39480: Policy loss = 1.486006736755371, value loss = 0.21612665057182312\n",
      "INFO 2024-12-04 21:04:14 pipeline.py:712] Training Step 39500: Policy loss = 1.480762243270874, value loss = 0.22451192140579224\n",
      "INFO 2024-12-04 21:04:24 pipeline.py:712] Training Step 39520: Policy loss = 1.4987602233886719, value loss = 0.2061139941215515\n",
      "INFO 2024-12-04 21:04:33 pipeline.py:712] Training Step 39540: Policy loss = 1.4828147888183594, value loss = 0.2062312364578247\n",
      "INFO 2024-12-04 21:04:43 pipeline.py:712] Training Step 39560: Policy loss = 1.5297889709472656, value loss = 0.21618562936782837\n",
      "INFO 2024-12-04 21:04:52 pipeline.py:712] Training Step 39580: Policy loss = 1.4423599243164062, value loss = 0.17748510837554932\n",
      "INFO 2024-12-04 21:05:02 pipeline.py:712] Training Step 39600: Policy loss = 1.5506523847579956, value loss = 0.20049630105495453\n",
      "INFO 2024-12-04 21:05:12 pipeline.py:712] Training Step 39620: Policy loss = 1.5493485927581787, value loss = 0.20078334212303162\n",
      "INFO 2024-12-04 21:05:21 pipeline.py:712] Training Step 39640: Policy loss = 1.4367642402648926, value loss = 0.19365358352661133\n",
      "INFO 2024-12-04 21:05:31 pipeline.py:712] Training Step 39660: Policy loss = 1.4766182899475098, value loss = 0.2238306701183319\n",
      "INFO 2024-12-04 21:05:40 pipeline.py:712] Training Step 39680: Policy loss = 1.472631812095642, value loss = 0.16559256613254547\n",
      "INFO 2024-12-04 21:06:02 pipeline.py:738] training_steps 39688: Validation loss: Poliy loss 1.8551093603743882, value_loss 0.4509607289658218\n",
      "INFO 2024-12-04 21:06:07 pipeline.py:712] Training Step 39700: Policy loss = 1.4541765451431274, value loss = 0.2008703351020813\n",
      "INFO 2024-12-04 21:06:17 pipeline.py:712] Training Step 39720: Policy loss = 1.5390074253082275, value loss = 0.20047622919082642\n",
      "INFO 2024-12-04 21:06:27 pipeline.py:712] Training Step 39740: Policy loss = 1.4686791896820068, value loss = 0.1950218379497528\n",
      "INFO 2024-12-04 21:06:36 pipeline.py:712] Training Step 39760: Policy loss = 1.449432611465454, value loss = 0.1761849820613861\n",
      "INFO 2024-12-04 21:06:46 pipeline.py:712] Training Step 39780: Policy loss = 1.482623815536499, value loss = 0.1936662197113037\n",
      "INFO 2024-12-04 21:06:55 pipeline.py:712] Training Step 39800: Policy loss = 1.5810484886169434, value loss = 0.1869107335805893\n",
      "INFO 2024-12-04 21:07:05 pipeline.py:712] Training Step 39820: Policy loss = 1.5225939750671387, value loss = 0.2174375355243683\n",
      "INFO 2024-12-04 21:07:14 pipeline.py:712] Training Step 39840: Policy loss = 1.495361566543579, value loss = 0.2125958502292633\n",
      "INFO 2024-12-04 21:07:24 pipeline.py:712] Training Step 39860: Policy loss = 1.5339547395706177, value loss = 0.19707131385803223\n",
      "INFO 2024-12-04 21:07:34 pipeline.py:712] Training Step 39880: Policy loss = 1.5489461421966553, value loss = 0.20342475175857544\n",
      "INFO 2024-12-04 21:07:43 pipeline.py:712] Training Step 39900: Policy loss = 1.5225753784179688, value loss = 0.19271960854530334\n",
      "INFO 2024-12-04 21:07:53 pipeline.py:712] Training Step 39920: Policy loss = 1.4274853467941284, value loss = 0.21099312603473663\n",
      "INFO 2024-12-04 21:08:02 pipeline.py:712] Training Step 39940: Policy loss = 1.5751644372940063, value loss = 0.18053188920021057\n",
      "INFO 2024-12-04 21:08:12 pipeline.py:712] Training Step 39960: Policy loss = 1.5332266092300415, value loss = 0.2204647809267044\n",
      "INFO 2024-12-04 21:08:22 pipeline.py:712] Training Step 39980: Policy loss = 1.4677644968032837, value loss = 0.19584986567497253\n",
      "INFO 2024-12-04 21:08:31 pipeline.py:712] Training Step 40000: Policy loss = 1.4047574996948242, value loss = 0.24303069710731506\n",
      "INFO 2024-12-04 21:08:41 pipeline.py:712] Training Step 40020: Policy loss = 1.498267650604248, value loss = 0.1994612216949463\n",
      "INFO 2024-12-04 21:08:50 pipeline.py:712] Training Step 40040: Policy loss = 1.4970762729644775, value loss = 0.19409340620040894\n",
      "INFO 2024-12-04 21:09:00 pipeline.py:712] Training Step 40060: Policy loss = 1.4372379779815674, value loss = 0.21107596158981323\n",
      "INFO 2024-12-04 21:09:10 pipeline.py:712] Training Step 40080: Policy loss = 1.4569244384765625, value loss = 0.22449830174446106\n",
      "INFO 2024-12-04 21:09:19 pipeline.py:712] Training Step 40100: Policy loss = 1.5051558017730713, value loss = 0.19931849837303162\n",
      "INFO 2024-12-04 21:09:29 pipeline.py:712] Training Step 40120: Policy loss = 1.5429432392120361, value loss = 0.20678840577602386\n",
      "INFO 2024-12-04 21:09:38 pipeline.py:712] Training Step 40140: Policy loss = 1.593064546585083, value loss = 0.21311813592910767\n",
      "INFO 2024-12-04 21:09:48 pipeline.py:712] Training Step 40160: Policy loss = 1.5697638988494873, value loss = 0.21447286009788513\n",
      "INFO 2024-12-04 21:10:11 pipeline.py:738] training_steps 40172: Validation loss: Poliy loss 1.8547546707215856, value_loss 0.4511815197155124\n",
      "INFO 2024-12-04 21:10:15 pipeline.py:712] Training Step 40180: Policy loss = 1.500359058380127, value loss = 0.20681032538414001\n",
      "INFO 2024-12-04 21:10:25 pipeline.py:712] Training Step 40200: Policy loss = 1.5266635417938232, value loss = 0.2116941213607788\n",
      "INFO 2024-12-04 21:10:34 pipeline.py:712] Training Step 40220: Policy loss = 1.4812660217285156, value loss = 0.18436966836452484\n",
      "INFO 2024-12-04 21:10:44 pipeline.py:712] Training Step 40240: Policy loss = 1.587894320487976, value loss = 0.2093338668346405\n",
      "INFO 2024-12-04 21:10:53 pipeline.py:712] Training Step 40260: Policy loss = 1.483363151550293, value loss = 0.21482253074645996\n",
      "INFO 2024-12-04 21:11:03 pipeline.py:712] Training Step 40280: Policy loss = 1.5435049533843994, value loss = 0.2261158972978592\n",
      "INFO 2024-12-04 21:11:13 pipeline.py:712] Training Step 40300: Policy loss = 1.5173020362854004, value loss = 0.2300453931093216\n",
      "INFO 2024-12-04 21:11:22 pipeline.py:712] Training Step 40320: Policy loss = 1.5450327396392822, value loss = 0.1718565970659256\n",
      "INFO 2024-12-04 21:11:32 pipeline.py:712] Training Step 40340: Policy loss = 1.5586326122283936, value loss = 0.2054707109928131\n",
      "INFO 2024-12-04 21:11:42 pipeline.py:712] Training Step 40360: Policy loss = 1.5209156274795532, value loss = 0.20422226190567017\n",
      "INFO 2024-12-04 21:11:51 pipeline.py:712] Training Step 40380: Policy loss = 1.4976283311843872, value loss = 0.19488710165023804\n",
      "INFO 2024-12-04 21:12:01 pipeline.py:712] Training Step 40400: Policy loss = 1.5868468284606934, value loss = 0.1819789707660675\n",
      "INFO 2024-12-04 21:12:10 pipeline.py:712] Training Step 40420: Policy loss = 1.4948137998580933, value loss = 0.1761230230331421\n",
      "INFO 2024-12-04 21:12:20 pipeline.py:712] Training Step 40440: Policy loss = 1.5448132753372192, value loss = 0.18872886896133423\n",
      "INFO 2024-12-04 21:12:29 pipeline.py:712] Training Step 40460: Policy loss = 1.5101419687271118, value loss = 0.22003351151943207\n",
      "INFO 2024-12-04 21:12:39 pipeline.py:712] Training Step 40480: Policy loss = 1.5563459396362305, value loss = 0.2125667929649353\n",
      "INFO 2024-12-04 21:12:49 pipeline.py:712] Training Step 40500: Policy loss = 1.519168734550476, value loss = 0.21559423208236694\n",
      "INFO 2024-12-04 21:12:58 pipeline.py:712] Training Step 40520: Policy loss = 1.4926244020462036, value loss = 0.20197027921676636\n",
      "INFO 2024-12-04 21:13:08 pipeline.py:712] Training Step 40540: Policy loss = 1.5211399793624878, value loss = 0.18511530756950378\n",
      "INFO 2024-12-04 21:13:17 pipeline.py:712] Training Step 40560: Policy loss = 1.486391544342041, value loss = 0.19039060175418854\n",
      "INFO 2024-12-04 21:13:27 pipeline.py:712] Training Step 40580: Policy loss = 1.570602536201477, value loss = 0.18810664117336273\n",
      "INFO 2024-12-04 21:13:36 pipeline.py:712] Training Step 40600: Policy loss = 1.4501761198043823, value loss = 0.2194746732711792\n",
      "INFO 2024-12-04 21:13:46 pipeline.py:712] Training Step 40620: Policy loss = 1.4987709522247314, value loss = 0.19025710225105286\n",
      "INFO 2024-12-04 21:13:56 pipeline.py:712] Training Step 40640: Policy loss = 1.4802742004394531, value loss = 0.19749735295772552\n",
      "INFO 2024-12-04 21:14:21 pipeline.py:738] training_steps 40656: Validation loss: Poliy loss 1.8547579607025522, value_loss 0.4511067281003858\n",
      "INFO 2024-12-04 21:14:23 pipeline.py:712] Training Step 40660: Policy loss = 1.5006691217422485, value loss = 0.2095785140991211\n",
      "INFO 2024-12-04 21:14:33 pipeline.py:712] Training Step 40680: Policy loss = 1.4428589344024658, value loss = 0.2148432731628418\n",
      "INFO 2024-12-04 21:14:42 pipeline.py:712] Training Step 40700: Policy loss = 1.5208746194839478, value loss = 0.20864173769950867\n",
      "INFO 2024-12-04 21:14:52 pipeline.py:712] Training Step 40720: Policy loss = 1.5023384094238281, value loss = 0.19079546630382538\n",
      "INFO 2024-12-04 21:15:01 pipeline.py:712] Training Step 40740: Policy loss = 1.5377025604248047, value loss = 0.16378989815711975\n",
      "INFO 2024-12-04 21:15:11 pipeline.py:712] Training Step 40760: Policy loss = 1.5132579803466797, value loss = 0.19159118831157684\n",
      "INFO 2024-12-04 21:15:20 pipeline.py:712] Training Step 40780: Policy loss = 1.3848204612731934, value loss = 0.21365942060947418\n",
      "INFO 2024-12-04 21:15:30 pipeline.py:712] Training Step 40800: Policy loss = 1.519885778427124, value loss = 0.1851063370704651\n",
      "INFO 2024-12-04 21:15:40 pipeline.py:712] Training Step 40820: Policy loss = 1.5286585092544556, value loss = 0.21301348507404327\n",
      "INFO 2024-12-04 21:15:49 pipeline.py:712] Training Step 40840: Policy loss = 1.4655582904815674, value loss = 0.2135666459798813\n",
      "INFO 2024-12-04 21:15:59 pipeline.py:712] Training Step 40860: Policy loss = 1.533212423324585, value loss = 0.22586144506931305\n",
      "INFO 2024-12-04 21:16:08 pipeline.py:712] Training Step 40880: Policy loss = 1.4796905517578125, value loss = 0.19129987061023712\n",
      "INFO 2024-12-04 21:16:18 pipeline.py:712] Training Step 40900: Policy loss = 1.5099319219589233, value loss = 0.1982542872428894\n",
      "INFO 2024-12-04 21:16:28 pipeline.py:712] Training Step 40920: Policy loss = 1.5244460105895996, value loss = 0.19524449110031128\n",
      "INFO 2024-12-04 21:16:37 pipeline.py:712] Training Step 40940: Policy loss = 1.5447967052459717, value loss = 0.18958541750907898\n",
      "INFO 2024-12-04 21:16:47 pipeline.py:712] Training Step 40960: Policy loss = 1.4738118648529053, value loss = 0.20540070533752441\n",
      "INFO 2024-12-04 21:16:56 pipeline.py:712] Training Step 40980: Policy loss = 1.442514419555664, value loss = 0.19996359944343567\n",
      "INFO 2024-12-04 21:17:06 pipeline.py:712] Training Step 41000: Policy loss = 1.4616103172302246, value loss = 0.22026386857032776\n",
      "INFO 2024-12-04 21:17:15 pipeline.py:712] Training Step 41020: Policy loss = 1.5715947151184082, value loss = 0.2026245892047882\n",
      "INFO 2024-12-04 21:17:25 pipeline.py:712] Training Step 41040: Policy loss = 1.5033164024353027, value loss = 0.23945409059524536\n",
      "INFO 2024-12-04 21:17:35 pipeline.py:712] Training Step 41060: Policy loss = 1.5070054531097412, value loss = 0.20871630311012268\n",
      "INFO 2024-12-04 21:17:44 pipeline.py:712] Training Step 41080: Policy loss = 1.5918045043945312, value loss = 0.1981426328420639\n",
      "INFO 2024-12-04 21:17:54 pipeline.py:712] Training Step 41100: Policy loss = 1.519936203956604, value loss = 0.1835838109254837\n",
      "INFO 2024-12-04 21:18:03 pipeline.py:712] Training Step 41120: Policy loss = 1.4689704179763794, value loss = 0.1933830827474594\n",
      "INFO 2024-12-04 21:18:13 pipeline.py:712] Training Step 41140: Policy loss = 1.4862253665924072, value loss = 0.2109529972076416\n",
      "INFO 2024-12-04 21:18:31 pipeline.py:738] training_steps 41140: Validation loss: Poliy loss 1.8547130100062637, value_loss 0.45097391771488504\n",
      "INFO 2024-12-04 21:18:40 pipeline.py:712] Training Step 41160: Policy loss = 1.4658160209655762, value loss = 0.1812869906425476\n",
      "INFO 2024-12-04 21:18:50 pipeline.py:712] Training Step 41180: Policy loss = 1.4459704160690308, value loss = 0.19642609357833862\n",
      "INFO 2024-12-04 21:18:59 pipeline.py:712] Training Step 41200: Policy loss = 1.4891959428787231, value loss = 0.19455447793006897\n",
      "INFO 2024-12-04 21:19:09 pipeline.py:712] Training Step 41220: Policy loss = 1.4987074136734009, value loss = 0.20752021670341492\n",
      "INFO 2024-12-04 21:19:18 pipeline.py:712] Training Step 41240: Policy loss = 1.516603946685791, value loss = 0.22355537116527557\n",
      "INFO 2024-12-04 21:19:28 pipeline.py:712] Training Step 41260: Policy loss = 1.533329963684082, value loss = 0.21241223812103271\n",
      "INFO 2024-12-04 21:19:38 pipeline.py:712] Training Step 41280: Policy loss = 1.5117735862731934, value loss = 0.1817370057106018\n",
      "INFO 2024-12-04 21:19:47 pipeline.py:712] Training Step 41300: Policy loss = 1.600259780883789, value loss = 0.21100525557994843\n",
      "INFO 2024-12-04 21:19:57 pipeline.py:712] Training Step 41320: Policy loss = 1.5944639444351196, value loss = 0.20018687844276428\n",
      "INFO 2024-12-04 21:20:06 pipeline.py:712] Training Step 41340: Policy loss = 1.5466320514678955, value loss = 0.21543529629707336\n",
      "INFO 2024-12-04 21:20:16 pipeline.py:712] Training Step 41360: Policy loss = 1.549556016921997, value loss = 0.18170537054538727\n",
      "INFO 2024-12-04 21:20:25 pipeline.py:712] Training Step 41380: Policy loss = 1.4999459981918335, value loss = 0.2321937531232834\n",
      "INFO 2024-12-04 21:20:35 pipeline.py:712] Training Step 41400: Policy loss = 1.5175641775131226, value loss = 0.20677709579467773\n",
      "INFO 2024-12-04 21:20:45 pipeline.py:712] Training Step 41420: Policy loss = 1.4936144351959229, value loss = 0.20012010633945465\n",
      "INFO 2024-12-04 21:20:54 pipeline.py:712] Training Step 41440: Policy loss = 1.4857183694839478, value loss = 0.2292919009923935\n",
      "INFO 2024-12-04 21:21:04 pipeline.py:712] Training Step 41460: Policy loss = 1.5211982727050781, value loss = 0.19534678757190704\n",
      "INFO 2024-12-04 21:21:13 pipeline.py:712] Training Step 41480: Policy loss = 1.4694126844406128, value loss = 0.23247180879116058\n",
      "INFO 2024-12-04 21:21:23 pipeline.py:712] Training Step 41500: Policy loss = 1.464721441268921, value loss = 0.19681912660598755\n",
      "INFO 2024-12-04 21:21:32 pipeline.py:712] Training Step 41520: Policy loss = 1.5666441917419434, value loss = 0.21585196256637573\n",
      "INFO 2024-12-04 21:21:42 pipeline.py:712] Training Step 41540: Policy loss = 1.4791226387023926, value loss = 0.20258115231990814\n",
      "INFO 2024-12-04 21:21:52 pipeline.py:712] Training Step 41560: Policy loss = 1.5282707214355469, value loss = 0.19357237219810486\n",
      "INFO 2024-12-04 21:22:01 pipeline.py:712] Training Step 41580: Policy loss = 1.5496537685394287, value loss = 0.18530380725860596\n",
      "INFO 2024-12-04 21:22:11 pipeline.py:712] Training Step 41600: Policy loss = 1.5351576805114746, value loss = 0.23038215935230255\n",
      "INFO 2024-12-04 21:22:20 pipeline.py:712] Training Step 41620: Policy loss = 1.523425817489624, value loss = 0.19443969428539276\n",
      "INFO 2024-12-04 21:22:40 pipeline.py:738] training_steps 41624: Validation loss: Poliy loss 1.8547106727224882, value_loss 0.45092146636032665\n",
      "INFO 2024-12-04 21:22:48 pipeline.py:712] Training Step 41640: Policy loss = 1.4482989311218262, value loss = 0.22536058723926544\n",
      "INFO 2024-12-04 21:22:57 pipeline.py:712] Training Step 41660: Policy loss = 1.4483855962753296, value loss = 0.18900492787361145\n",
      "INFO 2024-12-04 21:23:07 pipeline.py:712] Training Step 41680: Policy loss = 1.5678091049194336, value loss = 0.2120572328567505\n",
      "INFO 2024-12-04 21:23:16 pipeline.py:712] Training Step 41700: Policy loss = 1.5444258451461792, value loss = 0.2069278061389923\n",
      "INFO 2024-12-04 21:23:26 pipeline.py:712] Training Step 41720: Policy loss = 1.5249097347259521, value loss = 0.2118118852376938\n",
      "INFO 2024-12-04 21:23:36 pipeline.py:712] Training Step 41740: Policy loss = 1.4926787614822388, value loss = 0.20933520793914795\n",
      "INFO 2024-12-04 21:23:45 pipeline.py:712] Training Step 41760: Policy loss = 1.4928271770477295, value loss = 0.20216229557991028\n",
      "INFO 2024-12-04 21:23:55 pipeline.py:712] Training Step 41780: Policy loss = 1.5300254821777344, value loss = 0.17758892476558685\n",
      "INFO 2024-12-04 21:24:04 pipeline.py:712] Training Step 41800: Policy loss = 1.556457757949829, value loss = 0.1980787217617035\n",
      "INFO 2024-12-04 21:24:14 pipeline.py:712] Training Step 41820: Policy loss = 1.5050866603851318, value loss = 0.21794269979000092\n",
      "INFO 2024-12-04 21:24:23 pipeline.py:712] Training Step 41840: Policy loss = 1.4773869514465332, value loss = 0.20295703411102295\n",
      "INFO 2024-12-04 21:24:33 pipeline.py:712] Training Step 41860: Policy loss = 1.4851502180099487, value loss = 0.20916834473609924\n",
      "INFO 2024-12-04 21:24:42 pipeline.py:712] Training Step 41880: Policy loss = 1.5682755708694458, value loss = 0.1998404860496521\n",
      "INFO 2024-12-04 21:24:52 pipeline.py:712] Training Step 41900: Policy loss = 1.5584666728973389, value loss = 0.22292178869247437\n",
      "INFO 2024-12-04 21:25:02 pipeline.py:712] Training Step 41920: Policy loss = 1.4944756031036377, value loss = 0.20423972606658936\n",
      "INFO 2024-12-04 21:25:11 pipeline.py:712] Training Step 41940: Policy loss = 1.536581039428711, value loss = 0.22679254412651062\n",
      "INFO 2024-12-04 21:25:21 pipeline.py:712] Training Step 41960: Policy loss = 1.5887264013290405, value loss = 0.21670468151569366\n",
      "INFO 2024-12-04 21:25:30 pipeline.py:712] Training Step 41980: Policy loss = 1.5063364505767822, value loss = 0.20926827192306519\n",
      "INFO 2024-12-04 21:25:40 pipeline.py:712] Training Step 42000: Policy loss = 1.515609860420227, value loss = 0.20310795307159424\n",
      "INFO 2024-12-04 21:25:50 pipeline.py:712] Training Step 42020: Policy loss = 1.5130021572113037, value loss = 0.21840599179267883\n",
      "INFO 2024-12-04 21:25:59 pipeline.py:712] Training Step 42040: Policy loss = 1.4802980422973633, value loss = 0.19886673986911774\n",
      "INFO 2024-12-04 21:26:09 pipeline.py:712] Training Step 42060: Policy loss = 1.573850393295288, value loss = 0.20681443810462952\n",
      "INFO 2024-12-04 21:26:18 pipeline.py:712] Training Step 42080: Policy loss = 1.492866039276123, value loss = 0.1913076937198639\n",
      "INFO 2024-12-04 21:26:28 pipeline.py:712] Training Step 42100: Policy loss = 1.513788104057312, value loss = 0.22206218540668488\n",
      "INFO 2024-12-04 21:26:49 pipeline.py:738] training_steps 42108: Validation loss: Poliy loss 1.8548506390853006, value_loss 0.4510275460168964\n",
      "INFO 2024-12-04 21:26:55 pipeline.py:712] Training Step 42120: Policy loss = 1.5695710182189941, value loss = 0.21138739585876465\n",
      "INFO 2024-12-04 21:27:05 pipeline.py:712] Training Step 42140: Policy loss = 1.5640792846679688, value loss = 0.18472683429718018\n",
      "INFO 2024-12-04 21:27:14 pipeline.py:712] Training Step 42160: Policy loss = 1.5609664916992188, value loss = 0.2156820297241211\n",
      "INFO 2024-12-04 21:27:24 pipeline.py:712] Training Step 42180: Policy loss = 1.4458727836608887, value loss = 0.20702987909317017\n",
      "INFO 2024-12-04 21:27:33 pipeline.py:712] Training Step 42200: Policy loss = 1.5846353769302368, value loss = 0.20902781188488007\n",
      "INFO 2024-12-04 21:27:43 pipeline.py:712] Training Step 42220: Policy loss = 1.5515587329864502, value loss = 0.19047850370407104\n",
      "INFO 2024-12-04 21:27:53 pipeline.py:712] Training Step 42240: Policy loss = 1.4775594472885132, value loss = 0.22103185951709747\n",
      "INFO 2024-12-04 21:28:02 pipeline.py:712] Training Step 42260: Policy loss = 1.4536062479019165, value loss = 0.20490530133247375\n",
      "INFO 2024-12-04 21:28:12 pipeline.py:712] Training Step 42280: Policy loss = 1.5352509021759033, value loss = 0.20398777723312378\n",
      "INFO 2024-12-04 21:28:21 pipeline.py:712] Training Step 42300: Policy loss = 1.578570008277893, value loss = 0.19993433356285095\n",
      "INFO 2024-12-04 21:28:31 pipeline.py:712] Training Step 42320: Policy loss = 1.5402910709381104, value loss = 0.19154103100299835\n",
      "INFO 2024-12-04 21:28:40 pipeline.py:712] Training Step 42340: Policy loss = 1.4620757102966309, value loss = 0.20164138078689575\n",
      "INFO 2024-12-04 21:28:50 pipeline.py:712] Training Step 42360: Policy loss = 1.5381406545639038, value loss = 0.17971287667751312\n",
      "INFO 2024-12-04 21:29:00 pipeline.py:712] Training Step 42380: Policy loss = 1.5211421251296997, value loss = 0.21783190965652466\n",
      "INFO 2024-12-04 21:29:09 pipeline.py:712] Training Step 42400: Policy loss = 1.4496452808380127, value loss = 0.19988641142845154\n",
      "INFO 2024-12-04 21:29:19 pipeline.py:712] Training Step 42420: Policy loss = 1.4817330837249756, value loss = 0.19053269922733307\n",
      "INFO 2024-12-04 21:29:29 pipeline.py:712] Training Step 42440: Policy loss = 1.474593162536621, value loss = 0.19904547929763794\n",
      "INFO 2024-12-04 21:29:38 pipeline.py:712] Training Step 42460: Policy loss = 1.4738211631774902, value loss = 0.2509477734565735\n",
      "INFO 2024-12-04 21:29:48 pipeline.py:712] Training Step 42480: Policy loss = 1.5227611064910889, value loss = 0.18390130996704102\n",
      "INFO 2024-12-04 21:29:57 pipeline.py:712] Training Step 42500: Policy loss = 1.494918704032898, value loss = 0.2063751518726349\n",
      "INFO 2024-12-04 21:30:07 pipeline.py:712] Training Step 42520: Policy loss = 1.5097169876098633, value loss = 0.20440365374088287\n",
      "INFO 2024-12-04 21:30:17 pipeline.py:712] Training Step 42540: Policy loss = 1.4825433492660522, value loss = 0.22470244765281677\n",
      "INFO 2024-12-04 21:30:26 pipeline.py:712] Training Step 42560: Policy loss = 1.5211975574493408, value loss = 0.19762520492076874\n",
      "INFO 2024-12-04 21:30:36 pipeline.py:712] Training Step 42580: Policy loss = 1.4477025270462036, value loss = 0.18962028622627258\n",
      "INFO 2024-12-04 21:30:59 pipeline.py:738] training_steps 42592: Validation loss: Poliy loss 1.8549828607527936, value_loss 0.4509295376597858\n",
      "INFO 2024-12-04 21:31:03 pipeline.py:712] Training Step 42600: Policy loss = 1.55574369430542, value loss = 0.22270148992538452\n",
      "INFO 2024-12-04 21:31:13 pipeline.py:712] Training Step 42620: Policy loss = 1.517309308052063, value loss = 0.19497385621070862\n",
      "INFO 2024-12-04 21:31:22 pipeline.py:712] Training Step 42640: Policy loss = 1.5563547611236572, value loss = 0.21968455612659454\n",
      "INFO 2024-12-04 21:31:32 pipeline.py:712] Training Step 42660: Policy loss = 1.4646000862121582, value loss = 0.1834871619939804\n",
      "INFO 2024-12-04 21:31:41 pipeline.py:712] Training Step 42680: Policy loss = 1.481345534324646, value loss = 0.22642400860786438\n",
      "INFO 2024-12-04 21:31:51 pipeline.py:712] Training Step 42700: Policy loss = 1.5413899421691895, value loss = 0.17411170899868011\n",
      "INFO 2024-12-04 21:32:00 pipeline.py:712] Training Step 42720: Policy loss = 1.4862937927246094, value loss = 0.2000981569290161\n",
      "INFO 2024-12-04 21:32:10 pipeline.py:712] Training Step 42740: Policy loss = 1.5069828033447266, value loss = 0.19655174016952515\n",
      "INFO 2024-12-04 21:32:20 pipeline.py:712] Training Step 42760: Policy loss = 1.521688461303711, value loss = 0.19404447078704834\n",
      "INFO 2024-12-04 21:32:29 pipeline.py:712] Training Step 42780: Policy loss = 1.5394062995910645, value loss = 0.1982877403497696\n",
      "INFO 2024-12-04 21:32:39 pipeline.py:712] Training Step 42800: Policy loss = 1.4997167587280273, value loss = 0.19780732691287994\n",
      "INFO 2024-12-04 21:32:48 pipeline.py:712] Training Step 42820: Policy loss = 1.491060733795166, value loss = 0.20522934198379517\n",
      "INFO 2024-12-04 21:32:58 pipeline.py:712] Training Step 42840: Policy loss = 1.504455804824829, value loss = 0.24661752581596375\n",
      "INFO 2024-12-04 21:33:08 pipeline.py:712] Training Step 42860: Policy loss = 1.548653483390808, value loss = 0.21456027030944824\n",
      "INFO 2024-12-04 21:33:17 pipeline.py:712] Training Step 42880: Policy loss = 1.4944109916687012, value loss = 0.17713148891925812\n",
      "INFO 2024-12-04 21:33:27 pipeline.py:712] Training Step 42900: Policy loss = 1.486168384552002, value loss = 0.19609321653842926\n",
      "INFO 2024-12-04 21:33:36 pipeline.py:712] Training Step 42920: Policy loss = 1.5005977153778076, value loss = 0.2006400227546692\n",
      "INFO 2024-12-04 21:33:46 pipeline.py:712] Training Step 42940: Policy loss = 1.4912047386169434, value loss = 0.19066710770130157\n",
      "INFO 2024-12-04 21:33:55 pipeline.py:712] Training Step 42960: Policy loss = 1.5144702196121216, value loss = 0.22287431359291077\n",
      "INFO 2024-12-04 21:34:05 pipeline.py:712] Training Step 42980: Policy loss = 1.5207674503326416, value loss = 0.22686660289764404\n",
      "INFO 2024-12-04 21:34:15 pipeline.py:712] Training Step 43000: Policy loss = 1.4940032958984375, value loss = 0.19352903962135315\n",
      "INFO 2024-12-04 21:34:24 pipeline.py:712] Training Step 43020: Policy loss = 1.454756736755371, value loss = 0.1911114901304245\n",
      "INFO 2024-12-04 21:34:34 pipeline.py:712] Training Step 43040: Policy loss = 1.5062353610992432, value loss = 0.1766301691532135\n",
      "INFO 2024-12-04 21:34:43 pipeline.py:712] Training Step 43060: Policy loss = 1.5091869831085205, value loss = 0.2124122679233551\n",
      "INFO 2024-12-04 21:35:09 pipeline.py:738] training_steps 43076: Validation loss: Poliy loss 1.8549277274335016, value_loss 0.45095847400485495\n",
      "INFO 2024-12-04 21:35:11 pipeline.py:712] Training Step 43080: Policy loss = 1.5158193111419678, value loss = 0.24219633638858795\n",
      "INFO 2024-12-04 21:35:20 pipeline.py:712] Training Step 43100: Policy loss = 1.471541166305542, value loss = 0.20230597257614136\n",
      "INFO 2024-12-04 21:35:30 pipeline.py:712] Training Step 43120: Policy loss = 1.52045476436615, value loss = 0.2124689519405365\n",
      "INFO 2024-12-04 21:35:39 pipeline.py:712] Training Step 43140: Policy loss = 1.5151563882827759, value loss = 0.2075461745262146\n",
      "INFO 2024-12-04 21:35:49 pipeline.py:712] Training Step 43160: Policy loss = 1.4875383377075195, value loss = 0.1994052231311798\n",
      "INFO 2024-12-04 21:35:59 pipeline.py:712] Training Step 43180: Policy loss = 1.4918713569641113, value loss = 0.22145439684391022\n",
      "INFO 2024-12-04 21:36:08 pipeline.py:712] Training Step 43200: Policy loss = 1.4486021995544434, value loss = 0.24108147621154785\n",
      "INFO 2024-12-04 21:36:18 pipeline.py:712] Training Step 43220: Policy loss = 1.5003657341003418, value loss = 0.1935986876487732\n",
      "INFO 2024-12-04 21:36:27 pipeline.py:712] Training Step 43240: Policy loss = 1.5961477756500244, value loss = 0.183861643075943\n",
      "INFO 2024-12-04 21:36:37 pipeline.py:712] Training Step 43260: Policy loss = 1.5354318618774414, value loss = 0.2253558337688446\n",
      "INFO 2024-12-04 21:36:46 pipeline.py:712] Training Step 43280: Policy loss = 1.4440240859985352, value loss = 0.22393865883350372\n",
      "INFO 2024-12-04 21:36:56 pipeline.py:712] Training Step 43300: Policy loss = 1.5259424448013306, value loss = 0.20805580914020538\n",
      "INFO 2024-12-04 21:37:06 pipeline.py:712] Training Step 43320: Policy loss = 1.5307365655899048, value loss = 0.178005650639534\n",
      "INFO 2024-12-04 21:37:15 pipeline.py:712] Training Step 43340: Policy loss = 1.529384970664978, value loss = 0.18079142272472382\n",
      "INFO 2024-12-04 21:37:25 pipeline.py:712] Training Step 43360: Policy loss = 1.4458118677139282, value loss = 0.21158210933208466\n",
      "INFO 2024-12-04 21:37:34 pipeline.py:712] Training Step 43380: Policy loss = 1.4660933017730713, value loss = 0.17478814721107483\n",
      "INFO 2024-12-04 21:37:44 pipeline.py:712] Training Step 43400: Policy loss = 1.5427573919296265, value loss = 0.23784194886684418\n",
      "INFO 2024-12-04 21:37:53 pipeline.py:712] Training Step 43420: Policy loss = 1.5039024353027344, value loss = 0.19703862071037292\n",
      "INFO 2024-12-04 21:38:03 pipeline.py:712] Training Step 43440: Policy loss = 1.5844539403915405, value loss = 0.22599384188652039\n",
      "INFO 2024-12-04 21:38:13 pipeline.py:712] Training Step 43460: Policy loss = 1.5030217170715332, value loss = 0.19534927606582642\n",
      "INFO 2024-12-04 21:38:22 pipeline.py:712] Training Step 43480: Policy loss = 1.4861279726028442, value loss = 0.18222051858901978\n",
      "INFO 2024-12-04 21:38:32 pipeline.py:712] Training Step 43500: Policy loss = 1.5295116901397705, value loss = 0.23291297256946564\n",
      "INFO 2024-12-04 21:38:41 pipeline.py:712] Training Step 43520: Policy loss = 1.5368289947509766, value loss = 0.20893748104572296\n",
      "INFO 2024-12-04 21:38:51 pipeline.py:712] Training Step 43540: Policy loss = 1.6017671823501587, value loss = 0.20405356585979462\n",
      "INFO 2024-12-04 21:39:01 pipeline.py:712] Training Step 43560: Policy loss = 1.5059915781021118, value loss = 0.2223851978778839\n",
      "INFO 2024-12-04 21:39:18 pipeline.py:738] training_steps 43560: Validation loss: Poliy loss 1.8550131780202272, value_loss 0.45096040578162083\n",
      "INFO 2024-12-04 21:39:28 pipeline.py:712] Training Step 43580: Policy loss = 1.4663360118865967, value loss = 0.20885112881660461\n",
      "INFO 2024-12-04 21:39:38 pipeline.py:712] Training Step 43600: Policy loss = 1.5801974534988403, value loss = 0.22016583383083344\n",
      "INFO 2024-12-04 21:39:47 pipeline.py:712] Training Step 43620: Policy loss = 1.4806612730026245, value loss = 0.18796662986278534\n",
      "INFO 2024-12-04 21:39:57 pipeline.py:712] Training Step 43640: Policy loss = 1.5224782228469849, value loss = 0.22491446137428284\n",
      "INFO 2024-12-04 21:40:06 pipeline.py:712] Training Step 43660: Policy loss = 1.5343433618545532, value loss = 0.20045869052410126\n",
      "INFO 2024-12-04 21:40:16 pipeline.py:712] Training Step 43680: Policy loss = 1.524998664855957, value loss = 0.22737190127372742\n",
      "INFO 2024-12-04 21:40:26 pipeline.py:712] Training Step 43700: Policy loss = 1.533586025238037, value loss = 0.20217762887477875\n",
      "INFO 2024-12-04 21:40:35 pipeline.py:712] Training Step 43720: Policy loss = 1.5459239482879639, value loss = 0.20460231602191925\n",
      "INFO 2024-12-04 21:40:45 pipeline.py:712] Training Step 43740: Policy loss = 1.4991075992584229, value loss = 0.21171270310878754\n",
      "INFO 2024-12-04 21:40:54 pipeline.py:712] Training Step 43760: Policy loss = 1.4706389904022217, value loss = 0.22603318095207214\n",
      "INFO 2024-12-04 21:41:04 pipeline.py:712] Training Step 43780: Policy loss = 1.4949966669082642, value loss = 0.20230036973953247\n",
      "INFO 2024-12-04 21:41:13 pipeline.py:712] Training Step 43800: Policy loss = 1.5252094268798828, value loss = 0.19964906573295593\n",
      "INFO 2024-12-04 21:41:23 pipeline.py:712] Training Step 43820: Policy loss = 1.473095417022705, value loss = 0.19653362035751343\n",
      "INFO 2024-12-04 21:41:32 pipeline.py:712] Training Step 43840: Policy loss = 1.5372161865234375, value loss = 0.21696580946445465\n",
      "INFO 2024-12-04 21:41:42 pipeline.py:712] Training Step 43860: Policy loss = 1.499501347541809, value loss = 0.22123833000659943\n",
      "INFO 2024-12-04 21:41:52 pipeline.py:712] Training Step 43880: Policy loss = 1.486392617225647, value loss = 0.213041752576828\n",
      "INFO 2024-12-04 21:42:01 pipeline.py:712] Training Step 43900: Policy loss = 1.554469108581543, value loss = 0.19603179395198822\n",
      "INFO 2024-12-04 21:42:11 pipeline.py:712] Training Step 43920: Policy loss = 1.4772459268569946, value loss = 0.22043271362781525\n",
      "INFO 2024-12-04 21:42:20 pipeline.py:712] Training Step 43940: Policy loss = 1.5349246263504028, value loss = 0.19713018834590912\n",
      "INFO 2024-12-04 21:42:30 pipeline.py:712] Training Step 43960: Policy loss = 1.4962413311004639, value loss = 0.2004185914993286\n",
      "INFO 2024-12-04 21:42:39 pipeline.py:712] Training Step 43980: Policy loss = 1.500910997390747, value loss = 0.2241082489490509\n",
      "INFO 2024-12-04 21:42:49 pipeline.py:712] Training Step 44000: Policy loss = 1.508671522140503, value loss = 0.19896692037582397\n",
      "INFO 2024-12-04 21:42:59 pipeline.py:712] Training Step 44020: Policy loss = 1.486992597579956, value loss = 0.19922153651714325\n",
      "INFO 2024-12-04 21:43:08 pipeline.py:712] Training Step 44040: Policy loss = 1.4337058067321777, value loss = 0.20640219748020172\n",
      "INFO 2024-12-04 21:43:28 pipeline.py:738] training_steps 44044: Validation loss: Poliy loss 1.8548487219654146, value_loss 0.45089107507564985\n",
      "INFO 2024-12-04 21:43:36 pipeline.py:712] Training Step 44060: Policy loss = 1.5077540874481201, value loss = 0.22030103206634521\n",
      "INFO 2024-12-04 21:43:45 pipeline.py:712] Training Step 44080: Policy loss = 1.471907615661621, value loss = 0.1914619356393814\n",
      "INFO 2024-12-04 21:43:55 pipeline.py:712] Training Step 44100: Policy loss = 1.5337313413619995, value loss = 0.17438966035842896\n",
      "INFO 2024-12-04 21:44:04 pipeline.py:712] Training Step 44120: Policy loss = 1.5295568704605103, value loss = 0.21758350729942322\n",
      "INFO 2024-12-04 21:44:14 pipeline.py:712] Training Step 44140: Policy loss = 1.5466980934143066, value loss = 0.20555230975151062\n",
      "INFO 2024-12-04 21:44:23 pipeline.py:712] Training Step 44160: Policy loss = 1.57636296749115, value loss = 0.18097078800201416\n",
      "INFO 2024-12-04 21:44:33 pipeline.py:712] Training Step 44180: Policy loss = 1.4961448907852173, value loss = 0.22065766155719757\n",
      "INFO 2024-12-04 21:44:43 pipeline.py:712] Training Step 44200: Policy loss = 1.5420818328857422, value loss = 0.21248134970664978\n",
      "INFO 2024-12-04 21:44:52 pipeline.py:712] Training Step 44220: Policy loss = 1.5392943620681763, value loss = 0.21334901452064514\n",
      "INFO 2024-12-04 21:45:02 pipeline.py:712] Training Step 44240: Policy loss = 1.5699400901794434, value loss = 0.20854586362838745\n",
      "INFO 2024-12-04 21:45:11 pipeline.py:712] Training Step 44260: Policy loss = 1.4721722602844238, value loss = 0.18146145343780518\n",
      "INFO 2024-12-04 21:45:21 pipeline.py:712] Training Step 44280: Policy loss = 1.5027892589569092, value loss = 0.1803300380706787\n",
      "INFO 2024-12-04 21:45:30 pipeline.py:712] Training Step 44300: Policy loss = 1.438860535621643, value loss = 0.1991060972213745\n",
      "INFO 2024-12-04 21:45:40 pipeline.py:712] Training Step 44320: Policy loss = 1.4995191097259521, value loss = 0.21574294567108154\n",
      "INFO 2024-12-04 21:45:49 pipeline.py:712] Training Step 44340: Policy loss = 1.5445059537887573, value loss = 0.2124967724084854\n",
      "INFO 2024-12-04 21:45:59 pipeline.py:712] Training Step 44360: Policy loss = 1.4848027229309082, value loss = 0.23833133280277252\n",
      "INFO 2024-12-04 21:46:09 pipeline.py:712] Training Step 44380: Policy loss = 1.5213115215301514, value loss = 0.20166799426078796\n",
      "INFO 2024-12-04 21:46:18 pipeline.py:712] Training Step 44400: Policy loss = 1.5045757293701172, value loss = 0.21167927980422974\n",
      "INFO 2024-12-04 21:46:28 pipeline.py:712] Training Step 44420: Policy loss = 1.492499589920044, value loss = 0.1989133059978485\n",
      "INFO 2024-12-04 21:46:37 pipeline.py:712] Training Step 44440: Policy loss = 1.4612956047058105, value loss = 0.20815806090831757\n",
      "INFO 2024-12-04 21:46:47 pipeline.py:712] Training Step 44460: Policy loss = 1.5209155082702637, value loss = 0.2112341672182083\n",
      "INFO 2024-12-04 21:46:56 pipeline.py:712] Training Step 44480: Policy loss = 1.4419645071029663, value loss = 0.2123129963874817\n",
      "INFO 2024-12-04 21:47:06 pipeline.py:712] Training Step 44500: Policy loss = 1.6109031438827515, value loss = 0.17437335848808289\n",
      "INFO 2024-12-04 21:47:16 pipeline.py:712] Training Step 44520: Policy loss = 1.515345573425293, value loss = 0.2025676965713501\n",
      "INFO 2024-12-04 21:47:37 pipeline.py:738] training_steps 44528: Validation loss: Poliy loss 1.8549047845308897, value_loss 0.4509517184046448\n",
      "INFO 2024-12-04 21:47:43 pipeline.py:712] Training Step 44540: Policy loss = 1.559862494468689, value loss = 0.17690503597259521\n",
      "INFO 2024-12-04 21:47:53 pipeline.py:712] Training Step 44560: Policy loss = 1.606290340423584, value loss = 0.1962185651063919\n",
      "INFO 2024-12-04 21:48:02 pipeline.py:712] Training Step 44580: Policy loss = 1.441070795059204, value loss = 0.19427639245986938\n",
      "INFO 2024-12-04 21:48:12 pipeline.py:712] Training Step 44600: Policy loss = 1.465952754020691, value loss = 0.19103939831256866\n",
      "INFO 2024-12-04 21:48:21 pipeline.py:712] Training Step 44620: Policy loss = 1.5240199565887451, value loss = 0.2246670126914978\n",
      "INFO 2024-12-04 21:48:31 pipeline.py:712] Training Step 44640: Policy loss = 1.498199701309204, value loss = 0.19345876574516296\n",
      "INFO 2024-12-04 21:48:41 pipeline.py:712] Training Step 44660: Policy loss = 1.5547223091125488, value loss = 0.20031313598155975\n",
      "INFO 2024-12-04 21:48:50 pipeline.py:712] Training Step 44680: Policy loss = 1.4569439888000488, value loss = 0.19675776362419128\n",
      "INFO 2024-12-04 21:49:00 pipeline.py:712] Training Step 44700: Policy loss = 1.5363051891326904, value loss = 0.2456149458885193\n",
      "INFO 2024-12-04 21:49:09 pipeline.py:712] Training Step 44720: Policy loss = 1.5255756378173828, value loss = 0.19539150595664978\n",
      "INFO 2024-12-04 21:49:19 pipeline.py:712] Training Step 44740: Policy loss = 1.4645509719848633, value loss = 0.1928899884223938\n",
      "INFO 2024-12-04 21:49:28 pipeline.py:712] Training Step 44760: Policy loss = 1.5520117282867432, value loss = 0.1972455531358719\n",
      "INFO 2024-12-04 21:49:38 pipeline.py:712] Training Step 44780: Policy loss = 1.6156190633773804, value loss = 0.1776430606842041\n",
      "INFO 2024-12-04 21:49:47 pipeline.py:712] Training Step 44800: Policy loss = 1.505705714225769, value loss = 0.22449184954166412\n",
      "INFO 2024-12-04 21:49:57 pipeline.py:712] Training Step 44820: Policy loss = 1.4525704383850098, value loss = 0.20989377796649933\n",
      "INFO 2024-12-04 21:50:07 pipeline.py:712] Training Step 44840: Policy loss = 1.543245792388916, value loss = 0.22855085134506226\n",
      "INFO 2024-12-04 21:50:16 pipeline.py:712] Training Step 44860: Policy loss = 1.5854285955429077, value loss = 0.20739279687404633\n",
      "INFO 2024-12-04 21:50:26 pipeline.py:712] Training Step 44880: Policy loss = 1.4800682067871094, value loss = 0.21013230085372925\n",
      "INFO 2024-12-04 21:50:35 pipeline.py:712] Training Step 44900: Policy loss = 1.5113248825073242, value loss = 0.20514431595802307\n",
      "INFO 2024-12-04 21:50:45 pipeline.py:712] Training Step 44920: Policy loss = 1.5413117408752441, value loss = 0.20706841349601746\n",
      "INFO 2024-12-04 21:50:54 pipeline.py:712] Training Step 44940: Policy loss = 1.484503984451294, value loss = 0.19026349484920502\n",
      "INFO 2024-12-04 21:51:04 pipeline.py:712] Training Step 44960: Policy loss = 1.4914404153823853, value loss = 0.21361161768436432\n",
      "INFO 2024-12-04 21:51:13 pipeline.py:712] Training Step 44980: Policy loss = 1.502229928970337, value loss = 0.19866880774497986\n",
      "INFO 2024-12-04 21:51:23 pipeline.py:712] Training Step 45000: Policy loss = 1.5718164443969727, value loss = 0.19323226809501648\n",
      "INFO 2024-12-04 21:51:47 pipeline.py:738] training_steps 45012: Validation loss: Poliy loss 1.855019537151837, value_loss 0.4510003948797945\n",
      "INFO 2024-12-04 21:51:51 pipeline.py:712] Training Step 45020: Policy loss = 1.5241427421569824, value loss = 0.19242341816425323\n",
      "INFO 2024-12-04 21:52:00 pipeline.py:712] Training Step 45040: Policy loss = 1.531116247177124, value loss = 0.17999520897865295\n",
      "INFO 2024-12-04 21:52:10 pipeline.py:712] Training Step 45060: Policy loss = 1.4853475093841553, value loss = 0.21426162123680115\n",
      "INFO 2024-12-04 21:52:19 pipeline.py:712] Training Step 45080: Policy loss = 1.5691490173339844, value loss = 0.1975230872631073\n",
      "INFO 2024-12-04 21:52:29 pipeline.py:712] Training Step 45100: Policy loss = 1.5474047660827637, value loss = 0.21034589409828186\n",
      "INFO 2024-12-04 21:52:39 pipeline.py:712] Training Step 45120: Policy loss = 1.4489061832427979, value loss = 0.2166043221950531\n",
      "INFO 2024-12-04 21:52:48 pipeline.py:712] Training Step 45140: Policy loss = 1.4862817525863647, value loss = 0.20767688751220703\n",
      "INFO 2024-12-04 21:52:58 pipeline.py:712] Training Step 45160: Policy loss = 1.5138599872589111, value loss = 0.2061653435230255\n",
      "INFO 2024-12-04 21:53:07 pipeline.py:712] Training Step 45180: Policy loss = 1.4992642402648926, value loss = 0.22522300481796265\n",
      "INFO 2024-12-04 21:53:17 pipeline.py:712] Training Step 45200: Policy loss = 1.4781413078308105, value loss = 0.22304488718509674\n",
      "INFO 2024-12-04 21:53:26 pipeline.py:712] Training Step 45220: Policy loss = 1.5329443216323853, value loss = 0.22920942306518555\n",
      "INFO 2024-12-04 21:53:36 pipeline.py:712] Training Step 45240: Policy loss = 1.5694169998168945, value loss = 0.20429769158363342\n",
      "INFO 2024-12-04 21:53:45 pipeline.py:712] Training Step 45260: Policy loss = 1.4642372131347656, value loss = 0.24051818251609802\n",
      "INFO 2024-12-04 21:53:55 pipeline.py:712] Training Step 45280: Policy loss = 1.5049540996551514, value loss = 0.22491228580474854\n",
      "INFO 2024-12-04 21:54:05 pipeline.py:712] Training Step 45300: Policy loss = 1.5118194818496704, value loss = 0.20529597997665405\n",
      "INFO 2024-12-04 21:54:14 pipeline.py:712] Training Step 45320: Policy loss = 1.508433222770691, value loss = 0.18188096582889557\n",
      "INFO 2024-12-04 21:54:24 pipeline.py:712] Training Step 45340: Policy loss = 1.5380513668060303, value loss = 0.20282931625843048\n",
      "INFO 2024-12-04 21:54:33 pipeline.py:712] Training Step 45360: Policy loss = 1.5497491359710693, value loss = 0.2319328486919403\n",
      "INFO 2024-12-04 21:54:43 pipeline.py:712] Training Step 45380: Policy loss = 1.4908040761947632, value loss = 0.20486889779567719\n",
      "INFO 2024-12-04 21:54:52 pipeline.py:712] Training Step 45400: Policy loss = 1.5244395732879639, value loss = 0.2017192393541336\n",
      "INFO 2024-12-04 21:55:02 pipeline.py:712] Training Step 45420: Policy loss = 1.549548625946045, value loss = 0.19804127514362335\n",
      "INFO 2024-12-04 21:55:11 pipeline.py:712] Training Step 45440: Policy loss = 1.5582947731018066, value loss = 0.19798842072486877\n",
      "INFO 2024-12-04 21:55:21 pipeline.py:712] Training Step 45460: Policy loss = 1.564340353012085, value loss = 0.21538414061069489\n",
      "INFO 2024-12-04 21:55:31 pipeline.py:712] Training Step 45480: Policy loss = 1.4860155582427979, value loss = 0.20534123480319977\n",
      "INFO 2024-12-04 21:55:56 pipeline.py:738] training_steps 45496: Validation loss: Poliy loss 1.8550058515345464, value_loss 0.4510168118066475\n",
      "INFO 2024-12-04 21:55:58 pipeline.py:712] Training Step 45500: Policy loss = 1.4606812000274658, value loss = 0.2097298800945282\n",
      "INFO 2024-12-04 21:56:08 pipeline.py:712] Training Step 45520: Policy loss = 1.5359419584274292, value loss = 0.22967857122421265\n",
      "INFO 2024-12-04 21:56:17 pipeline.py:712] Training Step 45540: Policy loss = 1.4503105878829956, value loss = 0.17830118536949158\n",
      "INFO 2024-12-04 21:56:27 pipeline.py:712] Training Step 45560: Policy loss = 1.48212730884552, value loss = 0.17324869334697723\n",
      "INFO 2024-12-04 21:56:36 pipeline.py:712] Training Step 45580: Policy loss = 1.432037591934204, value loss = 0.21966122090816498\n",
      "INFO 2024-12-04 21:56:46 pipeline.py:712] Training Step 45600: Policy loss = 1.4818851947784424, value loss = 0.19160856306552887\n",
      "INFO 2024-12-04 21:56:56 pipeline.py:712] Training Step 45620: Policy loss = 1.639529824256897, value loss = 0.18438777327537537\n",
      "INFO 2024-12-04 21:57:05 pipeline.py:712] Training Step 45640: Policy loss = 1.5176575183868408, value loss = 0.18197496235370636\n",
      "INFO 2024-12-04 21:57:15 pipeline.py:712] Training Step 45660: Policy loss = 1.5272226333618164, value loss = 0.1954936534166336\n",
      "INFO 2024-12-04 21:57:24 pipeline.py:712] Training Step 45680: Policy loss = 1.532220721244812, value loss = 0.218794584274292\n",
      "INFO 2024-12-04 21:57:34 pipeline.py:712] Training Step 45700: Policy loss = 1.5040191411972046, value loss = 0.1821310818195343\n",
      "INFO 2024-12-04 21:57:43 pipeline.py:712] Training Step 45720: Policy loss = 1.507030725479126, value loss = 0.21064485609531403\n",
      "INFO 2024-12-04 21:57:53 pipeline.py:712] Training Step 45740: Policy loss = 1.5082635879516602, value loss = 0.20003986358642578\n",
      "INFO 2024-12-04 21:58:02 pipeline.py:712] Training Step 45760: Policy loss = 1.474095106124878, value loss = 0.21281969547271729\n",
      "INFO 2024-12-04 21:58:12 pipeline.py:712] Training Step 45780: Policy loss = 1.4338574409484863, value loss = 0.1871405988931656\n",
      "INFO 2024-12-04 21:58:21 pipeline.py:712] Training Step 45800: Policy loss = 1.5469932556152344, value loss = 0.2017715573310852\n",
      "INFO 2024-12-04 21:58:31 pipeline.py:712] Training Step 45820: Policy loss = 1.5241706371307373, value loss = 0.21760293841362\n",
      "INFO 2024-12-04 21:58:41 pipeline.py:712] Training Step 45840: Policy loss = 1.4842925071716309, value loss = 0.19096776843070984\n",
      "INFO 2024-12-04 21:58:50 pipeline.py:712] Training Step 45860: Policy loss = 1.53226900100708, value loss = 0.19795817136764526\n",
      "INFO 2024-12-04 21:59:00 pipeline.py:712] Training Step 45880: Policy loss = 1.4692351818084717, value loss = 0.17467398941516876\n",
      "INFO 2024-12-04 21:59:09 pipeline.py:712] Training Step 45900: Policy loss = 1.5543487071990967, value loss = 0.20127636194229126\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     14\u001b[0m     learner_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43msupervised_learner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlearner_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margument_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_training_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/alpha_zero/core/pipeline.py:697\u001b[0m, in \u001b[0;36msupervised_learner_loop\u001b[0;34m(seed, network, data_dir, optimizer, lr_scheduler, device, logger, argument_data, batch_size, ckpt_interval, log_interval, max_training_steps, patience, ckpt_dir, logs_dir)\u001b[0m\n\u001b[1;32m    695\u001b[0m pi_loss, v_loss \u001b[38;5;241m=\u001b[39m compute_supervised_losses(network, device, transition, argument_data)\n\u001b[1;32m    696\u001b[0m loss \u001b[38;5;241m=\u001b[39m pi_loss \u001b[38;5;241m+\u001b[39m v_loss\n\u001b[0;32m--> 697\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    699\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/neural-search/venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "set_seed(FLAGS.seed)\n",
    "\n",
    "maybe_create_dir(FLAGS.ckpt_dir)\n",
    "maybe_create_dir(FLAGS.logs_dir)\n",
    "# maybe_create_dir(FLAGS.save_sgf_dir)\n",
    "\n",
    "logger = create_logger(FLAGS.log_level)\n",
    "\n",
    "logger.info(extract_args_from_flags_dict(FLAGS.flag_values_dict()))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    learner_device = torch.device('cuda')\n",
    "supervised_learner_loop(\n",
    "    seed = FLAGS.seed,\n",
    "    network = network,\n",
    "    data_dir = FLAGS.dataset_dir,\n",
    "    device = learner_device,\n",
    "    optimizer = optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    logger = logger,\n",
    "    argument_data = FLAGS.argument_data,\n",
    "    batch_size = FLAGS.batch_size,\n",
    "    ckpt_interval = FLAGS.ckpt_interval,\n",
    "    log_interval = FLAGS.log_interval,\n",
    "    max_training_steps = FLAGS.max_training_steps,\n",
    "    patience = 1000,\n",
    "    ckpt_dir = FLAGS.ckpt_dir,\n",
    "    logs_dir = FLAGS.logs_dir,\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hook_fn(module, input, output):\n",
    "#     print(f\"Input shape: {module}, {input[0].shape}\")  # input is a tuple; get the shape of the first element\n",
    "#     print(f\"Output shape:{module}, {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the hook on the first layer of conv_block1\n",
    "# hook_handle = network.conv_block.register_forward_hook(hook_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
