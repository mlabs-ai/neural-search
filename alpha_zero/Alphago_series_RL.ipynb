{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# This forces OpenMP to use 1 single thread, which is needed to\n",
    "# prevent contention between multiple process.\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# Tell numpy to only use one core.\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer('board_size', 5, 'Board size for Go.')\n",
    "flags.DEFINE_float('komi', 7.5, 'Komi rule for Go.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_stack',\n",
    "    8,\n",
    "    'Stack N previous states, the state is an image of N x 2 + 1 binary planes.',\n",
    ")\n",
    "flags.DEFINE_integer('num_res_blocks', 5, 'Number of residual blocks in the neural network.')\n",
    "flags.DEFINE_integer('num_filters_resnet', 64, 'Number of filters for the conv2d layers in the neural network.')\n",
    "flags.DEFINE_integer(\n",
    "    'num_fc_units',\n",
    "    128,\n",
    "    'Number of hidden units in the linear layer of the neural network.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'num_simulations',\n",
    "    200,\n",
    "    'Number of simulations per MCTS search, this applies to both self-play and evaluation processes.',\n",
    ")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'num_parallel',\n",
    "    6,\n",
    "    'Number of leaves to collect before using the neural network to evaluate the positions during MCTS search,'\n",
    "    '1 means no parallel search.',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'c_puct_base',\n",
    "    19652,\n",
    "    'Exploration constants balancing priors vs. search values. Original paper use 19652',\n",
    ")\n",
    "flags.DEFINE_float(\n",
    "    'c_puct_init',\n",
    "    1.25,\n",
    "    'Exploration constants balancing priors vs. search values. Original paper use 1.25',\n",
    ")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    'default_rating',\n",
    "    1500,\n",
    "    'Default elo rating, change to the rating (for black) from last checkpoint when resume training.',\n",
    ")\n",
    "flags.DEFINE_string(\n",
    "    'logs_dir',\n",
    "    './logs/go/5x5/alphago_series',\n",
    "    'Path to save statistics for self-play, training, and evaluation.',\n",
    ")\n",
    "flags.DEFINE_string('log_level', 'INFO', '')\n",
    "flags.DEFINE_integer('seed', 1, 'Seed the runtime.')\n",
    "# Initialize flags\n",
    "FLAGS(sys.argv, known_only = True)\n",
    "\n",
    "os.environ['BOARD_SIZE'] = str(FLAGS.board_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_zero.envs.go import GoEnv\n",
    "from alpha_zero.core.pipeline import (\n",
    "    set_seed,\n",
    "    maybe_create_dir,\n",
    ")\n",
    "from alpha_zero.core.multi_game import run_tournament\n",
    "from alpha_zero.core.quantum_net import QuantumAlphaZeroNet\n",
    "from alpha_zero.core.network import AlphaZeroNet\n",
    "from alpha_zero.utils.util import extract_args_from_flags_dict, create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_configs = [\n",
    "\n",
    "\n",
    "    {\n",
    "        'name': 'search_50k',\n",
    "        'num_filters': 16,\n",
    "        'max_depth': 1,\n",
    "        'branching_width': 3,\n",
    "        'beam_width': 1,\n",
    "        'num_fc_units':128,\n",
    "        'num_search':5,\n",
    "        'load_chkpt' : './checkpoints/go/5x5/search/f_16_sgf_500/chkpts_lr_.0001/training_steps_50176.ckpt'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'name': 'Search_90k',\n",
    "        'num_filters': 16,\n",
    "        'max_depth': 1,\n",
    "        'branching_width': 3,\n",
    "        'beam_width': 1,\n",
    "        'num_fc_units':128,\n",
    "        'num_search':5,\n",
    "        'load_chkpt' : './checkpoints/go/5x5/search/f_16_sgf_500/chkpts_lr_.0001/training_steps_90112.ckpt'\n",
    "    },\n",
    "    {\n",
    "        'name': 'search_100k',\n",
    "        'num_filters': 16,\n",
    "        'max_depth': 1,\n",
    "        'branching_width': 3,\n",
    "        'beam_width': 1,\n",
    "        'num_fc_units':128,\n",
    "        'num_search':5,\n",
    "        'load_chkpt' : './checkpoints/go/5x5/search/f_16_sgf_500/chkpts_lr_.0001/training_steps_100352.ckpt'\n",
    "    },\n",
    "     {\n",
    "        'name': 'Search_138k',\n",
    "        'num_filters': 16,\n",
    "        'max_depth': 1,\n",
    "        'branching_width': 3,\n",
    "        'beam_width': 1,\n",
    "        'num_fc_units':128,\n",
    "        'num_search':5,\n",
    "        'load_chkpt' : './checkpoints/go/5x5/search/f_16_sgf_500/chkpts_lr_.0001/training_steps_138240.ckpt'\n",
    "    },\n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_configs_resnet = [\n",
    "\n",
    "\n",
    "     {\n",
    "        'name': 'resnet_88k',\n",
    "        'num_res_blocks': 5,\n",
    "        'num_filters_resnet': 64,\n",
    "        'num_fc_units':128,\n",
    "        'load_chkpt' : './checkpoints/go/5x5/resnets/training_steps_88000.ckpt'\n",
    "    },\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_builder():\n",
    "        return GoEnv(komi=FLAGS.komi, num_stack=FLAGS.num_stack)\n",
    "eval_env = env_builder()\n",
    "\n",
    "input_shape = eval_env.observation_space.shape\n",
    "num_actions = eval_env.action_space.n\n",
    "\n",
    "# Initialize agents\n",
    "Agents = []\n",
    "Agents_resnet = []\n",
    "for config in agent_configs:\n",
    "    agent = QuantumAlphaZeroNet(\n",
    "        input_shape,\n",
    "        num_actions,\n",
    "        config['num_filters'],\n",
    "        config['max_depth'],\n",
    "        config['branching_width'],\n",
    "        config['beam_width'],\n",
    "        config['num_fc_units'],\n",
    "        config['num_search'],\n",
    "    )\n",
    "    Agents.append(agent)\n",
    "\n",
    "for config in agent_configs_resnet:\n",
    "    agent = AlphaZeroNet(\n",
    "            input_shape,\n",
    "            num_actions,\n",
    "            config['num_res_blocks'],\n",
    "            config['num_filters_resnet'],\n",
    "            FLAGS.num_fc_units,\n",
    "        )\n",
    "    Agents_resnet.append(agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agents with metadata\n",
    "\n",
    "agents_search = {}\n",
    "agents_resnet = {}\n",
    "\n",
    "# Add QuantumAlphaZeroNet agents\n",
    "for config, agent in zip(agent_configs, Agents):\n",
    "    agents_search[config[\"name\"]] = {\n",
    "        \"network\": agent,\n",
    "        \"elo_rating\": 1500,  # Initial Elo rating\n",
    "        \"checkpoint\": config[\"load_chkpt\"],\n",
    "        \"wins\": 0,\n",
    "        \"lost\":0\n",
    "    }\n",
    "\n",
    "for config, agent in zip(agent_configs_resnet, Agents_resnet):\n",
    "    agents_resnet[config[\"name\"]] = {\n",
    "        \"network\": agent,\n",
    "        \"elo_rating\": 1500,  # Initial Elo rating\n",
    "        \"checkpoint\": config[\"load_chkpt\"],\n",
    "        \"wins\": 0,\n",
    "        \"lost\":0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = agents_resnet | agents_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(FLAGS.seed)\n",
    "\n",
    "logger = create_logger(FLAGS.log_level)\n",
    "\n",
    "logger.info(extract_args_from_flags_dict(FLAGS.flag_values_dict()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    learner_device = torch.device('cuda')\n",
    "\n",
    "run_tournament(\n",
    "    seed = FLAGS.seed,\n",
    "    agents = agents,\n",
    "    env = eval_env,\n",
    "    device = learner_device,\n",
    "    num_games = 1000*len(agents),\n",
    "    num_simulations = FLAGS.num_simulations,\n",
    "    num_parallel = FLAGS.num_parallel,\n",
    "    c_puct_base = FLAGS.c_puct_base,\n",
    "    c_puct_init = FLAGS.c_puct_init,\n",
    "    default_rating = FLAGS.default_rating,\n",
    "    log_level = FLAGS.log_level,\n",
    "    logs_dir = FLAGS.logs_dir,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
